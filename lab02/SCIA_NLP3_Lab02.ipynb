{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yxyfer/EPTIA_NLP3/blob/main/lab02/SCIA_NLP3_Lab02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "444rw1H7Tc5X"
      },
      "source": [
        "import os \n",
        "import pandas as pd \n",
        "\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZZ-lQ6ZCSkw"
      },
      "source": [
        "%%capture\n",
        "! pip install fasttext"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdJi0t01bK4w"
      },
      "source": [
        "# I. Language detection (24 points)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for the fasttext model that has been saved\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "finb8qDKcU3i",
        "outputId": "4d91275f-dac1-4e91-cab9-77b5c5afc66d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLTloWrXUPjX"
      },
      "source": [
        "## Setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvSPXjija_s3"
      },
      "source": [
        "%%capture\n",
        "! git clone https://github.com/MastafaF/LanguageDetection.git"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "i1FzKr_KTn--",
        "outputId": "24074f76-6883-47ac-b4b6-940319ca3f27"
      },
      "source": [
        "os.listdir(\"./LanguageDetection\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-725a9ecd8b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./LanguageDetection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './LanguageDetection'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUX_IVaqTrGY"
      },
      "source": [
        "# CD the LanguageDetection folder - we are working in the below folder now\n",
        "os.chdir(\"./LanguageDetection\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCV5bn74UAPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998b3b16-341b-4f5f-abc0-43b149ae6bfe"
      },
      "source": [
        "# only if not installed\n",
        "! unzip dataset.csv.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset.csv.zip\n",
            "replace dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIBh8insUSc-"
      },
      "source": [
        "## Data Exploration Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDfv7hhSUN6i"
      },
      "source": [
        "data = pd.read_csv(\"./dataset.csv\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAXFNxudyfTr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "ef63bd04-a258-4fbf-b7f2-60c60d69f435"
      },
      "source": [
        "# Sample of the data\n",
        "HTML(data[data.language == \"Chinese\"].sample().to_html())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2147</th>\n",
              "      <td>年五-六月份爆發澱粉含順丁烯二酸酐食安事件，並擴及全台灣，俗稱毒澱粉事件。這一波食品安全危機中，台南市部份澱粉廠商為主要供應毒澱粉來源，當時衛生署採用選定特定的類項食品的全面稽查末端小吃店方式，展現所謂「全國同步、積極稽查」的執行作為，要求店家出具檢驗合格證明文件，否則不得販售該類產品的措施。而台南市長賴清德砲轟此執行作為，本末倒置、並不具任何效益。並指示暫停此種無效益的行政稽查，台南市處理原則為「源頭管理、阻斷貨源、追查上下游、並輔導店家使用合法澱粉」，只查在台南市轄區內製造廠，透過查核供貨帳冊及出貨單，查出其下游中盤商，並在媒體前建議中央參考南市源頭管理的做法。在月日市政府第次市政會議上市長宣稱：『所有問題澱粉月日全數銷毀，已沒有問題澱粉在台南市轄區內流通，請全體市民安心』。年月日食藥局表示市售抽驗毒澱粉未再發現新案，決定跟進台南市政府的作法，不再強制小吃攤飯張貼安全證明。而後在月日檢方查出茂利澱粉廠二度販售毒澱粉，將毒澱粉重新包裝再低價賣出，供貨遍及全台各地夜市、小吃。對於再度爆發毒澱粉案市長賴清德僅表示痛心，南市衛生局長表示將依新食品衛生管理法開罰。月日三進粉業再度被查出有庫存未申報的毒澱粉。</td>\n",
              "      <td>Chinese</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN0ADAdPVejT"
      },
      "source": [
        "### Question 1.1. Describe the distribution of languages and give at least two comments about the dataset. (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd1UdWiiVcoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcaf9ee9-2ea9-46ef-ab48-b85a2332f449"
      },
      "source": [
        "################################################\n",
        "# your implementation goes here\n",
        "\n",
        "def get_language_distrib(data):\n",
        "    print(data.groupby('language').size())\n",
        "\n",
        "get_language_distrib(data)\n",
        "##################################################"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language\n",
            "Arabic        1000\n",
            "Chinese       1000\n",
            "Dutch         1000\n",
            "English       1000\n",
            "Estonian      1000\n",
            "French        1000\n",
            "Hindi         1000\n",
            "Indonesian    1000\n",
            "Japanese      1000\n",
            "Korean        1000\n",
            "Latin         1000\n",
            "Persian       1000\n",
            "Portugese     1000\n",
            "Pushto        1000\n",
            "Romanian      1000\n",
            "Russian       1000\n",
            "Spanish       1000\n",
            "Swedish       1000\n",
            "Tamil         1000\n",
            "Thai          1000\n",
            "Turkish       1000\n",
            "Urdu          1000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.2. Do the appropriate pre-processing to maximise the accuracy of language detection. What is your strategy? (1 point)"
      ],
      "metadata": {
        "id": "OnxU_80iuWoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "zS6LfxEe414C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=data['Text']\n",
        "y=data['language']"
      ],
      "metadata": {
        "id": "Fuhj5LuL42aC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "id": "dvmS5DE-acJe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a93f2b58-4f14-49e3-b234-2468401434f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemärke  aastal viidi ta surnukeha mausoleumist ära ja kremeeriti zlíni linn kandis aastatel – nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel – nime gotvald'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "yMwRH0_3OmB_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 1.2.1. Preprocess X"
      ],
      "metadata": {
        "id": "_bUPnFmp_hBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from gensim.parsing import (\n",
        "    preprocess_string,\n",
        "    strip_numeric,\n",
        "    strip_multiple_whitespaces,\n",
        "    #strip_punctuation,\n",
        "  )\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "################################################\n",
        "# your implementation goes here\n",
        "\n",
        "def pre_process(text):\n",
        "  CUSTOM_FILTERS = [\n",
        "    lambda s: s.lower(),\n",
        "    lambda s: re.sub(r'[!@#$(),\"%^*?:;~`]', ' ', s),\n",
        "    strip_numeric,\n",
        "    #strip_punctuation, \n",
        "    strip_multiple_whitespaces,\n",
        "  ]\n",
        "  \n",
        "  return ' '.join(\n",
        "      preprocess_string(text, CUSTOM_FILTERS)\n",
        "    )\n",
        "\n",
        "X = X.apply(pre_process)\n",
        "\n",
        "X_copy = X\n",
        "\n",
        "# cv = CountVectorizer()\n",
        "cv = CountVectorizer(min_df=5)\n",
        "cv.fit(X)\n",
        "X = cv.transform(X)\n",
        "X = X.toarray()\n",
        "\n",
        "print(X)\n",
        "################################################"
      ],
      "metadata": {
        "id": "R4HnhZTB44S9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543016d7-1d7c-439a-e74e-d3dbbb8d593e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 1.2.1. Preprocess labels (y)\n"
      ],
      "metadata": {
        "id": "HFwWk5Rf_mHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "################################################\n",
        "# your implementation goes here\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "print(y)\n",
        "\n",
        "################################################"
      ],
      "metadata": {
        "id": "sxoksZl0_l64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf523edd-680f-458f-cf8a-d9d708ea68c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 4 17 19 ... 16  1 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.5. Train a model of your choice and describe the accuracy across languages. Use an 80%, 20% train-test split. Performance is not key but explain thoroughly the process and the metric(s) you are tracking. (4 points)"
      ],
      "metadata": {
        "id": "FhCQZlGAueYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.5.1. Create & Train Model"
      ],
      "metadata": {
        "id": "8Zo41rLlSoQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "################################################\n",
        "# your implementation goes here\n",
        "\n",
        "indices = list(range(len(X)))\n",
        "train_indices, test_indices = train_test_split(indices, test_size=0.20, random_state=42)\n",
        "\n",
        "def train_model(X_train, y_train):\n",
        "  clf = MultinomialNB()\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  return clf\n",
        "\n",
        "def get_values_from_indices(x_vals, y_vals, indices):\n",
        "  len_vals = len(x_vals)\n",
        "  X_vals = [x_vals[i] for i in range(len_vals) if i in indices]\n",
        "  y_vals = [y_vals[i] for i in range(len_vals) if i in indices]\n",
        "\n",
        "  return X_vals, y_vals\n",
        "\n",
        "X_train, y_train = get_values_from_indices(X, y, train_indices)\n",
        "X_test, y_test = get_values_from_indices(X, y, test_indices)\n",
        "\n",
        "clf = train_model(X_train, y_train)\n",
        "print(f'General Model Score: {clf.score(X_test, y_test)}')\n",
        "\n",
        "################################################"
      ],
      "metadata": {
        "id": "j-_QSnBh467f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8075a504-5773-4663-b20b-bce417be54b1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "General Model Score: 0.9286363636363636\n",
            "CPU times: user 3min 35s, sys: 5.61 s, total: 3min 41s\n",
            "Wall time: 3min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_custom(sentence):\n",
        "  return le.inverse_transform(clf.predict(cv.transform([sentence]).toarray()))[0]"
      ],
      "metadata": {
        "id": "xJcKXPDfd9rJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_custom(\"I am French and I love English\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yHmnj5mdc0bV",
        "outputId": "054f6984-30aa-4882-c4d0-a9b68a51b922"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'English'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_custom('Bonjour comment allez vous')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6vCLT-5WctK1",
        "outputId": "9f7e2c93-65cc-4ee4-eeab-4202b9fd9e3e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'French'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.5.2 Accuracy per Language"
      ],
      "metadata": {
        "id": "zLPWqhKOSh_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# your implementation goes here\n",
        "\n",
        "def score_per_lang(y_true, y_hat):\n",
        "  Dic = [i for i in range(22)]\n",
        "  language_pos = dict.fromkeys(Dic, 0)\n",
        "  language_tot = dict.fromkeys(Dic, 0)\n",
        "\n",
        "  for t, h in zip(y_true, y_hat):\n",
        "    if h == t:\n",
        "        language_pos[t] += 1\n",
        "    language_tot[t] += 1\n",
        "\n",
        "  accuracies = dict()\n",
        "  print('Accuracy for each language:')\n",
        "  for i in range(22):\n",
        "    lang = le.inverse_transform([i])[0]\n",
        "    if language_tot[i] != 0:\n",
        "      accuracy = language_pos[i] / language_tot[i]\n",
        "    else:\n",
        "      accuracy = 0\n",
        "    accuracies[lang] = accuracy\n",
        "    print(f'{lang:10}: {accuracy:f}')\n",
        "\n",
        "  return accuracies\n",
        "\n",
        "\n",
        "y_hat = clf.predict(X_test)\n",
        "lang_accuracies = score_per_lang(y_hat, y_test)\n",
        "\n",
        "################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hBRrUSNSX7h",
        "outputId": "f372480e-7434-41c9-978b-a9afba910024"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each language:\n",
            "Arabic    : 1.000000\n",
            "Chinese   : 0.910256\n",
            "Dutch     : 0.982533\n",
            "English   : 0.713235\n",
            "Estonian  : 0.984456\n",
            "French    : 0.939394\n",
            "Hindi     : 0.995146\n",
            "Indonesian: 0.995215\n",
            "Japanese  : 0.968085\n",
            "Korean    : 0.994709\n",
            "Latin     : 0.979487\n",
            "Persian   : 0.994898\n",
            "Portugese : 0.994709\n",
            "Pushto    : 1.000000\n",
            "Romanian  : 0.979695\n",
            "Russian   : 0.985981\n",
            "Spanish   : 0.975369\n",
            "Swedish   : 0.493113\n",
            "Tamil     : 1.000000\n",
            "Thai      : 1.000000\n",
            "Turkish   : 0.989950\n",
            "Urdu      : 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0614tVO--6G"
      },
      "source": [
        "## FastText for language detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhGvhp6kf8E5"
      },
      "source": [
        "### FastText training setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZtDxw9D9aPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3d8130-71df-4eb9-e3d6-500dea063c78"
      },
      "source": [
        "! wget http://downloads.tatoeba.org/exports/sentences.tar.bz2"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2023-01-07 09:19:56--  https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172915061 (165M) [application/octet-stream]\n",
            "Saving to: ‘sentences.tar.bz2’\n",
            "\n",
            "sentences.tar.bz2   100%[===================>] 164.90M  25.3MB/s    in 7.4s    \n",
            "\n",
            "2023-01-07 09:20:04 (22.3 MB/s) - ‘sentences.tar.bz2’ saved [172915061/172915061]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9ETznJA9cLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cdcc23d-4ff3-47a1-b860-c37057bf41b5"
      },
      "source": [
        "! bunzip2 sentences.tar.bz2"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bunzip2: Output file sentences.tar already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cihDm5c99oZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390e6cfd-9b1f-4d41-ef42-c5b86e9e0d9a"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all.txt\t\t\tdata_test.txt\tsentences.csv\t   valid.txt\n",
            "dataset.csv\t\tdata_train.txt\tsentences.tar\n",
            "dataset.csv.zip\t\tLICENSE\t\tsentences.tar.bz2\n",
            "data_test_no_label.txt\tREADME.md\ttrain.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPZSloMN-cM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ac3e6e-8cc0-4597-b098-995d7d1ed545"
      },
      "source": [
        "! tar xvf sentences.tar"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si8T701N-h5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370517d8-26c7-4a31-a3e0-848161ee3d52"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset.csv  dataset.csv.zip  LICENSE  README.md  sentences.csv  sentences.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtjL8hYg-nZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6c6cd0-201d-4e64-d081-e2ce79de231a"
      },
      "source": [
        "! head -10 sentences.csv"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\tcmn\t我們試試看！\n",
            "2\tcmn\t我该去睡觉了。\n",
            "3\tcmn\t你在干什麼啊？\n",
            "4\tcmn\t這是什麼啊？\n",
            "5\tcmn\t今天是６月１８号，也是Muiriel的生日！\n",
            "6\tcmn\t生日快乐，Muiriel！\n",
            "7\tcmn\tMuiriel现在20岁了。\n",
            "8\tcmn\t密码是\"Muiriel\"。\n",
            "9\tcmn\t我很快就會回來。\n",
            "10\tcmn\t我不知道。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTtbtb5E-tFP"
      },
      "source": [
        "! awk -F\"\\t\" '{print\"__label__\"$2\" \"$3}' < sentences.csv | shuf > all.txt"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5CwoZkl_JS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4129dbed-bfe1-49a9-d237-af9296dafcc9"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all.txt      dataset.csv.zip  README.md      sentences.tar\n",
            "dataset.csv  LICENSE\t      sentences.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj17b-zF_V65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e827137-a662-4f62-a4e2-bdba488dbae8"
      },
      "source": [
        "! head -5 all.txt"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__label__kab Tettexfa deg usallas-nni.\n",
            "__label__pol Tom wygląda trochę niebezpiecznie.\n",
            "__label__kab Ad rekben ihi ɣer Warzazat.\n",
            "__label__srp Постати добар писац исто је као добар тесар; треба пажљиво тесати своје реченице.\n",
            "__label__eng Who are the people I saw her with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJFTaHZ8_D6V"
      },
      "source": [
        "! head -n 10000 all.txt > valid.txt"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJeo9_MD_qq8"
      },
      "source": [
        "! tail -n +10001 all.txt > train.txt"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZSiMBU7Aabp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e154ac-ca3a-4342-d9c7-4ee71a0c418b"
      },
      "source": [
        "! head -5 train.txt"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__label__tuk Ol öz aýalyny urup otyrdy.\n",
            "__label__mar तू त्यांच्यासाठी सँडविच बनवते आहेस का?\n",
            "__label__rus Том одинок, и ему не с кем играть.\n",
            "__label__epo Ne heroumu!\n",
            "__label__epo Knabinoj maturiĝas pli frue ol knaboj.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.6. Train a fasttext model on Tatoeba parallel corpus and check that performance is good. (3 points)"
      ],
      "metadata": {
        "id": "wiZRD_FjueS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del X\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ekPlYWSjt0l",
        "outputId": "e3f4fc41-41ac-4b27-bcc6-b14ad4b1f8c9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext"
      ],
      "metadata": {
        "id": "wKyg3QToJo3I"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YN516w-3Mea"
      },
      "source": [
        "#### Question 1.6.1. Train fasttext model on Tatoeba (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpaHpA9QCLur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65dade19-d019-4c97-a043-d1f2fead7ec3"
      },
      "source": [
        "%%time\n",
        "import fasttext\n",
        "\n",
        "# Check the fasttext library and implement the training\n",
        "###########################################\n",
        "\n",
        "# your implementation goes here\n",
        "pass\n",
        "\n",
        "fmodel = fasttext.train_supervised('train.txt') #, lr=1, epoch=1)\n",
        "\n",
        "################################################\n",
        "\n",
        "# @TODO: Save your model when trained \n",
        "fmodel.save_model(\"langdetect.bin\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1h 40min 15s, sys: 9.02 s, total: 1h 40min 24s\n",
            "Wall time: 1h 40min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fmodel = fasttext.load_model('/content/drive/MyDrive/ColabNotebooks/NLP3/lab02/langdetect.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11CodK6cJOq3",
        "outputId": "1664ef1a-53a2-4db9-fecf-b9993624b817"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFQcolkmIXZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9fa8687-b9c2-4d3f-f679-1f2574bbb6ad"
      },
      "source": [
        "# Sanity check \n",
        "fmodel.predict(\"I am French and I love English\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__eng',), array([1.00000882]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fmodel.predict(\"Bonjour je suis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlK-1bo0CjdM",
        "outputId": "51f79714-3938-4293-a142-95d7301d972f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__fra',), array([0.99995446]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZYQz3zh3VK5"
      },
      "source": [
        "#### Question 1.6.2. Evaluate performance of fasttext model on valid.txt (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "pip install iso639-lang"
      ],
      "metadata": {
        "id": "u-JV1ZA_Sie0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from iso639 import Lang\n",
        "\n",
        "Lang('ara')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMhIglB9Se88",
        "outputId": "adb02d03-72fa-4b5d-d6bf-0a614d3f21ba"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lang(name='Arabic', pt1='ar', pt2b='ara', pt2t='ara', pt3='ara', pt5='')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from iso639 import Lang\n",
        "\n",
        "class ModelPredict(object):\n",
        "  def __init__(self, model, le, nb_languages=22):\n",
        "    self.model = model\n",
        "    self.le = le\n",
        "    self.nb_languages = nb_languages\n",
        "\n",
        "    self.languages = self.get_languages()\n",
        "    self.flabels = self.format_model_labels()\n",
        "    self.lang_to_code, self.code_to_lang = self.get_code_to_lang()\n",
        "\n",
        "\n",
        "  def predict(self, sentence):\n",
        "    lang_code = self.model.predict(sentence)[0][0].replace('__label__', '')\n",
        "    return self.code_to_lang.get(lang_code, 'Not Found')\n",
        "\n",
        "  def predict_set(self, test_set):\n",
        "    y_hat = []\n",
        "    for sentence in test_set:\n",
        "      label = self.predict(sentence)\n",
        "      if label == 'Not Found':\n",
        "        y_hat_curr = -1;\n",
        "      else:\n",
        "        y_hat_curr = self.le.transform([label])[0]\n",
        "      y_hat.append(y_hat_curr)\n",
        "\n",
        "    return y_hat\n",
        "\n",
        "  ### HELPERS\n",
        "\n",
        "  def get_languages(self):\n",
        "    languages = []\n",
        "    for i in range(self.nb_languages):\n",
        "      lang = self.le.inverse_transform([i])[0]\n",
        "      languages.append(lang)\n",
        "\n",
        "    return languages\n",
        "\n",
        "  def remove_label(self, str):\n",
        "    return str.replace('__label__', '')\n",
        "\n",
        "  def format_model_labels(self):\n",
        "    labels_raw = sorted(self.model.get_labels())\n",
        "    labels = list(map(lambda str: self.remove_label(str), labels_raw))\n",
        "    return labels[1:]\n",
        "\n",
        "  def get_code_to_lang(self):\n",
        "    lang_to_code = dict.fromkeys(self.languages, '')\n",
        "\n",
        "    for lang in self.languages:\n",
        "      lang_code = Lang('Portuguese').pt3 if lang == 'Portugese' else 'pes' if lang == 'Persian' else (Lang(lang).pt3 if lang != 'Chinese' else 'cmn')\n",
        "      if lang_code in self.flabels:\n",
        "        lang_to_code[lang] = lang_code\n",
        "\n",
        "    code_to_lang = {v: k for k, v in lang_to_code.items()}\n",
        "\n",
        "    for lang in ['lzh', 'hak', 'cjy', 'cpi', 'hsn', 'gan', 'izh']:\n",
        "      code_to_lang[lang] = 'Chinese'\n",
        "\n",
        "    return lang_to_code, code_to_lang\n",
        "    "
      ],
      "metadata": {
        "id": "2sYiuevYw0SQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp = ModelPredict(fmodel, le)"
      ],
      "metadata": {
        "id": "o4AEkoMPycOe"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mp.languages[:5])\n",
        "print(mp.flabels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0V_RRU-NIgc",
        "outputId": "d618497d-7665-4fb5-d951-624cac8b79bb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Arabic', 'Chinese', 'Dutch', 'English', 'Estonian']\n",
            "['abk', 'acm', 'ady', 'afb', 'afh', 'afr', 'aii', 'ain', 'ajp', 'akl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mp.predict('Bonjour Comment allez vous')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nKmPTPztci4j",
        "outputId": "3fb699d4-078b-4010-a2a0-e0b7e3c200d9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'French'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWNZ5TSdKGgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "897b4d6c-4efd-4a05-a537-ab66790f6436"
      },
      "source": [
        "# Hint: Create dataframe from valid.txt and evaluate performance \n",
        "\n",
        "###########################################\n",
        "\n",
        "# your implementation goes here\n",
        "\n",
        "result = fmodel.test('valid.txt')\n",
        "print(\"Validation set accuracy:\", result[1])\n",
        "\n",
        "################################################"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set accuracy: 0.9879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.7. Test your fasttext model on the same dataset as in question 1-5. Compare with your custom model (make sure you use the exact same data for testing). How can you explain the difference in performance between the two models? (3 points)"
      ],
      "metadata": {
        "id": "1CI3pNqYueOX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJYVrn8FhcQf"
      },
      "source": [
        "import fasttext\n",
        "\n",
        "###########################################\n",
        "\n",
        "# your implementation goes here\n",
        "\n",
        "def save_data(X, y, train=False, label=True):\n",
        "  filename = 'data_train.txt' if train else ('data_test.txt' if label else 'data_test_no_label.txt')\n",
        "  \n",
        "  file = open(filename, 'w')\n",
        "  for x_curr, y_curr in zip(X, y):\n",
        "    if label:\n",
        "      lang = le.inverse_transform([y_curr])[0]\n",
        "      lang_code = Lang('Portuguese').pt3 if lang == 'Portugese' else Lang(lang).pt3\n",
        "      y_curr = '__label__' + lang_code\n",
        "      final_string = y_curr + ' ' + x_curr + '\\n'\n",
        "    else:\n",
        "      final_string = x_curr + '\\n'\n",
        "    \n",
        "    file.write(final_string)\n",
        "  file.close()\n",
        "\n",
        "\n",
        "#fX_train, fX_test, fy_train, fy_test = train_test_split(X_copy, y, test_size=0.20)\n",
        "\n",
        "fX_train, fy_train = get_values_from_indices(X_copy, y, train_indices)\n",
        "fX_test, fy_test = get_values_from_indices(X_copy, y, test_indices)\n",
        "\n",
        "save_data(fX_train, fy_train, train=True)             # Train with labels\n",
        "save_data(fX_test, fy_test, train=False)              # Test  with labels\n",
        "save_data(fX_test, fy_test, train=False, label=False) # Test  no   labels\n",
        "\n",
        "################################################"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = fmodel.test('data_test.txt')\n",
        "print(\"Validation set accuracy:\", result[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EebDObJkiExA",
        "outputId": "0a49b4be-b92a-4183-d477-9ac58f7199f0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set accuracy: 0.83337496877342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fy_hat = mp.predict_set(fX_test)\n",
        "print(-1 in fy_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED7xYNrj0bNk",
        "outputId": "0e00b387-0a94-4dd6-ade8-c5a6686ae96c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.8. Compute your performance metrics yourself and compare with sklearn. (1 point)"
      ],
      "metadata": {
        "id": "dqpnRWJ-ueE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.8.1. Personal Metrics"
      ],
      "metadata": {
        "id": "-2c_RRQjvI05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score_recoded(y_true, y_hat):\n",
        "  return np.mean(y_true == (y_hat))\n",
        "\n",
        "print(f'Accuracy Score: {accuracy_score_recoded(fy_test, fy_hat)}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDP3F1-qZvCO",
        "outputId": "7a7dbe88-8113-483b-dafc-5a816cb584ba"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = score_per_lang(fy_test, fy_hat)"
      ],
      "metadata": {
        "id": "ZoQ9qO4I5ytJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da8cf23-4b86-4b23-ebe4-566b2fa116da"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each language:\n",
            "Arabic    : 0.980198\n",
            "Chinese   : 0.004975\n",
            "Dutch     : 0.969565\n",
            "English   : 1.000000\n",
            "Estonian  : 0.810000\n",
            "French    : 0.989362\n",
            "Hindi     : 0.985577\n",
            "Indonesian: 0.868545\n",
            "Japanese  : 0.845361\n",
            "Korean    : 0.957895\n",
            "Latin     : 0.885714\n",
            "Persian   : 0.994898\n",
            "Portugese : 0.958763\n",
            "Pushto    : 0.000000\n",
            "Romanian  : 0.969543\n",
            "Russian   : 0.995305\n",
            "Spanish   : 0.984925\n",
            "Swedish   : 1.000000\n",
            "Tamil     : 0.474747\n",
            "Thai      : 0.117347\n",
            "Turkish   : 0.974874\n",
            "Urdu      : 0.866995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.8.2. sklearn Metrics"
      ],
      "metadata": {
        "id": "TTwdqtWtvMP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(fy_test, fy_hat)"
      ],
      "metadata": {
        "id": "5HHglOrFuMs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca244177-9a82-4392-d315-4025cdbd7899"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8027272727272727"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Rotate two semantic spaces (23 points) – Not guided coding\n"
      ],
      "metadata": {
        "id": "YgCNRO0Tud6v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YSo7Nyj50yv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}