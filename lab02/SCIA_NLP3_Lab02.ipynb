{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yxyfer/EPTIA_NLP3/blob/main/lab02/SCIA_NLP3_Lab02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "444rw1H7Tc5X"
      },
      "source": [
        "import os \n",
        "import pandas as pd \n",
        "\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZZ-lQ6ZCSkw"
      },
      "source": [
        "%%capture\n",
        "! pip install fasttext"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdJi0t01bK4w"
      },
      "source": [
        "# I. Language detection (24 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLTloWrXUPjX"
      },
      "source": [
        "## Setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvSPXjija_s3"
      },
      "source": [
        "%%capture\n",
        "! git clone https://github.com/MastafaF/LanguageDetection.git"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1FzKr_KTn--",
        "outputId": "213fb86e-b640-4643-f74e-66162e08c39f"
      },
      "source": [
        "os.listdir(\"./LanguageDetection\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_train.txt',\n",
              " 'dataset.csv',\n",
              " 'all.txt',\n",
              " 'langdetect.bin',\n",
              " 'sentences.csv',\n",
              " '.gitignore',\n",
              " 'valid.txt',\n",
              " '.git',\n",
              " 'train.txt',\n",
              " 'README.md',\n",
              " 'sentences.tar.bz2',\n",
              " 'data_test_no_label.txt',\n",
              " 'sentences.tar',\n",
              " 'LICENSE',\n",
              " 'dataset.csv.zip',\n",
              " 'data_test.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUX_IVaqTrGY"
      },
      "source": [
        "# CD the LanguageDetection folder - we are working in the below folder now\n",
        "os.chdir(\"./LanguageDetection\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCV5bn74UAPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d02a6e-adfc-4b1f-8197-912f7e1b2785"
      },
      "source": [
        "# only if not installed\n",
        "! unzip dataset.csv.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset.csv.zip\n",
            "replace dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIBh8insUSc-"
      },
      "source": [
        "## Data Exploration Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDfv7hhSUN6i"
      },
      "source": [
        "data = pd.read_csv(\"./dataset.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAXFNxudyfTr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "d2429636-f220-4768-eb00-19e09a773317"
      },
      "source": [
        "# Sample of the data\n",
        "HTML(data[data.language == \"Chinese\"].sample().to_html())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8349</th>\n",
              "      <td>张伯声（年月日－年月日），中国构造地质学家。生于河南荥阳。曾就读于河南留学欧美预备学校，年毕业于清华学校。年获美国芝加哥大学化学系学士学位。年当选为中国科学院学部委员院士。曾任西北大学教授、副校长，西安地质学院教授、院长、名誉院长。</td>\n",
              "      <td>Chinese</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN0ADAdPVejT"
      },
      "source": [
        "### Question 1.1. Describe the distribution of languages and give at least two comments about the dataset. (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd1UdWiiVcoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e88cca7-0da5-4659-e91c-142d40886f53"
      },
      "source": [
        "################################################\n",
        "# your implementation goes here\n",
        "\n",
        "def get_language_distrib(data):\n",
        "    print(data.groupby('language').size())\n",
        "\n",
        "get_language_distrib(data)\n",
        "##################################################"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language\n",
            "Arabic        1000\n",
            "Chinese       1000\n",
            "Dutch         1000\n",
            "English       1000\n",
            "Estonian      1000\n",
            "French        1000\n",
            "Hindi         1000\n",
            "Indonesian    1000\n",
            "Japanese      1000\n",
            "Korean        1000\n",
            "Latin         1000\n",
            "Persian       1000\n",
            "Portugese     1000\n",
            "Pushto        1000\n",
            "Romanian      1000\n",
            "Russian       1000\n",
            "Spanish       1000\n",
            "Swedish       1000\n",
            "Tamil         1000\n",
            "Thai          1000\n",
            "Turkish       1000\n",
            "Urdu          1000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.2. Do the appropriate pre-processing to maximise the accuracy of language detection. What is your strategy? (1 point)"
      ],
      "metadata": {
        "id": "OnxU_80iuWoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "zS6LfxEe414C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=data['Text']\n",
        "y=data['language']"
      ],
      "metadata": {
        "id": "Fuhj5LuL42aC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "id": "dvmS5DE-acJe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8b4d3206-32f2-4928-a72e-ed28fa5820ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemärke  aastal viidi ta surnukeha mausoleumist ära ja kremeeriti zlíni linn kandis aastatel – nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel – nime gotvald'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "yMwRH0_3OmB_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 1.2.1. Preprocess X"
      ],
      "metadata": {
        "id": "_bUPnFmp_hBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from gensim.parsing import (\n",
        "    preprocess_string,\n",
        "    strip_numeric,\n",
        "    strip_multiple_whitespaces,\n",
        "    #strip_punctuation,\n",
        "  )\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "################################################\n",
        "# your implementation goes here\n",
        "\n",
        "def pre_process(text):\n",
        "  CUSTOM_FILTERS = [\n",
        "    lambda s: s.lower(),\n",
        "    lambda s: re.sub(r'[!@#$(),\"%^*?:;~`]', ' ', s),\n",
        "    strip_numeric,\n",
        "    #strip_punctuation, \n",
        "    strip_multiple_whitespaces,\n",
        "  ]\n",
        "  \n",
        "  return ' '.join(\n",
        "      preprocess_string(text, CUSTOM_FILTERS)\n",
        "    )\n",
        "\n",
        "X = X.apply(pre_process)\n",
        "\n",
        "X_copy = X\n",
        "\n",
        "# cv = CountVectorizer()\n",
        "cv = CountVectorizer(min_df=5)\n",
        "cv.fit(X)\n",
        "X = cv.transform(X)\n",
        "X = X.toarray()\n",
        "\n",
        "print(X)\n",
        "################################################"
      ],
      "metadata": {
        "id": "R4HnhZTB44S9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8925b795-91cb-4094-cb2d-f55e8597d425"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 1.2.1. Preprocess labels (y)\n"
      ],
      "metadata": {
        "id": "HFwWk5Rf_mHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "################################################\n",
        "# your implementation goes here\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "print(y)\n",
        "\n",
        "################################################"
      ],
      "metadata": {
        "id": "sxoksZl0_l64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4e6943-d98a-4212-ac22-7eafaff22457"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 4 17 19 ... 16  1 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.5. Train a model of your choice and describe the accuracy across languages. Use an 80%, 20% train-test split. Performance is not key but explain thoroughly the process and the metric(s) you are tracking. (4 points)"
      ],
      "metadata": {
        "id": "FhCQZlGAueYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.5.1. Create & Train Model"
      ],
      "metadata": {
        "id": "8Zo41rLlSoQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "################################################\n",
        "# your implementation goes here\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "\n",
        "def train_model(X_train, y_train):\n",
        "  clf = MultinomialNB()\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  return clf\n",
        "\n",
        "clf = train_model(X_train, y_train)\n",
        "print(f'General Model Score: {clf.score(X_test, y_test)}')\n",
        "\n",
        "################################################"
      ],
      "metadata": {
        "id": "j-_QSnBh467f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f3bdf9-6797-491b-8327-3a6912c2c6b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "General Model Score: 0.9315909090909091\n",
            "CPU times: user 1min 19s, sys: 1.68 s, total: 1min 21s\n",
            "Wall time: 1min 21s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.5.2 Accuracy per Language"
      ],
      "metadata": {
        "id": "zLPWqhKOSh_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# your implementation goes here\n",
        "\n",
        "def score_per_lang(y_true, y_hat):\n",
        "  Dic = [i for i in range(22)]\n",
        "  language_pos = dict.fromkeys(Dic, 0)\n",
        "  language_tot = dict.fromkeys(Dic, 0)\n",
        "\n",
        "  for t, h in zip(y_true, y_hat):\n",
        "    if h == t:\n",
        "        language_pos[t] += 1\n",
        "    language_tot[t] += 1\n",
        "\n",
        "  accuracies = dict()\n",
        "  print('Accuracy for each language:')\n",
        "  for i in range(22):\n",
        "    lang = le.inverse_transform([i])[0]\n",
        "    if language_tot[i] != 0:\n",
        "      accuracy = language_pos[i] / language_tot[i]\n",
        "    else:\n",
        "      accuracy = 0\n",
        "    accuracies[lang] = accuracy\n",
        "    print(f'{lang:10}: {accuracy:f}')\n",
        "\n",
        "  return accuracies\n",
        "\n",
        "\n",
        "y_hat = clf.predict(X_test)\n",
        "lang_accuracies = score_per_lang(y_hat, y_test)\n",
        "\n",
        "################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hBRrUSNSX7h",
        "outputId": "5dadeb3e-0cfe-4a57-871c-de0aabf82fbd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each language:\n",
            "Arabic    : 1.000000\n",
            "Chinese   : 0.917647\n",
            "Dutch     : 0.989796\n",
            "English   : 0.723636\n",
            "Estonian  : 0.975369\n",
            "French    : 0.489130\n",
            "Hindi     : 0.995169\n",
            "Indonesian: 0.995215\n",
            "Japanese  : 1.000000\n",
            "Korean    : 1.000000\n",
            "Latin     : 0.983146\n",
            "Persian   : 1.000000\n",
            "Portugese : 0.989071\n",
            "Pushto    : 0.994975\n",
            "Romanian  : 0.994792\n",
            "Russian   : 0.995074\n",
            "Spanish   : 0.965000\n",
            "Swedish   : 0.974747\n",
            "Tamil     : 1.000000\n",
            "Thai      : 1.000000\n",
            "Turkish   : 0.995146\n",
            "Urdu      : 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0614tVO--6G"
      },
      "source": [
        "## FastText for language detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhGvhp6kf8E5"
      },
      "source": [
        "### FastText training setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZtDxw9D9aPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ee4099-1072-4ac7-e9e4-beaf76a2f3bb"
      },
      "source": [
        "! wget http://downloads.tatoeba.org/exports/sentences.tar.bz2"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2023-01-06 12:58:59--  https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172433658 (164M) [application/octet-stream]\n",
            "Saving to: ‘sentences.tar.bz2’\n",
            "\n",
            "sentences.tar.bz2   100%[===================>] 164.45M  16.4MB/s    in 11s     \n",
            "\n",
            "2023-01-06 12:59:11 (15.0 MB/s) - ‘sentences.tar.bz2’ saved [172433658/172433658]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9ETznJA9cLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12cddc19-16c4-4203-e513-132c41a5f999"
      },
      "source": [
        "! bunzip2 sentences.tar.bz2"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bunzip2: Output file sentences.tar already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cihDm5c99oZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0248c8ae-dc51-4810-8dea-26b717ce91c9"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all.txt\t\t langdetect.bin  sentences.csv\t    train.txt\n",
            "dataset.csv\t LICENSE\t sentences.tar\t    valid.txt\n",
            "dataset.csv.zip  README.md\t sentences.tar.bz2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPZSloMN-cM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4882dc5-55cd-4a28-eed9-ae65de2a1072"
      },
      "source": [
        "! tar xvf sentences.tar"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si8T701N-h5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66db0764-e88a-43bc-b50f-c91f6af8e24a"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all.txt\t\t langdetect.bin  sentences.csv\t    train.txt\n",
            "dataset.csv\t LICENSE\t sentences.tar\t    valid.txt\n",
            "dataset.csv.zip  README.md\t sentences.tar.bz2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtjL8hYg-nZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e1e437-db8f-41c2-c490-d9fdf878d3a5"
      },
      "source": [
        "! head -10 sentences.csv"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\tcmn\t我們試試看！\n",
            "2\tcmn\t我该去睡觉了。\n",
            "3\tcmn\t你在干什麼啊？\n",
            "4\tcmn\t這是什麼啊？\n",
            "5\tcmn\t今天是６月１８号，也是Muiriel的生日！\n",
            "6\tcmn\t生日快乐，Muiriel！\n",
            "7\tcmn\tMuiriel现在20岁了。\n",
            "8\tcmn\t密码是\"Muiriel\"。\n",
            "9\tcmn\t我很快就會回來。\n",
            "10\tcmn\t我不知道。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTtbtb5E-tFP"
      },
      "source": [
        "! awk -F\"\\t\" '{print\"__label__\"$2\" \"$3}' < sentences.csv | shuf > all.txt"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5CwoZkl_JS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1cdd6a-f5d3-46aa-d18a-f1c9390a5243"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all.txt\t\t langdetect.bin  sentences.csv\t    train.txt\n",
            "dataset.csv\t LICENSE\t sentences.tar\t    valid.txt\n",
            "dataset.csv.zip  README.md\t sentences.tar.bz2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj17b-zF_V65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ffca84-7ad4-4900-968a-f663ddf61cd5"
      },
      "source": [
        "! head -5 all.txt"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__label__fra La pièce est très petite, à tel point qu'il n'est pas possible d'ajouter des meubles.\n",
            "__label__spa Los gemelos se ocupaban del bebé.\n",
            "__label__por Ele é ucraniano.\n",
            "__label__ina Il ha multe blau edificios gigantesc in le grande citate.\n",
            "__label__deu Sie ist vorigen Montag mit ihm einkaufen gegangen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJFTaHZ8_D6V"
      },
      "source": [
        "! head -n 10000 all.txt > valid.txt"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJeo9_MD_qq8"
      },
      "source": [
        "! tail -n +10001 all.txt > train.txt"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZSiMBU7Aabp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459b765a-e92a-47b9-a24a-e6293a99b03a"
      },
      "source": [
        "! head -5 train.txt"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__label__jpn その日から、不安がつのっていくばかりだった。\n",
            "__label__por Quanto menor o medo, menor o perigo.\n",
            "__label__tur Neden Tom bir şey yapmıyor?\n",
            "__label__eng Tom has never got the credit for anything.\n",
            "__label__spa John es un chico americano.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.6. Train a fasttext model on Tatoeba parallel corpus and check that performance is good. (3 points)"
      ],
      "metadata": {
        "id": "wiZRD_FjueS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del X\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ekPlYWSjt0l",
        "outputId": "50e218ca-f2b1-4d9a-d616-49b7a3e2dc29"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext"
      ],
      "metadata": {
        "id": "wKyg3QToJo3I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YN516w-3Mea"
      },
      "source": [
        "#### Question 1.6.1. Train fasttext model on Tatoeba (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpaHpA9QCLur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65dade19-d019-4c97-a043-d1f2fead7ec3"
      },
      "source": [
        "%%time\n",
        "import fasttext\n",
        "\n",
        "# Check the fasttext library and implement the training\n",
        "###########################################\n",
        "\n",
        "# your implementation goes here\n",
        "pass\n",
        "\n",
        "fmodel = fasttext.train_supervised('train.txt') #, lr=1, epoch=1)\n",
        "\n",
        "################################################\n",
        "\n",
        "# @TODO: Save your model when trained \n",
        "fmodel.save_model(\"langdetect.bin\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1h 40min 15s, sys: 9.02 s, total: 1h 40min 24s\n",
            "Wall time: 1h 40min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fmodel = fasttext.load_model('langdetect.bin')\n",
        "fmodel = fasttext.load_model('/content/drive/MyDrive/ColabNotebooks/NLP3/lab02/langdetect.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11CodK6cJOq3",
        "outputId": "e57e6941-0ccc-4510-b9ef-a94505c05277"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFQcolkmIXZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eabdc1b-5e5e-44f1-cec8-bc594cc0c55e"
      },
      "source": [
        "# Sanity check \n",
        "fmodel.predict(\"I am French and I love English\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__eng',), array([1.00000882]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fmodel.predict(\"Bonjour je suis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlK-1bo0CjdM",
        "outputId": "5bef9e8f-ef40-4d67-decb-8e20b010052d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__fra',), array([0.99995446]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZYQz3zh3VK5"
      },
      "source": [
        "#### Question 1.6.2. Evaluate performance of fasttext model on valid.txt (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "pip install iso639-lang"
      ],
      "metadata": {
        "id": "u-JV1ZA_Sie0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from iso639 import Lang\n",
        "\n",
        "Lang('ara')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMhIglB9Se88",
        "outputId": "8883fed2-6ddf-43f9-9b85-972c7d271656"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lang(name='Arabic', pt1='ar', pt2b='ara', pt2t='ara', pt3='ara', pt5='')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from iso639 import Lang\n",
        "\n",
        "class ModelPredict(object):\n",
        "  def __init__(self, model, le, nb_languages=22):\n",
        "    self.model = model\n",
        "    self.le = le\n",
        "    self.nb_languages = nb_languages\n",
        "\n",
        "    self.languages = self.get_languages()\n",
        "    self.flabels = self.format_model_labels()\n",
        "    self.lang_to_code, self.code_to_lang = self.get_code_to_lang()\n",
        "\n",
        "\n",
        "  def predict(self, sentence):\n",
        "    lang_code = self.model.predict(sentence)[0][0].replace('__label__', '')\n",
        "    return self.code_to_lang.get(lang_code, 'Not Found')\n",
        "\n",
        "  def predict_set(self, test_set):\n",
        "    y_hat = []\n",
        "    for sentence in test_set:\n",
        "      label = self.predict(sentence)\n",
        "      if label == 'Not Found':\n",
        "        y_hat_curr = -1;\n",
        "      else:\n",
        "        y_hat_curr = self.le.transform([label])[0]\n",
        "      y_hat.append(y_hat_curr)\n",
        "\n",
        "    return y_hat\n",
        "\n",
        "  ### HELPERS\n",
        "\n",
        "  def get_languages(self):\n",
        "    languages = []\n",
        "    for i in range(self.nb_languages):\n",
        "      lang = self.le.inverse_transform([i])[0]\n",
        "      languages.append(lang)\n",
        "\n",
        "    return languages\n",
        "\n",
        "  def remove_label(self, str):\n",
        "    return str.replace('__label__', '')\n",
        "\n",
        "  def format_model_labels(self):\n",
        "    labels_raw = sorted(self.model.get_labels())\n",
        "    labels = list(map(lambda str: self.remove_label(str), labels_raw))\n",
        "    return labels[1:]\n",
        "\n",
        "  def get_code_to_lang(self):\n",
        "    lang_to_code = dict.fromkeys(self.languages, '')\n",
        "\n",
        "    for lang in self.languages:\n",
        "      lang_code = Lang('Portuguese').pt3 if lang == 'Portugese' else 'pes' if lang == 'Persian' else (Lang(lang).pt3 if lang != 'Chinese' else 'cmn')\n",
        "      if lang_code in self.flabels:\n",
        "        lang_to_code[lang] = lang_code\n",
        "\n",
        "    code_to_lang = {v: k for k, v in lang_to_code.items()}\n",
        "\n",
        "    for lang in ['lzh', 'hak', 'cjy', 'cpi', 'hsn', 'gan', 'izh']:\n",
        "      code_to_lang[lang] = 'Chinese'\n",
        "\n",
        "    return lang_to_code, code_to_lang\n",
        "    "
      ],
      "metadata": {
        "id": "2sYiuevYw0SQ"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp = ModelPredict(fmodel, le)"
      ],
      "metadata": {
        "id": "o4AEkoMPycOe"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mp.languages[:5])\n",
        "print(mp.flabels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0V_RRU-NIgc",
        "outputId": "5aad1760-9991-45ee-b140-0f7012cb8fdb"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Arabic', 'Chinese', 'Dutch', 'English', 'Estonian']\n",
            "['abk', 'acm', 'ady', 'afb', 'afh', 'afr', 'aii', 'ain', 'ajp', 'akl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mp.predict('Bonjour Comment allez vous')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nKmPTPztci4j",
        "outputId": "0dc3ba3b-6eae-401f-a8ab-c551d28346f9"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'French'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWNZ5TSdKGgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca27125-3da0-4de1-ccdf-8814603a93a9"
      },
      "source": [
        "# Hint: Create dataframe from valid.txt and evaluate performance \n",
        "\n",
        "###########################################\n",
        "\n",
        "# your implementation goes here\n",
        "\n",
        "result = fmodel.test('valid.txt')\n",
        "print(\"Validation set accuracy:\", result[1])\n",
        "\n",
        "################################################"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set accuracy: 0.9904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.7. Test your fasttext model on the same dataset as in question 1-5. Compare with your custom model (make sure you use the exact same data for testing). How can you explain the difference in performance between the two models? (3 points)"
      ],
      "metadata": {
        "id": "1CI3pNqYueOX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJYVrn8FhcQf"
      },
      "source": [
        "import fasttext\n",
        "\n",
        "###########################################\n",
        "\n",
        "# your implementation goes here\n",
        "\n",
        "def save_data(X, y, train=False, label=True):\n",
        "  filename = 'data_train.txt' if train else ('data_test.txt' if label else 'data_test_no_label.txt')\n",
        "  \n",
        "  file = open(filename, 'w')\n",
        "  for x_curr, y_curr in zip(X, y):\n",
        "    if label:\n",
        "      lang = le.inverse_transform([y_curr])[0]\n",
        "      lang_code = Lang('Portuguese').pt3 if lang == 'Portugese' else Lang(lang).pt3\n",
        "      y_curr = '__label__' + lang_code\n",
        "      final_string = y_curr + ' ' + x_curr + '\\n'\n",
        "    else:\n",
        "      final_string = x_curr + '\\n'\n",
        "    \n",
        "    file.write(final_string)\n",
        "  file.close()\n",
        "\n",
        "\n",
        "fX_train, fX_test, fy_train, fy_test = train_test_split(X_copy, y, test_size=0.20)\n",
        "\n",
        "\n",
        "save_data(fX_train, fy_train, train=True)             # Train with labels\n",
        "save_data(fX_test, fy_test, train=False)              # Test  with labels\n",
        "save_data(fX_test, fy_test, train=False, label=False) # Test  no   labels\n",
        "\n",
        "################################################"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = fmodel.test('data_test.txt')\n",
        "print(\"Validation set accuracy:\", result[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EebDObJkiExA",
        "outputId": "48cfd2ec-09aa-4f95-e80b-442864fd6ffe"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set accuracy: 0.8312593330014932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fy_hat = mp.predict_set(fX_test)\n",
        "print(-1 in fy_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED7xYNrj0bNk",
        "outputId": "05a7217b-fbf8-4001-9b68-7d81be1bef43"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-GQvqOVo0xLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.8. Compute your performance metrics yourself and compare with sklearn. (1 point)"
      ],
      "metadata": {
        "id": "dqpnRWJ-ueE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.8.1. Personal Metrics"
      ],
      "metadata": {
        "id": "-2c_RRQjvI05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score_recoded(y_true, y_hat):\n",
        "  return np.mean(y_true == y_hat)\n",
        "\n",
        "\n",
        "fast_accuracy = accuracy_score_recoded(fy_test, fy_hat)\n",
        "\n",
        "print(f'Accuracy Score: {fast_accuracy}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDP3F1-qZvCO",
        "outputId": "bf8241fb-43c2-4de9-ec1a-c5359250690e"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.8040909090909091\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = score_per_lang(fy_test, fy_hat)"
      ],
      "metadata": {
        "id": "ZoQ9qO4I5ytJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f2eab7-e011-4ca4-fb8e-b55ae57fb819"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each language:\n",
            "Arabic    : 0.985000\n",
            "Chinese   : 0.005435\n",
            "Dutch     : 0.960591\n",
            "English   : 0.995169\n",
            "Estonian  : 0.830688\n",
            "French    : 0.990654\n",
            "Hindi     : 0.980488\n",
            "Indonesian: 0.903226\n",
            "Japanese  : 0.821596\n",
            "Korean    : 0.942708\n",
            "Latin     : 0.919192\n",
            "Persian   : 0.994949\n",
            "Portugese : 0.945545\n",
            "Pushto    : 0.000000\n",
            "Romanian  : 0.979275\n",
            "Russian   : 0.995074\n",
            "Spanish   : 0.977778\n",
            "Swedish   : 1.000000\n",
            "Tamil     : 0.465608\n",
            "Thai      : 0.100000\n",
            "Turkish   : 0.979167\n",
            "Urdu      : 0.883495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.8.2. sklearn Metrics"
      ],
      "metadata": {
        "id": "TTwdqtWtvMP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(fy_test, fy_hat)"
      ],
      "metadata": {
        "id": "5HHglOrFuMs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc18bc03-6159-49cc-8355-8fafa5f58f11"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8040909090909091"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Rotate two semantic spaces (23 points) – Not guided coding\n"
      ],
      "metadata": {
        "id": "YgCNRO0Tud6v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YSo7Nyj50yv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}