{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jr3WHRR0C9Il",
        "5TRcD4MeHFnt",
        "ObtV0t6W5Wqe",
        "mhS_Y6qgqW4Z",
        "hQg7l284V0oa",
        "edzctdyh0rDm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMwkByBnaE49"
      },
      "source": [
        "<p style=\"text-align:center;\"><img src=\"data:image/jpeg;base64,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\" alt=\"EPITA Lab 1\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TO NOTE \n",
        "Most of the answers on the notebook are complete. Although, __some answers are only fully redacted on the attached report__. "
      ],
      "metadata": {
        "id": "No8aEYwtFnev"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKtcL0CYn2n_"
      },
      "source": [
        "# Part 1. Keywords Extraction (14 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXcmrzodG1pt"
      },
      "source": [
        "## What is Keyword Extraction?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZWKLXCYG9NJ"
      },
      "source": [
        "Keyword extraction is defined as the task that automatically identifies a set of the terms that best describe the subject of document. This is an important method in information retrieval (IR) systems: keywords simplify and speed up the search. Keyword extraction can be used to reduce the dimensionality of text for further text analysis (text classification ot topic modeling). S.Art et al., for example, extracted keywords to measure patent similarity. Using keyword extraction, you can automatically index data, summarize a text, or generate tag clouds with the most representative keywords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O3FI910HETW"
      },
      "source": [
        "## How to extract the keywords?\n",
        "All keyword extraction algorithms include the following steps:\n",
        "\n",
        "* Candidate generation. Detection of possible candidate keywords from the text.\n",
        "* Property calculation. Computation of properties and statistics required for ranking.\n",
        "* Ranking. Computation of a score for each candidate keyword and sorting in descending order of all candidates. The top n candidates are finally selected as the n keywords representing the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD64EYyAHE5k"
      },
      "source": [
        "# all the imports \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "\n",
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr3WHRR0C9Il"
      },
      "source": [
        "## Goal.\n",
        "\n",
        "In the following, given a paper, we will extract the keywords associated to this paper. Each individual can have their own qualitative assessment of what is \"key\" word. However, we will try as much as possible to objectify the approach and quantify to what extent a keyword is indeed key to the paper in question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoUQe5Df4Bpr"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT3cUUST9QX6"
      },
      "source": [
        "%%capture\n",
        "! git clone https://github.com/MastafaF/ExtractKeywords.git"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duJTpCLQ9XJ5",
        "outputId": "66c2ac0c-32f4-41b8-f2ac-f7035b51163c"
      },
      "source": [
        "import os \n",
        "\n",
        "os.listdir(\"./ExtractKeywords\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', '.git', 'LICENSE', 'data.tar.gz', 'README.md']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfVjwTfE9dyP",
        "outputId": "e07131d8-0cf8-4c46-f34a-16bec0cf93db"
      },
      "source": [
        "# Extract data file \n",
        "\n",
        "! cd ExtractKeywords && tar -zxvf data.tar.gz data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/\n",
            "data/papers.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "CdRVtKw44C9p",
        "outputId": "cfdc1ce7-e281-4d53-f180-53395b7e00db"
      },
      "source": [
        "# load the dataset\n",
        "df = pd.read_csv('./ExtractKeywords/data/papers.csv')\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id  year                                              title event_type  \\\n",
              "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
              "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
              "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
              "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
              "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
              "\n",
              "                                            pdf_name          abstract  \\\n",
              "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
              "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
              "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
              "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
              "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
              "\n",
              "                                          paper_text  \n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f873fb4-53fa-4d0e-b4a5-67bf0724e576\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f873fb4-53fa-4d0e-b4a5-67bf0724e576')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f873fb4-53fa-4d0e-b4a5-67bf0724e576 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f873fb4-53fa-4d0e-b4a5-67bf0724e576');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2IElpuJ76o0"
      },
      "source": [
        "## Preprocessing data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRAj0JXjAWBo",
        "outputId": "0bc9a249-86e9-4c9d-a52a-40f955e0511e"
      },
      "source": [
        "# For the Lemmatizer \n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHC9ShM-IX7E"
      },
      "source": [
        "### Question 1.1: Preprocessing data in a meaningful way [code] (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWpI1OJk78Gc"
      },
      "source": [
        "import re\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "\n",
        "# Me \n",
        "from gensim.parsing import preprocess_string, strip_short, strip_tags, strip_numeric, strip_multiple_whitespaces, stem_text, strip_punctuation, remove_stopwords\n",
        "\n",
        "# Update stop words accordingly\n",
        "#my_stop_words = STOPWORDS.union(set(['mystopword1', 'mystopword2']))\n",
        "my_stop_words = STOPWORDS.union(set(['\\n', '~\\n\\n']))\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "##Creating a list of custom stopwords\n",
        "new_words = [\"fig\",\"figure\",\"image\",\"sample\",\"using\", \n",
        "             \"show\", \"result\", \"large\", \n",
        "             \"also\", \"one\", \"two\", \"three\", \n",
        "             \"four\", \"five\", \"seven\",\"eight\",\"nine\"]\n",
        "\n",
        "stop_words = STOPWORDS.union(set(new_words))\n",
        "\n",
        "def pre_process(text):\n",
        "  # ------------------\n",
        "  # Write your implementation here.\n",
        "\n",
        "  CUSTOM_FILTERS = [\n",
        "    lambda s: s.lower(),\n",
        "    lambda s: re.sub(r'\\s+\\w{1}\\s+', ' ', s),\n",
        "    strip_tags,\n",
        "    strip_numeric,\n",
        "    strip_punctuation, \n",
        "    strip_multiple_whitespaces,\n",
        "    strip_short,\n",
        "    #remove_stopwords, # Removes all English generic stopwords\n",
        "  ]\n",
        "\n",
        "  text = preprocess_string(text, CUSTOM_FILTERS)\n",
        "\n",
        "  lemmatized_text = []\n",
        "  wnl = WordNetLemmatizer()\n",
        "  for word in text:\n",
        "    lemmatized_text.append(wnl.lemmatize(word))\n",
        "\n",
        "  text_wo_stopwords = [word for word in lemmatized_text if not word in stop_words]\n",
        "  final_text = ' '.join(text_wo_stopwords)\n",
        "  \n",
        "  return final_text\n",
        "\n",
        "  # ------------------"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZFsz9JX_9I0",
        "outputId": "5e004bc9-b9f9-4314-ecb6-e8b186946e69"
      },
      "source": [
        "%%time\n",
        "df['preproc_text'] = df['paper_text'].apply(pre_process)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 12s, sys: 439 ms, total: 2min 13s\n",
            "Wall time: 2min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "_3ADgBBsAHhg",
        "outputId": "6857908c-542d-45f5-d4ec-c18abe6ac2b4"
      },
      "source": [
        "# Visualizing data \n",
        "HTML(pd.DataFrame(df.loc[0, [\"preproc_text\"]]).to_html())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>preproc_text</th>\n",
              "      <td>self organization associative database application hisashi suzuki suguru arimoto osaka university toyonaka osaka japan abstract efficient method self organizing associative database proposed application robot eyesight proposed database associate input output half discussion algorithm self organization proposed aspect hardware produce new style neural network half applicability handwritten letter recognition autonomous mobile robot demonstrated introduction let mapping given finite infinite set finite infinite set learning machine observes set pair sampled randomly mean cartesian product computes estimate small estimation error measure usually faster decrease estimation error increase number better learning machine expression performance incomplete lack consideration candidate assumed preliminarily good learning machine clarify conception let discus type learning machine let advance understanding self organization associative database parameter type ordinary type learning machine assumes equation relating parameter indefinite structure equivalent define implicitly set candidate subset mapping computes value parameter based observed type parameter type learning machine defined approach number increase alternative case estimation error remains eternally problem designing learning machine return proper structure sense hand assumed structure demanded compact possible achieve fast learning word number parameter small parameter uniquely determined observed demand proper contradicts compact consequently parameter type better compactness assumed structure proper better learning machine elementary conception design learning machine universality ordinary neural network suppose sufficient knowledge given unknown case comparatively easy proper compact structure alternative case difficult possible solution compactness assume almighty structure cover combination orthogonal base infinite dimension structure neural network approximation obtained truncating finitely dimension implementation american institute physic main topic designing neural network establish desirable structure work includes developing practical procedure compute value coefficient observed discussion flourishing efficient method proposed recently hardware unit computing coefficient parallel speed sold anza mark iii odyssey neural network exists danger error remaining eternally estimating precisely speaking suppose combination base finite number define structure essentially word suppose located near case estimation error negligible distant estimation error negligible research report following situation appears complex estimation error converges value number increase decrease hardly dimension heighten property considerable defect neural network recursi type recursive type founded methodology learning follows initial stage set instead notation candidate equal set mapping observing reduced observing second reduced candidate set gradually small observation proceeds observing write likelihood estimation selected contrarily parameter type recursive type guarantee surely approach number increase recursive type observes rewrite value correlated type ha architecture composed rule rewriting free memory space architecture form naturally kind database build management data self organizing way database differs ordinary following sense doe record observed computes estimation database associative database subject constructing associative database establish rule rewri ting purpose adap measure called dissimilari dissimilari mean mapping real necessarily defined single formula definable example collection rule written form dissimilarity defines structure locally knowledge imperfect flect heuristic way contrarily neural network possible accelerate speed learning establishing especially easily simple process analogically information like human application paper recursive type strongly effectiveness denote sequence observed simplest construction associative database observing follows algorithm initial stage let set let equal min furthermore add produce version improved economize memory follows algorithm initial stage let composed arbitrary element let lex equal min furthermore let add produce construction approach increase computation time grows proportionally size second subject constructing associative database addressing rule employ economize computation time subsequent chapter construction associative database purpose proposed manages data form binary tree self organization associative database given sequence algorithm constructing associative database follows algorithm step initialization let root root variable assigned respective node memorize data furthermore let step increase reset pointer root repeat following arrives terminal node leaf notation nand let mean descendant node let step display yin related information yin step establish new descendant node secondly let yin yin yin finally step loop step stopped time continued suppose gate element artificial synapsis play role branching prepared obtain new style neural network gate element randomly connected algorithm letter recognition recen tly vertical slitting method recognizing typographic english letter elastic matching method recognizing hand written discrete english letter global training fuzzy logic search method recognizing chinese character written square style published self organization associative database realizes recognition handwritten continuous english letter nov dwlo source document loo windowing number nualber sampl experiment scanner document letter recognizer parallelogram window cover maximal letter process sequence letter shifting window recognizer scan word slant direction place window left vicinity black point detected window catch letter succeeding letter recognition head letter performed end position boundary line letter known starting scanning boundary repeating operation recognizer accomplishes recursively task major problem come identifying head letter window considering define following regard window define accordingly denote black point left area boundary window project window measure euclidean distance black point closest let summation black point divided number regard couple reading position boundary define accordingly operator teach recognizer interaction relation window reading boundary algorithm precisely recalled reading incorrect operator teach correct reading console boundary position incorrect teach correct position mouse partially document experiment change number node recognition rate defined relative frequency correct answer past trial speciiications window height dot width dot slant angular deg example level tree distributed time recognition rate converged experimentally recognition rate converges case rare case doe attain distinguishable excessive lluctuation writing consistency relation assured like number node increase endlessly clever stop learning recognition rate attains upper limit improve recognition rate consider spelling word future subject obstacle avoiding movement camera type autonomous mobile robot reported flourishingly author belongs category mathematical methodology solve usually problem obstacle avoiding movement cost minimization problem cost criterion established artificially contrarily self organization associative database reproduces faithfully cost criterion operator motion robot learning natural length width height robot weight visual angle camera deg robot ha following factor motion turn le deg advance le control speed le experiment wa passageway wid inside building author laboratory exist experimental intention arrange box smoking stand gas cylinder stool handcart passage way random let robot camera recall similar trace route preliminarily recorded purpose define following let camera face deg downward process low pas filter scanning vertically filtered search point luminance change excessively bstitu point white point black obstacle exists robot white area free area robot regard binary dot processed define accordingly let number black point exclusive regard obtained drawing route define accordingly robot superimposes current camera route recalled inquires operator instruction operator judge subjectively suggested route appropriate negative answer draw desirable route mouse teach new robot opera tion defines implicitly sequence reflecting cost criterion operator iibube roan stationary uni configuration autonomous mobile robot north rmbi unit robot roan experimental environment wall camera preprocessing preprocessing course suggest ion search processing obstacle avoiding movement processing position identification define satisfaction rate relative frequency acceptable suggestion route past trial typical experiment change satisfaction rate showed similar tendency attains time notice rest doe mean directly percentage collision practice prevent collision adopting supplementary measure time number node wa level tree distributed proposed method reflects delicately character operator example robot trained operator slowly space obstacle trained operator brush quickly obstacle fact hint method printing character machine position identification robot identify position recalling similar landscape position data camera purpose principle suffices regard camera position data respectively memory capacity finite actual compu ters compress camera slight loss information compression admittable long precision position identification acceptable area major problem come suitable compression method experimental environment jut passageway interval section adjacent jut ha door robot identifies roughly surrounding landscape section place temporarily triangular surveying technique exact measure necessary realize task define following turn camera panorama deg scanning horizontally center line substitute point luminance excessively change black point white regard binary dot line processed define accordingly project black point measure euclidean distance black point closest let summation similarly calculate exchanging role denoting number respectively nand define regard positive integer labeled section define accordingly learning mode robot check exactly position counter reset periodically operator robot run arbitrarily passageway area learns relation landscape position data position identification area achieved crossing plural database task automatic excepting periodic reset counter kind learning teacher define identification rate relative frequency correct recall position data past trial typical example converged time time number level wa level oftree distributed identification failure rejected considering trajectory pro blem arises practical use order improve identification rate compression ratio camera loosened possibility depends improvement hardware future example actual motion robot based database obstacle avoiding movement position identification example corresponds case moving time interval frame sec actual motion robot conclusion method self organizing associative database wa proposed application robot eyesight machine decomposes global structure unknown set local structure known learns universally input output response framework problem implies wide application area example shown paper defect algorithm self organization tree balanced subclass structure subject imposed widen class probable solution abolish addressing rule depending directly value instead establish rule depending distribution function value investigation reference hopfield tank computing neural circuit model science rumelhart learning representation propagating error nature hull hypothesis generation computational model visual word recognition ieee expert fall kurtzberg feature analysis symbol recognition elastic matching ibm develop wang suen tree classifier heuristic search global training ieee trans pattern anal mach intell pami brook self calibration motion stereo vision mobile robot int symp robotics research goto stentz cmu mobile robot navigation ieee int conf robotics automation madarasz design autonomous vehicle disabled ieee jour robotics automation triendl kriegman stereo vision navigation building ieee int conf robotics automation turk video road following autonomous land vehicle ieee int conf robotics automation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLS9mbe8B4UY"
      },
      "source": [
        "## 0. Raw counts\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WY9c6iwI0Lv"
      },
      "source": [
        "### Question 1.2: Build a top N words based on occurence [code] (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izLhCAH5B-jy"
      },
      "source": [
        "\"\"\"\n",
        "Idea: \n",
        "\n",
        "0. Split with spacy OR nltk \n",
        "\n",
        "1. Counter \n",
        "\n",
        "2. Surface top 10 \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def get_counter(txt_preproc, N=10): \n",
        "\n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    \n",
        "    tokens = nltk.word_tokenize(txt_preproc)\n",
        "    count_tokens = nltk.FreqDist(tokens)\n",
        "\n",
        "    count_tokens_list = list(dict(count_tokens).items())\n",
        "    count_tokens_list.sort(key=lambda ele: ele[1], reverse=True)\n",
        "\n",
        "    return count_tokens_list[:10]\n",
        "    # ------------------\n",
        "\n",
        "df[\"Top N\"] = df[\"preproc_text\"].apply(get_counter)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Xt7vPHWTaDCX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "983a1cd8-58a8-4c20-e300-f94d8c7d2cb8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  year                                              title  \\\n",
              "0        1  1987  Self-Organization of Associative Database and ...   \n",
              "1       10  1987  A Mean Field Theory of Layer IV of Visual Cort...   \n",
              "2      100  1988  Storing Covariance by the Associative Long-Ter...   \n",
              "3     1000  1994  Bayesian Query Construction for Neural Network...   \n",
              "4     1001  1994  Neural Network Ensembles, Cross Validation, an...   \n",
              "...    ...   ...                                                ...   \n",
              "7236   994  1994                Single Transistor Learning Synapses   \n",
              "7237   996  1994  Bias, Variance and the Combination of Least Sq...   \n",
              "7238   997  1994          A Real Time Clustering CMOS Neural Engine   \n",
              "7239   998  1994  Learning direction in global motion: two class...   \n",
              "7240   999  1994  Correlation and Interpolation Networks for Rea...   \n",
              "\n",
              "     event_type                                           pdf_name  \\\n",
              "0           NaN  1-self-organization-of-associative-database-an...   \n",
              "1           NaN  10-a-mean-field-theory-of-layer-iv-of-visual-c...   \n",
              "2           NaN  100-storing-covariance-by-the-associative-long...   \n",
              "3           NaN  1000-bayesian-query-construction-for-neural-ne...   \n",
              "4           NaN  1001-neural-network-ensembles-cross-validation...   \n",
              "...         ...                                                ...   \n",
              "7236        NaN        994-single-transistor-learning-synapses.pdf   \n",
              "7237        NaN  996-bias-variance-and-the-combination-of-least...   \n",
              "7238        NaN  997-a-real-time-clustering-cmos-neural-engine.pdf   \n",
              "7239        NaN  998-learning-direction-in-global-motion-two-cl...   \n",
              "7240        NaN  999-correlation-and-interpolation-networks-for...   \n",
              "\n",
              "              abstract                                         paper_text  \\\n",
              "0     Abstract Missing  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...   \n",
              "1     Abstract Missing  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...   \n",
              "2     Abstract Missing  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...   \n",
              "3     Abstract Missing  Bayesian Query Construction for Neural\\nNetwor...   \n",
              "4     Abstract Missing  Neural Network Ensembles, Cross\\nValidation, a...   \n",
              "...                ...                                                ...   \n",
              "7236  Abstract Missing  Single Transistor Learning Synapses\\n\\nPaul Ha...   \n",
              "7237  Abstract Missing  Bias, Variance and the Combination of\\nLeast S...   \n",
              "7238  Abstract Missing  A Real Time Clustering CMOS\\nNeural Engine\\nT....   \n",
              "7239  Abstract Missing  Learning direction in global motion: two\\nclas...   \n",
              "7240  Abstract Missing  Correlation and Interpolation Networks for\\nRe...   \n",
              "\n",
              "                                           preproc_text  \\\n",
              "0     self organization associative database applica...   \n",
              "1     mean field theory layer visual cortex applicat...   \n",
              "2     storing covariance associative long term poten...   \n",
              "3     bayesian query construction neural network mod...   \n",
              "4     neural network ensemble cross validation activ...   \n",
              "...                                                 ...   \n",
              "7236  single transistor learning synapsis paul hasle...   \n",
              "7237  bias variance combination square estimator ron...   \n",
              "7238  real time clustering cmos neural engine serran...   \n",
              "7239  learning direction global motion class psychop...   \n",
              "7240  correlation interpolation network real time ex...   \n",
              "\n",
              "                                                  Top N  \n",
              "0     [(robot, 23), (database, 19), (let, 18), (lear...  \n",
              "1     [(cell, 51), (network, 42), (cortical, 32), (s...  \n",
              "2     [(input, 58), (weak, 42), (synaptic, 36), (ass...  \n",
              "3     [(loss, 42), (query, 25), (model, 23), (functi...  \n",
              "4     [(ensemble, 56), (network, 52), (error, 51), (...  \n",
              "...                                                 ...  \n",
              "7236  [(gate, 44), (weight, 42), (synapse, 42), (cur...  \n",
              "7237  [(estimator, 37), (variance, 29), (bias, 25), ...  \n",
              "7238  [(current, 35), (chip, 21), (input, 19), (patt...  \n",
              "7239  [(learning, 69), (motion, 42), (direction, 32)...  \n",
              "7240  [(model, 54), (view, 47), (expression, 46), (f...  \n",
              "\n",
              "[7241 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2391330-277f-4e2e-a325-faf03a560b4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "      <th>preproc_text</th>\n",
              "      <th>Top N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "      <td>self organization associative database applica...</td>\n",
              "      <td>[(robot, 23), (database, 19), (let, 18), (lear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "      <td>mean field theory layer visual cortex applicat...</td>\n",
              "      <td>[(cell, 51), (network, 42), (cortical, 32), (s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "      <td>storing covariance associative long term poten...</td>\n",
              "      <td>[(input, 58), (weak, 42), (synaptic, 36), (ass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "      <td>bayesian query construction neural network mod...</td>\n",
              "      <td>[(loss, 42), (query, 25), (model, 23), (functi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "      <td>neural network ensemble cross validation activ...</td>\n",
              "      <td>[(ensemble, 56), (network, 52), (error, 51), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7236</th>\n",
              "      <td>994</td>\n",
              "      <td>1994</td>\n",
              "      <td>Single Transistor Learning Synapses</td>\n",
              "      <td>NaN</td>\n",
              "      <td>994-single-transistor-learning-synapses.pdf</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Single Transistor Learning Synapses\\n\\nPaul Ha...</td>\n",
              "      <td>single transistor learning synapsis paul hasle...</td>\n",
              "      <td>[(gate, 44), (weight, 42), (synapse, 42), (cur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7237</th>\n",
              "      <td>996</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bias, Variance and the Combination of Least Sq...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>996-bias-variance-and-the-combination-of-least...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bias, Variance and the Combination of\\nLeast S...</td>\n",
              "      <td>bias variance combination square estimator ron...</td>\n",
              "      <td>[(estimator, 37), (variance, 29), (bias, 25), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7238</th>\n",
              "      <td>997</td>\n",
              "      <td>1994</td>\n",
              "      <td>A Real Time Clustering CMOS Neural Engine</td>\n",
              "      <td>NaN</td>\n",
              "      <td>997-a-real-time-clustering-cmos-neural-engine.pdf</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>A Real Time Clustering CMOS\\nNeural Engine\\nT....</td>\n",
              "      <td>real time clustering cmos neural engine serran...</td>\n",
              "      <td>[(current, 35), (chip, 21), (input, 19), (patt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7239</th>\n",
              "      <td>998</td>\n",
              "      <td>1994</td>\n",
              "      <td>Learning direction in global motion: two class...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>998-learning-direction-in-global-motion-two-cl...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Learning direction in global motion: two\\nclas...</td>\n",
              "      <td>learning direction global motion class psychop...</td>\n",
              "      <td>[(learning, 69), (motion, 42), (direction, 32)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7240</th>\n",
              "      <td>999</td>\n",
              "      <td>1994</td>\n",
              "      <td>Correlation and Interpolation Networks for Rea...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>999-correlation-and-interpolation-networks-for...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Correlation and Interpolation Networks for\\nRe...</td>\n",
              "      <td>correlation interpolation network real time ex...</td>\n",
              "      <td>[(model, 54), (view, 47), (expression, 46), (f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7241 rows  9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2391330-277f-4e2e-a325-faf03a560b4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2391330-277f-4e2e-a325-faf03a560b4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2391330-277f-4e2e-a325-faf03a560b4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-J0RHMMFW6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863d791a-a066-46e1-e9be-619f37a5c103"
      },
      "source": [
        "df.loc[2, \"Top N\"]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('input', 58),\n",
              " ('weak', 42),\n",
              " ('synaptic', 36),\n",
              " ('associative', 35),\n",
              " ('ltp', 30),\n",
              " ('strong', 26),\n",
              " ('phase', 26),\n",
              " ('long', 24),\n",
              " ('stimulus', 23),\n",
              " ('hippocampus', 22)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK7YbNCyJaqk"
      },
      "source": [
        "### Question 1.3: What are some of the limits of raw counts? How could we improve the approach through preprocessing? [written] (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eewWd_TjJlt-"
      },
      "source": [
        "Counting the number of times each word appears in a document is a very simple approach to text processing, but it has several limitations. First, it does not account for the order of the words in the document, so two documents with the same words in different orders will be considered to be identical. Second, it does not account for different forms of the same word, so \"fish\" and \"fishing\" will be considered to be different words. Third, raw counts could be very low for rare words, and this could also skew the similarity results. Finally, it does not account for the context of the words in the document, so two documents with the same words but different meanings will be considered to be identical.\n",
        "\n",
        "One way to improve the approach is to use a technique called \"stemming\" to reduce each word to its base form before counting. This will account for different forms of the same word. Further, we could use a weighting scheme such as tf-idf. This will palliate rare words getting low scores and skewing the results. Another way to improve the approach is to use a technique called \"stopword removal\" to remove common words such as \"a\", \"the\", and \"of\" before counting. This will account for the context of the words in the document.\n",
        "\n",
        "We've implemented in question 1.1 both the removal of stop words and the lemmatization which is the process of grouping together the different forms of a word so they can be analyzed as a single item."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wao4NivXGPIM"
      },
      "source": [
        "## 1. TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TRcD4MeHFnt"
      },
      "source": [
        "### Introduction.\n",
        "\n",
        "TF-IDF stands for Text Frequency Inverse Document Frequency. The importance of each word increases proportionally to the number of times a word appears in the document (Text Frequency - TF) but is offset by the frequency of the word in the corpus (Inverse Document Frequency - IDF). Using the tf-idf weighting scheme, the keywords are the words with the higherst TF-IDF score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOZe8obbHm-Q"
      },
      "source": [
        "### CountVectorizer to create a vocabulary and generate word counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pd54cOkGV_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb1973e9-5b12-4108-89c1-d35b6ee283ea"
      },
      "source": [
        "%%time\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "#create a vocabulary of words, \n",
        "cv=CountVectorizer(max_df=0.95,         # ignore words that appear in 95% of documents\n",
        "                   max_features=10000,  # the size of the vocabulary\n",
        "                   ngram_range=(1,3)    # vocabulary contains single words, bigrams, trigrams\n",
        "                  )\n",
        "\n",
        "\n",
        "word_count_vector=cv.fit_transform(df[\"preproc_text\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 12s, sys: 9 s, total: 2min 21s\n",
            "Wall time: 2min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fngZVCVGcG_",
        "outputId": "eea293d6-7e2c-4e5a-b85a-691b5ea44ca5"
      },
      "source": [
        "word_count_vector"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7241x10000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 5316905 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxV_evcXHuKp"
      },
      "source": [
        "### TfidfTransformer to Compute Inverse Document Frequency (IDF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCfwFzHCHzOY",
        "outputId": "0ec8b296-faf3-46dd-acbf-eeaa81106ba2"
      },
      "source": [
        "%%time\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,\n",
        "                                   use_idf=True)\n",
        "\n",
        "tfidf_transformer.fit(word_count_vector)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 21 ms, sys: 0 ns, total: 21 ms\n",
            "Wall time: 21 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer()"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd9hXGWJHzLy",
        "outputId": "6fe0e212-b0b2-4195-87d4-fb89d8b3e7a5"
      },
      "source": [
        "tfidf_transformer"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer()"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1wbWizrJ5CE"
      },
      "source": [
        "### Question 1.4: How can you find an optimal max_df? Why are we using a sparse matrix instead of a regular matrix? [written] (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EekhsGbKYoyv"
      },
      "source": [
        "The max_df parameter in a CountVectorizer indicates the maximum frequency of a word allowed in order to be included in the vocabulary. A higher max_df results in a smaller vocabulary.\n",
        "\n",
        "One way to find an optimal max_df is to iterate over different values and compare the results. Another way is to use a grid search to test a range of values and find the best one.\n",
        "\n",
        "There are a few reasons for using a sparse matrix with a CountVectorizer. First, a regular matrix requires a lot of memory, and a sparse matrix uses much less memory (because 0 values do not take up memory). Second, a sparse matrix can be created much faster than a regular matrix. Finally, a sparse matrix can be used with a much larger dataset than a regular matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2_9miFxKaU1",
        "outputId": "e528584c-0ce0-4d7d-c32f-1841698ab078"
      },
      "source": [
        "cv.transform([\" change number node recognition rate defined relative frequency\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x10000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 10 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "K2Vdn9NTMIxI",
        "outputId": "c73a9bfb-5577-41ee-9669-74a14439e658"
      },
      "source": [
        "# Visualizing data \n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "plt.spy(csr_matrix(cv.transform([\"change number node recognition rate defined relative frequency\"])))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7fc03f345610>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRI_AZtROxP0",
        "outputId": "c00dac94-aa72-4923-e918-7d22aec92505"
      },
      "source": [
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "#generate tf-idf for the given document\n",
        "tf_idf_vector=tfidf_transformer.transform(cv.transform([\"change number node recognition rate defined relative frequency\"]))\n",
        "\n",
        "#sort the tf-idf vectors by descending order of scores\n",
        "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "sorted_items"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(7360, 0.6332528462762741),\n",
              " (6110, 0.48592082711420476),\n",
              " (3282, 0.2823916239785495),\n",
              " (5971, 0.2677155552680803),\n",
              " (7348, 0.2262665323411533),\n",
              " (7490, 0.2242783939550881),\n",
              " (1179, 0.1963759835498492),\n",
              " (7270, 0.17762842408345383),\n",
              " (2062, 0.15648471115689686),\n",
              " (6087, 0.12391506848540515)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxhq2LiEOxD3",
        "outputId": "22e938b1-5982-4390-acea-97007c474946"
      },
      "source": [
        "coo_matrix = tf_idf_vector.tocoo()\n",
        "#list(zip(coo_matrix.col, coo_matrix.data))\n",
        "coo_matrix"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 10 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4EwdqH_Gm0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a5d540-9a58-4642-c2cf-73ceb6a904ee"
      },
      "source": [
        "# get feature names\n",
        "feature_names=cv.get_feature_names()\n",
        "\n",
        "def get_keywords(txt, top_N=10):\n",
        "\n",
        "  # ------------------\n",
        "  # Write your implementation here.\n",
        "\n",
        "  # Get tf idf\n",
        "  count_vector = cv.transform([txt]) \n",
        "  tf_idf_vector = tfidf_transformer.transform(count_vector)\n",
        "\n",
        "  # get scores\n",
        "  scores = np.asarray(tf_idf_vector.sum(axis=0)).ravel()\n",
        "  scores_rounded = list(np.around(scores, 3))\n",
        "\n",
        "  # Get keyword scores\n",
        "  keyword_score =  list(zip(feature_names, scores_rounded))\n",
        "  keyword_score.sort(key=lambda element: element[1], reverse=True)\n",
        "  sorted_keyword_score = keyword_score[:top_N]\n",
        "  # ------------------\n",
        "  \n",
        "  return sorted_keyword_score"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahvTo9gjSWCW",
        "outputId": "0538143b-2e55-43fa-f64d-cf3bb555c5ab"
      },
      "source": [
        "get_keywords(txt=\"change number node recognition rate defined relative frequency\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('recognition rate', 0.633),\n",
              " ('number node', 0.486),\n",
              " ('frequency', 0.282),\n",
              " ('node', 0.268),\n",
              " ('recognition', 0.226),\n",
              " ('relative', 0.224),\n",
              " ('change', 0.196),\n",
              " ('rate', 0.178),\n",
              " ('defined', 0.156),\n",
              " ('number', 0.124)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9hzsg0CUQZ_"
      },
      "source": [
        "### Compare Raw Counts to Tf-IDF approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot6GLVIiUPqj"
      },
      "source": [
        "df[\"Top_N_TF-IDF\"] = df[\"preproc_text\"].apply(get_keywords, top_N=10)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4sydV20UjvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd8355a-5ac2-460f-a9a6-ed541a8dac2e"
      },
      "source": [
        "comparator = list(df[['Top N', 'Top_N_TF-IDF']].iloc[1].values)\n",
        "\n",
        "print(comparator[0])\n",
        "print(comparator[1])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('cell', 51), ('network', 42), ('cortical', 32), ('synapsis', 26), ('activity', 19), ('mean', 17), ('field', 17), ('eye', 17), ('layer', 13), ('single', 12)]\n",
            "[('cell', 0.456), ('cortical', 0.365), ('synapsis', 0.342), ('mean field', 0.223), ('eye', 0.211), ('network', 0.197), ('lgn', 0.175), ('activity', 0.17), ('mean field approximation', 0.147), ('field approximation', 0.146)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkDLV8yILNNS"
      },
      "source": [
        "### Question 1.5: Find an example where there is a noticeable difference between tf-idf and raw counts? Justify which method you would choose yourself (there is no bad and good answer here) [written] (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comparator = list(df[['Top N', 'Top_N_TF-IDF']].iloc[4].values)\n",
        "\n",
        "print(f'Raw counts: {comparator[0]}')\n",
        "print(f'tf-idf : {comparator[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFpjlzCP7D7W",
        "outputId": "c10b336d-c8fb-4be7-f3ca-b418c4467908"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw counts: [('ensemble', 56), ('network', 52), ('error', 51), ('generalization', 40), ('set', 27), ('ambiguity', 26), ('weight', 26), ('learning', 22), ('training', 22), ('example', 22)]\n",
            "tf-idf : [('ensemble', 0.525), ('generalization error', 0.356), ('ambiguity', 0.302), ('generalization', 0.232), ('network', 0.21), ('error', 0.203), ('active learning', 0.195), ('cross validation', 0.14), ('active', 0.136), ('individual', 0.125)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see in this example (text 4) that the general words look similar. Although, upon inspection we realise that the words from `Raw counts` lack context and meaning for example we see `learning` as a keyword but what learning are we talking about machine learning, active learning, ...? On the other end, tf-idf is able to classify `active learning` as one of its keywords which actually gives more information on the contents of the article! We can further see those differences with `error` and `generalization error`.\n",
        "\n",
        "Overall at least on this example, tf-idf seems to give way more context than raw counts and seems to be a much better choice in this particular case.\n",
        "\n",
        "Although we can generalise this observersation as: raw counts are the number of times a term appears in a document which appear relatively naive. tf-idf is a measure of how important a term is to a document in a collection of documents which seems to be a more complete overview. It is the product of the term's raw count and a document frequency weight. tf-idf is thus better because it takes into account how often a term appears in a document."
      ],
      "metadata": {
        "id": "Rr2OVkoZ7a__"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mes_RnLNVXBX"
      },
      "source": [
        "## 1.6. KeyBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7iWThDYXlJY"
      },
      "source": [
        "### 1.6.0. Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Ji149nXmUU"
      },
      "source": [
        "%%capture\n",
        "pip install keybert"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-kXWUGKXqIB"
      },
      "source": [
        "%%capture\n",
        "from keybert import KeyBERT\n",
        "\n",
        "doc = \"\"\"\n",
        "         Supervised learning is the machine learning task of learning a function that\n",
        "         maps an input to an output based on example input-output pairs. It infers a\n",
        "         function from labeled training data consisting of a set of training examples.\n",
        "         In supervised learning, each example is a pair consisting of an input object\n",
        "         (typically a vector) and a desired output value (also called the supervisory signal). \n",
        "         A supervised learning algorithm analyzes the training data and produces an inferred function, \n",
        "         which can be used for mapping new examples. An optimal scenario will allow for the \n",
        "         algorithm to correctly determine the class labels for unseen instances. This requires \n",
        "         the learning algorithm to generalize from the training data to unseen situations in a \n",
        "         'reasonable' way (see inductive bias).\n",
        "      \"\"\"\n",
        "kw_model = KeyBERT()\n",
        "keywords = kw_model.extract_keywords(doc)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNrYae2jYDqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d26de5-68a5-4e7b-e468-3afa11c00344"
      },
      "source": [
        "keywords"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('supervised', 0.6676),\n",
              " ('labeled', 0.4896),\n",
              " ('learning', 0.4813),\n",
              " ('training', 0.4134),\n",
              " ('labels', 0.3947)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJs_f30AYmKN"
      },
      "source": [
        "### Question 1.6.1. Apply KeyBERT to the a sample of the dataset [code] (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GisGAL0pIDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "461b5b5d-ea91-43b0-d9ca-5a7f8475b2df"
      },
      "source": [
        "df_ = df.sample(100, random_state=42)\n",
        "df_.sample(1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  year                                              title  \\\n",
              "2540  3303  2007  Progressive mixture rules are deviation subopt...   \n",
              "\n",
              "     event_type                                           pdf_name  \\\n",
              "2540        NaN  3303-progressive-mixture-rules-are-deviation-s...   \n",
              "\n",
              "                                               abstract  \\\n",
              "2540  We consider the learning task consisting in pr...   \n",
              "\n",
              "                                             paper_text  \\\n",
              "2540  Progressive mixture rules are deviation subopt...   \n",
              "\n",
              "                                           preproc_text  \\\n",
              "2540  progressive mixture rule deviation suboptimal ...   \n",
              "\n",
              "                                                  Top N  \\\n",
              "2540  [(function, 39), (log, 38), (prediction, 30), ...   \n",
              "\n",
              "                                           Top_N_TF-IDF  \n",
              "2540  [(mixture, 0.266), (log, 0.24), (indirect, 0.2...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-864d4086-e527-436d-a635-5a5fb59d6ee5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "      <th>preproc_text</th>\n",
              "      <th>Top N</th>\n",
              "      <th>Top_N_TF-IDF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2540</th>\n",
              "      <td>3303</td>\n",
              "      <td>2007</td>\n",
              "      <td>Progressive mixture rules are deviation subopt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3303-progressive-mixture-rules-are-deviation-s...</td>\n",
              "      <td>We consider the learning task consisting in pr...</td>\n",
              "      <td>Progressive mixture rules are deviation subopt...</td>\n",
              "      <td>progressive mixture rule deviation suboptimal ...</td>\n",
              "      <td>[(function, 39), (log, 38), (prediction, 30), ...</td>\n",
              "      <td>[(mixture, 0.266), (log, 0.24), (indirect, 0.2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-864d4086-e527-436d-a635-5a5fb59d6ee5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-864d4086-e527-436d-a635-5a5fb59d6ee5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-864d4086-e527-436d-a635-5a5fb59d6ee5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN3Dlu11YwLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a85dfd-c704-4b7d-a024-fb7bb9f59377"
      },
      "source": [
        "%%time\n",
        "%%capture\n",
        "\n",
        "# ------------------\n",
        "# Write your implementation here.\n",
        "\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "def get_key_bert_keywords(text):\n",
        "  keywords = kw_model.extract_keywords(text)\n",
        "\n",
        "  return keywords\n",
        "\n",
        "df_[\"Top_N_KeyBERT_1\"] = df_[\"preproc_text\"].apply(get_key_bert_keywords)\n",
        "# ------------------"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 6s, sys: 11.4 s, total: 3min 18s\n",
            "Wall time: 3min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "ycwvmMoS4i_6",
        "outputId": "cdbcdf9c-c97b-48b5-c35f-de7433463576"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  year                                              title  \\\n",
              "509   1466  1997  Independent Component Analysis for Identificat...   \n",
              "2576  3336  2007  Near-Maximum Entropy Models for Binary Neural ...   \n",
              "6362  6755  2017  Nearest-Neighbor Sample Compression: Efficienc...   \n",
              "6173  6584  2016  Efficient High-Order Interaction-Aware Feature...   \n",
              "6552  6927  2017  Multi-output Polynomial Networks and Factoriza...   \n",
              "...    ...   ...                                                ...   \n",
              "5909  6346  2016               Maximal Sparsity with Deep Networks?   \n",
              "6175  6586  2016              Edge-exchangeable graphs and sparsity   \n",
              "3966  4590  2012           Kernel Latent SVM for Visual Recognition   \n",
              "3592  4252  2011  Prismatic Algorithm for Discrete D.C. Programm...   \n",
              "742   1679  1999  Modeling High-Dimensional Discrete Data with M...   \n",
              "\n",
              "     event_type                                           pdf_name  \\\n",
              "509         NaN  1466-independent-component-analysis-for-identi...   \n",
              "2576        NaN  3336-near-maximum-entropy-models-for-binary-ne...   \n",
              "6362     Poster  6755-nearest-neighbor-sample-compression-effic...   \n",
              "6173     Poster  6584-efficient-high-order-interaction-aware-fe...   \n",
              "6552     Poster  6927-multi-output-polynomial-networks-and-fact...   \n",
              "...         ...                                                ...   \n",
              "5909     Poster       6346-maximal-sparsity-with-deep-networks.pdf   \n",
              "6175     Poster     6586-edge-exchangeable-graphs-and-sparsity.pdf   \n",
              "3966        NaN  4590-kernel-latent-svm-for-visual-recognition.pdf   \n",
              "3592        NaN  4252-prismatic-algorithm-for-discrete-dc-progr...   \n",
              "742         NaN  1679-modeling-high-dimensional-discrete-data-w...   \n",
              "\n",
              "                                               abstract  \\\n",
              "509                                    Abstract Missing   \n",
              "2576                                   Abstract Missing   \n",
              "6362  We examine the Bayes-consistency of a recently...   \n",
              "6173  This study introduces a novel feature selectio...   \n",
              "6552  Factorization machines and polynomial networks...   \n",
              "...                                                 ...   \n",
              "5909  The iterations of many sparse estimation algor...   \n",
              "6175  Many popular network models rely on the assump...   \n",
              "3966  Latent SVMs (LSVMs) are a class of powerful to...   \n",
              "3592  In this paper, we propose the first exact algo...   \n",
              "742                                    Abstract Missing   \n",
              "\n",
              "                                             paper_text  \\\n",
              "509   Independent Component Analysis for\\nidentifica...   \n",
              "2576  Near-Maximum Entropy Models for Binary\\nNeural...   \n",
              "6362  Nearest-Neighbor Sample Compression:\\nEfficien...   \n",
              "6173  Efficient High-Order Interaction-Aware Feature...   \n",
              "6552  Multi-output Polynomial Networks\\nand Factoriz...   \n",
              "...                                                 ...   \n",
              "5909  Maximal Sparsity with Deep Networks?\\n\\nBo Xin...   \n",
              "6175  Edge-exchangeable graphs and sparsity\\n\\nDiana...   \n",
              "3966  Kernel Latent SVM for Visual Recognition\\n\\nYa...   \n",
              "3592  Prismatic Algorithm for Discrete D.C. Programm...   \n",
              "742   Modeling High-Dimensional Discrete Data with\\n...   \n",
              "\n",
              "                                           preproc_text  \\\n",
              "509   independent component analysis identification ...   \n",
              "2576  near maximum entropy model binary neural repre...   \n",
              "6362  nearest neighbor compression efficiency consis...   \n",
              "6173  efficient high order interaction aware feature...   \n",
              "6552  multi output polynomial network factorization ...   \n",
              "...                                                 ...   \n",
              "5909  maximal sparsity deep network xin yizhou wang ...   \n",
              "6175  edge exchangeable graph sparsity diana cai dep...   \n",
              "3966  kernel latent svm visual recognition yang wang...   \n",
              "3592  prismatic algorithm discrete programming probl...   \n",
              "742   modeling high dimensional discrete data multi ...   \n",
              "\n",
              "                                                  Top N  \\\n",
              "509   [(artifact, 38), (independent, 32), (signal, 3...   \n",
              "2576  [(model, 91), (distribution, 47), (entropy, 42...   \n",
              "6362  [(bayes, 53), (compression, 50), (algorithm, 5...   \n",
              "6173  [(feature, 137), (score, 43), (method, 42), (s...   \n",
              "6552  [(output, 46), (basis, 37), (vector, 36), (alg...   \n",
              "...                                                 ...   \n",
              "5909  [(network, 35), (sparse, 32), (algorithm, 22),...   \n",
              "6175  [(graph, 136), (edge, 107), (vertex, 63), (seq...   \n",
              "3966  [(latent, 77), (kernel, 63), (variable, 52), (...   \n",
              "3592  [(problem, 51), (algorithm, 45), (function, 36...   \n",
              "742   [(model, 62), (variable, 51), (network, 41), (...   \n",
              "\n",
              "                                           Top_N_TF-IDF  \\\n",
              "509   [(artifact, 0.565), (meg, 0.378), (independent...   \n",
              "2576  [(entropy, 0.314), (ising model, 0.309), (isin...   \n",
              "6362  [(compression, 0.404), (bayes, 0.316), (metric...   \n",
              "6173  [(feature, 0.482), (team, 0.276), (score, 0.25...   \n",
              "6552  [(basis vector, 0.376), (basis, 0.233), (outpu...   \n",
              "...                                                 ...   \n",
              "5909  [(sparse, 0.244), (dictionary, 0.21), (deep, 0...   \n",
              "6175  [(graph, 0.508), (edge, 0.451), (exchangeable,...   \n",
              "3966  [(latent, 0.435), (latent variable, 0.315), (k...   \n",
              "3592  [(submodular, 0.447), (programming problem, 0....   \n",
              "742   [(variable, 0.255), (model, 0.246), (network, ...   \n",
              "\n",
              "                                        Top_N_KeyBERT_1  \n",
              "509   [(neuromagnetometer, 0.4323), (magnetoencephal...  \n",
              "2576  [(entropy, 0.335), (neurobiology, 0.2898), (ne...  \n",
              "6362  [(classifier, 0.4025), (classification, 0.3953...  \n",
              "6173  [(feature, 0.3224), (classifier, 0.3149), (sel...  \n",
              "6552  [(svm, 0.3737), (svms, 0.3693), (classificatio...  \n",
              "...                                                 ...  \n",
              "5909  [(sparse, 0.4469), (sparseness, 0.4132), (thre...  \n",
              "6175  [(graphon, 0.5184), (adjacency, 0.4975), (grap...  \n",
              "3966  [(svms, 0.5638), (svm, 0.5597), (classifier, 0...  \n",
              "3592  [(programming, 0.3882), (algorithm, 0.3861), (...  \n",
              "742   [(modeling, 0.3247), (modelization, 0.3108), (...  \n",
              "\n",
              "[100 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1171b2ff-6e2a-4429-82dd-efbd16b16180\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "      <th>preproc_text</th>\n",
              "      <th>Top N</th>\n",
              "      <th>Top_N_TF-IDF</th>\n",
              "      <th>Top_N_KeyBERT_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>1466</td>\n",
              "      <td>1997</td>\n",
              "      <td>Independent Component Analysis for Identificat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1466-independent-component-analysis-for-identi...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Independent Component Analysis for\\nidentifica...</td>\n",
              "      <td>independent component analysis identification ...</td>\n",
              "      <td>[(artifact, 38), (independent, 32), (signal, 3...</td>\n",
              "      <td>[(artifact, 0.565), (meg, 0.378), (independent...</td>\n",
              "      <td>[(neuromagnetometer, 0.4323), (magnetoencephal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2576</th>\n",
              "      <td>3336</td>\n",
              "      <td>2007</td>\n",
              "      <td>Near-Maximum Entropy Models for Binary Neural ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3336-near-maximum-entropy-models-for-binary-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Near-Maximum Entropy Models for Binary\\nNeural...</td>\n",
              "      <td>near maximum entropy model binary neural repre...</td>\n",
              "      <td>[(model, 91), (distribution, 47), (entropy, 42...</td>\n",
              "      <td>[(entropy, 0.314), (ising model, 0.309), (isin...</td>\n",
              "      <td>[(entropy, 0.335), (neurobiology, 0.2898), (ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6362</th>\n",
              "      <td>6755</td>\n",
              "      <td>2017</td>\n",
              "      <td>Nearest-Neighbor Sample Compression: Efficienc...</td>\n",
              "      <td>Poster</td>\n",
              "      <td>6755-nearest-neighbor-sample-compression-effic...</td>\n",
              "      <td>We examine the Bayes-consistency of a recently...</td>\n",
              "      <td>Nearest-Neighbor Sample Compression:\\nEfficien...</td>\n",
              "      <td>nearest neighbor compression efficiency consis...</td>\n",
              "      <td>[(bayes, 53), (compression, 50), (algorithm, 5...</td>\n",
              "      <td>[(compression, 0.404), (bayes, 0.316), (metric...</td>\n",
              "      <td>[(classifier, 0.4025), (classification, 0.3953...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6173</th>\n",
              "      <td>6584</td>\n",
              "      <td>2016</td>\n",
              "      <td>Efficient High-Order Interaction-Aware Feature...</td>\n",
              "      <td>Poster</td>\n",
              "      <td>6584-efficient-high-order-interaction-aware-fe...</td>\n",
              "      <td>This study introduces a novel feature selectio...</td>\n",
              "      <td>Efficient High-Order Interaction-Aware Feature...</td>\n",
              "      <td>efficient high order interaction aware feature...</td>\n",
              "      <td>[(feature, 137), (score, 43), (method, 42), (s...</td>\n",
              "      <td>[(feature, 0.482), (team, 0.276), (score, 0.25...</td>\n",
              "      <td>[(feature, 0.3224), (classifier, 0.3149), (sel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6552</th>\n",
              "      <td>6927</td>\n",
              "      <td>2017</td>\n",
              "      <td>Multi-output Polynomial Networks and Factoriza...</td>\n",
              "      <td>Poster</td>\n",
              "      <td>6927-multi-output-polynomial-networks-and-fact...</td>\n",
              "      <td>Factorization machines and polynomial networks...</td>\n",
              "      <td>Multi-output Polynomial Networks\\nand Factoriz...</td>\n",
              "      <td>multi output polynomial network factorization ...</td>\n",
              "      <td>[(output, 46), (basis, 37), (vector, 36), (alg...</td>\n",
              "      <td>[(basis vector, 0.376), (basis, 0.233), (outpu...</td>\n",
              "      <td>[(svm, 0.3737), (svms, 0.3693), (classificatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5909</th>\n",
              "      <td>6346</td>\n",
              "      <td>2016</td>\n",
              "      <td>Maximal Sparsity with Deep Networks?</td>\n",
              "      <td>Poster</td>\n",
              "      <td>6346-maximal-sparsity-with-deep-networks.pdf</td>\n",
              "      <td>The iterations of many sparse estimation algor...</td>\n",
              "      <td>Maximal Sparsity with Deep Networks?\\n\\nBo Xin...</td>\n",
              "      <td>maximal sparsity deep network xin yizhou wang ...</td>\n",
              "      <td>[(network, 35), (sparse, 32), (algorithm, 22),...</td>\n",
              "      <td>[(sparse, 0.244), (dictionary, 0.21), (deep, 0...</td>\n",
              "      <td>[(sparse, 0.4469), (sparseness, 0.4132), (thre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6175</th>\n",
              "      <td>6586</td>\n",
              "      <td>2016</td>\n",
              "      <td>Edge-exchangeable graphs and sparsity</td>\n",
              "      <td>Poster</td>\n",
              "      <td>6586-edge-exchangeable-graphs-and-sparsity.pdf</td>\n",
              "      <td>Many popular network models rely on the assump...</td>\n",
              "      <td>Edge-exchangeable graphs and sparsity\\n\\nDiana...</td>\n",
              "      <td>edge exchangeable graph sparsity diana cai dep...</td>\n",
              "      <td>[(graph, 136), (edge, 107), (vertex, 63), (seq...</td>\n",
              "      <td>[(graph, 0.508), (edge, 0.451), (exchangeable,...</td>\n",
              "      <td>[(graphon, 0.5184), (adjacency, 0.4975), (grap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3966</th>\n",
              "      <td>4590</td>\n",
              "      <td>2012</td>\n",
              "      <td>Kernel Latent SVM for Visual Recognition</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4590-kernel-latent-svm-for-visual-recognition.pdf</td>\n",
              "      <td>Latent SVMs (LSVMs) are a class of powerful to...</td>\n",
              "      <td>Kernel Latent SVM for Visual Recognition\\n\\nYa...</td>\n",
              "      <td>kernel latent svm visual recognition yang wang...</td>\n",
              "      <td>[(latent, 77), (kernel, 63), (variable, 52), (...</td>\n",
              "      <td>[(latent, 0.435), (latent variable, 0.315), (k...</td>\n",
              "      <td>[(svms, 0.5638), (svm, 0.5597), (classifier, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3592</th>\n",
              "      <td>4252</td>\n",
              "      <td>2011</td>\n",
              "      <td>Prismatic Algorithm for Discrete D.C. Programm...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4252-prismatic-algorithm-for-discrete-dc-progr...</td>\n",
              "      <td>In this paper, we propose the first exact algo...</td>\n",
              "      <td>Prismatic Algorithm for Discrete D.C. Programm...</td>\n",
              "      <td>prismatic algorithm discrete programming probl...</td>\n",
              "      <td>[(problem, 51), (algorithm, 45), (function, 36...</td>\n",
              "      <td>[(submodular, 0.447), (programming problem, 0....</td>\n",
              "      <td>[(programming, 0.3882), (algorithm, 0.3861), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>1679</td>\n",
              "      <td>1999</td>\n",
              "      <td>Modeling High-Dimensional Discrete Data with M...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1679-modeling-high-dimensional-discrete-data-w...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Modeling High-Dimensional Discrete Data with\\n...</td>\n",
              "      <td>modeling high dimensional discrete data multi ...</td>\n",
              "      <td>[(model, 62), (variable, 51), (network, 41), (...</td>\n",
              "      <td>[(variable, 0.255), (model, 0.246), (network, ...</td>\n",
              "      <td>[(modeling, 0.3247), (modelization, 0.3108), (...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1171b2ff-6e2a-4429-82dd-efbd16b16180')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1171b2ff-6e2a-4429-82dd-efbd16b16180 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1171b2ff-6e2a-4429-82dd-efbd16b16180');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9GQQGMTZgrR"
      },
      "source": [
        "### Question 1.7. Comparison of multilple techniques [written] (4 points)\n",
        "\n",
        "1. Draw a table of the solution, the quality score that you defined and the time taken to find keywords across a sample of 1000 of the original dataset. \n",
        "2. Can you think of tweaks to reduce time to compute? If yes, add an additional column to the above table with your proposed tweaks.\n",
        "3. Based on the above table and  lecture 1, what do you think is the most appropriate solution for keywords extraction? Why? "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%capture\n",
        "\n",
        "# TOP N\n",
        "df_[\"top_n_test\"] = df_[\"preproc_text\"].apply(get_counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-IWYm4CGoFi",
        "outputId": "d29f7d43-7cb7-4715-e52b-b57b29d4aae2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 885 ms, sys: 3.93 ms, total: 889 ms\n",
            "Wall time: 898 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%capture\n",
        "#create a vocabulary of words, \n",
        "cv_test = CountVectorizer(max_df=0.95,         # ignore words that appear in 95% of documents\n",
        "                   max_features=10000,  # the size of the vocabulary\n",
        "                   ngram_range=(1,3)    # vocabulary contains single words, bigrams, trigrams\n",
        "                  )\n",
        "\n",
        "word_count_vector_test = cv_test.fit_transform(df_[\"preproc_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2-8NOJmIXXc",
        "outputId": "7a76cf16-9794-4ea7-db2e-94f4390ad8bc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.41 s, sys: 17.1 ms, total: 1.43 s\n",
            "Wall time: 1.44 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%capture\n",
        "\n",
        "tfidf_transformer_test=TfidfTransformer(smooth_idf=True,\n",
        "                                   use_idf=True)\n",
        "tfidf_transformer_test.fit(word_count_vector_test)\n",
        "df_[\"tf_idf_test\"] = df_[\"preproc_text\"].apply(get_keywords, top_N=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmeWWi_3HiAc",
        "outputId": "372083e7-be70-47e7-bec9-6196dbc1dcb5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.04 s, sys: 13.9 ms, total: 1.06 s\n",
            "Wall time: 1.06 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "def get_top_n_only(l):\n",
        "    res = []\n",
        "    for e in l:\n",
        "        val, _ = e\n",
        "        res.append(val)\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "qISXgXWcL0p9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_['top_n_test'] = df_['top_n_test'].apply(get_top_n_only)\n",
        "df_['tf_idf_test'] = df_['tf_idf_test'].apply(get_top_n_only)\n",
        "df_['keyBERT_test'] = df_['Top_N_KeyBERT_1'].apply(get_top_n_only)"
      ],
      "metadata": {
        "id": "HTg5OqKiRWpl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def get_accuracy(df_, col1, col2):\n",
        "    accuracies = []\n",
        "    for i in range(len(df_)):\n",
        "        vals2 = df_[col2].values[i][:len(df_[col1].values[i])] \n",
        "        accuracies.append(accuracy_score(df_[col1].values[i], vals2))\n",
        "\n",
        "    return round(np.mean(accuracies), 4)"
      ],
      "metadata": {
        "id": "FPO7K6uDJFSS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(df_, 'keyBERT_test', 'tf_idf_test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW3C4-cARtba",
        "outputId": "df35f01b-62a0-4017-dd4e-1013c02d7997"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.044"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(df_, 'keyBERT_test', 'top_n_test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg7a5IcRT1Tc",
        "outputId": "9b60c7ce-2fc0-4ebf-bd87-7d8a3a63ab51"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.036"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(df_, 'top_n_test', 'tf_idf_test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4siWPpctUPyv",
        "outputId": "9d443f88-ad4c-49e9-f7d6-e897785d1352"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.109"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def matching(list1, list2):\n",
        "    matchings = 0\n",
        "    for item in list1:\n",
        "        if item in list2:\n",
        "            matchings += 1\n",
        "\n",
        "    return matchings / len(list1)"
      ],
      "metadata": {
        "id": "sRUzld_kVELq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_matching(df_, col1, col2):\n",
        "    matchings = []\n",
        "    for i in range(len(df_)):\n",
        "        matchings.append(matching(df_[col1].values[i], df_[col2].values[i]))\n",
        "\n",
        "    return round(np.mean(matchings), 5)"
      ],
      "metadata": {
        "id": "OK3d8kqFUv1k"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_matching(df_, 'keyBERT_test', 'tf_idf_test')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmH3PbilVjmc",
        "outputId": "b40d8f6e-f200-4b81-b8d9-b1b656242096"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_matching(df_, 'keyBERT_test', 'top_n_test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwleONHIVfGQ",
        "outputId": "8c8d8ddd-fec7-4fa4-e2ac-a94e13bf65da"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_matching(df_, 'tf_idf_test', 'top_n_test')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxHZ3D0uVl8L",
        "outputId": "2541aef3-f368-4425-f924-11b1551de018"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.555"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYDNwWa5ZiTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9975f05-a096-4733-9024-0eee25127630"
      },
      "source": [
        "# TODO: compare the same paper example across the 3 methods \n",
        "from pprint import pprint\n",
        "\n",
        "# idx_focus = 1271 \n",
        "idx_focus = df_.index[10]\n",
        "\n",
        "print('Keybert:')\n",
        "pprint(df_.loc[idx_focus, \"Top_N_KeyBERT_1\"])\n",
        "\n",
        "print('\\nTF-IDF:')\n",
        "pprint(df_.loc[idx_focus, \"Top_N_TF-IDF\"])\n",
        "\n",
        "print('\\nTop N:')\n",
        "pprint(df_.loc[idx_focus, \"Top N\"]) "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keybert:\n",
            "[('tactile', 0.479),\n",
            " ('neuroscience', 0.433),\n",
            " ('cortex', 0.4082),\n",
            " ('neuron', 0.4025),\n",
            " ('nerve', 0.3975)]\n",
            "\n",
            "TF-IDF:\n",
            "[('amari', 0.409),\n",
            " ('stimulus', 0.309),\n",
            " ('border', 0.197),\n",
            " ('change', 0.182),\n",
            " ('membrane', 0.168),\n",
            " ('cortex', 0.159),\n",
            " ('afferent', 0.155),\n",
            " ('perturbation', 0.14),\n",
            " ('training', 0.139),\n",
            " ('steady state', 0.138)]\n",
            "\n",
            "Top N:\n",
            "[('change', 21),\n",
            " ('stimulus', 20),\n",
            " ('training', 18),\n",
            " ('amari', 18),\n",
            " ('size', 18),\n",
            " ('neural', 14),\n",
            " ('model', 14),\n",
            " ('function', 13),\n",
            " ('field', 12),\n",
            " ('probability', 12)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODOOOOOOOOOO"
      ],
      "metadata": {
        "id": "ObtV0t6W5Wqe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhS_Y6qgqW4Z"
      },
      "source": [
        "# Part 2. Word Vectors (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kedMB9f-qsnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9e21d3-5509-4644-c367-f4de873bfabe"
      },
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "import nltk\n",
        "nltk.download('reuters')\n",
        "from nltk.corpus import reuters\n",
        "import numpy as np\n",
        "import random\n",
        "import scipy as sp\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5S4yJ_ZrHAo"
      },
      "source": [
        "Word Vectors are often used as a fundamental component for downstream NLP tasks, e.g. question answering, text generation, translation, etc., so it is important to build some intuitions as to their strengths and weaknesses. Here, you will explore two types of word vectors: those derived from co-occurrence matrices, and those derived via GloVe.\n",
        "\n",
        "Note on Terminology: The terms \"word vectors\" and \"word embeddings\" are often used interchangeably. The term \"embedding\" refers to the fact that we are encoding aspects of a word's meaning in a lower dimensional space. As Wikipedia states, \"conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKcD1SUIrP_m"
      },
      "source": [
        "## Count-Based Word Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Uvm6lbSsFD0"
      },
      "source": [
        "Most word vector models start from the following idea:\n",
        "\n",
        "You shall know a word by the company it keeps (Firth, J. R. 1957:11)\n",
        "\n",
        "Many word vector implementations are driven by the idea that similar words, i.e., (near) synonyms, will be used in similar contexts. As a result, similar words will often be spoken or written along with a shared subset of words, i.e., contexts. By examining these contexts, we can try to develop embeddings for our words. With this intuition in mind, many \"old school\" approaches to constructing word vectors relied on word counts. Here we elaborate upon one of those strategies, co-occurrence matrices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vMxbozcslLA"
      },
      "source": [
        "## Plotting Co-Occurrence Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3OO_oowsrK2"
      },
      "source": [
        "\n",
        "Here, we will be using the Reuters (business and financial news) corpus. If you haven't run the import cell at the top of this page, please run it now (click it and press SHIFT-RETURN). The corpus consists of 10,788 news documents totaling 1.3 million words. These documents span 90 categories and are split into train and test. For more details, please see https://www.nltk.org/book/ch02.html. We provide a read_corpus function below that pulls out only articles from the \"crude\" (i.e. news articles about oil, gas, etc.) category. The function also adds <START> and <END> tokens to each of the documents, and lowercases words. You do not have to perform any other kind of pre-processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xTQwympsqDq"
      },
      "source": [
        "def read_corpus(category=\"crude\"):\n",
        "    \"\"\" Read files from the specified Reuter's category.\n",
        "        Params:\n",
        "            category (string): category name\n",
        "        Return:\n",
        "            list of lists, with words from each of the processed files\n",
        "    \"\"\"\n",
        "    files = reuters.fileids(category)\n",
        "    return [[START_TOKEN] + [w.lower() for w in list(reuters.words(f))] + [END_TOKEN] for f in files]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQrwL93ns1Qy"
      },
      "source": [
        "Let's have a look what these documents are like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eZvFI3Qs0x4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a8d134-3f81-4b8d-dc1c-350a2c228933"
      },
      "source": [
        "reuters_corpus = read_corpus()\n",
        "pprint.pprint(reuters_corpus[:3], compact=True, width=100)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['<START>', 'japan', 'to', 'revise', 'long', '-', 'term', 'energy', 'demand', 'downwards', 'the',\n",
            "  'ministry', 'of', 'international', 'trade', 'and', 'industry', '(', 'miti', ')', 'will', 'revise',\n",
            "  'its', 'long', '-', 'term', 'energy', 'supply', '/', 'demand', 'outlook', 'by', 'august', 'to',\n",
            "  'meet', 'a', 'forecast', 'downtrend', 'in', 'japanese', 'energy', 'demand', ',', 'ministry',\n",
            "  'officials', 'said', '.', 'miti', 'is', 'expected', 'to', 'lower', 'the', 'projection', 'for',\n",
            "  'primary', 'energy', 'supplies', 'in', 'the', 'year', '2000', 'to', '550', 'mln', 'kilolitres',\n",
            "  '(', 'kl', ')', 'from', '600', 'mln', ',', 'they', 'said', '.', 'the', 'decision', 'follows',\n",
            "  'the', 'emergence', 'of', 'structural', 'changes', 'in', 'japanese', 'industry', 'following',\n",
            "  'the', 'rise', 'in', 'the', 'value', 'of', 'the', 'yen', 'and', 'a', 'decline', 'in', 'domestic',\n",
            "  'electric', 'power', 'demand', '.', 'miti', 'is', 'planning', 'to', 'work', 'out', 'a', 'revised',\n",
            "  'energy', 'supply', '/', 'demand', 'outlook', 'through', 'deliberations', 'of', 'committee',\n",
            "  'meetings', 'of', 'the', 'agency', 'of', 'natural', 'resources', 'and', 'energy', ',', 'the',\n",
            "  'officials', 'said', '.', 'they', 'said', 'miti', 'will', 'also', 'review', 'the', 'breakdown',\n",
            "  'of', 'energy', 'supply', 'sources', ',', 'including', 'oil', ',', 'nuclear', ',', 'coal', 'and',\n",
            "  'natural', 'gas', '.', 'nuclear', 'energy', 'provided', 'the', 'bulk', 'of', 'japan', \"'\", 's',\n",
            "  'electric', 'power', 'in', 'the', 'fiscal', 'year', 'ended', 'march', '31', ',', 'supplying',\n",
            "  'an', 'estimated', '27', 'pct', 'on', 'a', 'kilowatt', '/', 'hour', 'basis', ',', 'followed',\n",
            "  'by', 'oil', '(', '23', 'pct', ')', 'and', 'liquefied', 'natural', 'gas', '(', '21', 'pct', '),',\n",
            "  'they', 'noted', '.', '<END>'],\n",
            " ['<START>', 'energy', '/', 'u', '.', 's', '.', 'petrochemical', 'industry', 'cheap', 'oil',\n",
            "  'feedstocks', ',', 'the', 'weakened', 'u', '.', 's', '.', 'dollar', 'and', 'a', 'plant',\n",
            "  'utilization', 'rate', 'approaching', '90', 'pct', 'will', 'propel', 'the', 'streamlined', 'u',\n",
            "  '.', 's', '.', 'petrochemical', 'industry', 'to', 'record', 'profits', 'this', 'year', ',',\n",
            "  'with', 'growth', 'expected', 'through', 'at', 'least', '1990', ',', 'major', 'company',\n",
            "  'executives', 'predicted', '.', 'this', 'bullish', 'outlook', 'for', 'chemical', 'manufacturing',\n",
            "  'and', 'an', 'industrywide', 'move', 'to', 'shed', 'unrelated', 'businesses', 'has', 'prompted',\n",
            "  'gaf', 'corp', '&', 'lt', ';', 'gaf', '>,', 'privately', '-', 'held', 'cain', 'chemical', 'inc',\n",
            "  ',', 'and', 'other', 'firms', 'to', 'aggressively', 'seek', 'acquisitions', 'of', 'petrochemical',\n",
            "  'plants', '.', 'oil', 'companies', 'such', 'as', 'ashland', 'oil', 'inc', '&', 'lt', ';', 'ash',\n",
            "  '>,', 'the', 'kentucky', '-', 'based', 'oil', 'refiner', 'and', 'marketer', ',', 'are', 'also',\n",
            "  'shopping', 'for', 'money', '-', 'making', 'petrochemical', 'businesses', 'to', 'buy', '.', '\"',\n",
            "  'i', 'see', 'us', 'poised', 'at', 'the', 'threshold', 'of', 'a', 'golden', 'period', ',\"', 'said',\n",
            "  'paul', 'oreffice', ',', 'chairman', 'of', 'giant', 'dow', 'chemical', 'co', '&', 'lt', ';',\n",
            "  'dow', '>,', 'adding', ',', '\"', 'there', \"'\", 's', 'no', 'major', 'plant', 'capacity', 'being',\n",
            "  'added', 'around', 'the', 'world', 'now', '.', 'the', 'whole', 'game', 'is', 'bringing', 'out',\n",
            "  'new', 'products', 'and', 'improving', 'the', 'old', 'ones', '.\"', 'analysts', 'say', 'the',\n",
            "  'chemical', 'industry', \"'\", 's', 'biggest', 'customers', ',', 'automobile', 'manufacturers',\n",
            "  'and', 'home', 'builders', 'that', 'use', 'a', 'lot', 'of', 'paints', 'and', 'plastics', ',',\n",
            "  'are', 'expected', 'to', 'buy', 'quantities', 'this', 'year', '.', 'u', '.', 's', '.',\n",
            "  'petrochemical', 'plants', 'are', 'currently', 'operating', 'at', 'about', '90', 'pct',\n",
            "  'capacity', ',', 'reflecting', 'tighter', 'supply', 'that', 'could', 'hike', 'product', 'prices',\n",
            "  'by', '30', 'to', '40', 'pct', 'this', 'year', ',', 'said', 'john', 'dosher', ',', 'managing',\n",
            "  'director', 'of', 'pace', 'consultants', 'inc', 'of', 'houston', '.', 'demand', 'for', 'some',\n",
            "  'products', 'such', 'as', 'styrene', 'could', 'push', 'profit', 'margins', 'up', 'by', 'as',\n",
            "  'much', 'as', '300', 'pct', ',', 'he', 'said', '.', 'oreffice', ',', 'speaking', 'at', 'a',\n",
            "  'meeting', 'of', 'chemical', 'engineers', 'in', 'houston', ',', 'said', 'dow', 'would', 'easily',\n",
            "  'top', 'the', '741', 'mln', 'dlrs', 'it', 'earned', 'last', 'year', 'and', 'predicted', 'it',\n",
            "  'would', 'have', 'the', 'best', 'year', 'in', 'its', 'history', '.', 'in', '1985', ',', 'when',\n",
            "  'oil', 'prices', 'were', 'still', 'above', '25', 'dlrs', 'a', 'barrel', 'and', 'chemical',\n",
            "  'exports', 'were', 'adversely', 'affected', 'by', 'the', 'strong', 'u', '.', 's', '.', 'dollar',\n",
            "  ',', 'dow', 'had', 'profits', 'of', '58', 'mln', 'dlrs', '.', '\"', 'i', 'believe', 'the',\n",
            "  'entire', 'chemical', 'industry', 'is', 'headed', 'for', 'a', 'record', 'year', 'or', 'close',\n",
            "  'to', 'it', ',\"', 'oreffice', 'said', '.', 'gaf', 'chairman', 'samuel', 'heyman', 'estimated',\n",
            "  'that', 'the', 'u', '.', 's', '.', 'chemical', 'industry', 'would', 'report', 'a', '20', 'pct',\n",
            "  'gain', 'in', 'profits', 'during', '1987', '.', 'last', 'year', ',', 'the', 'domestic',\n",
            "  'industry', 'earned', 'a', 'total', 'of', '13', 'billion', 'dlrs', ',', 'a', '54', 'pct', 'leap',\n",
            "  'from', '1985', '.', 'the', 'turn', 'in', 'the', 'fortunes', 'of', 'the', 'once', '-', 'sickly',\n",
            "  'chemical', 'industry', 'has', 'been', 'brought', 'about', 'by', 'a', 'combination', 'of', 'luck',\n",
            "  'and', 'planning', ',', 'said', 'pace', \"'\", 's', 'john', 'dosher', '.', 'dosher', 'said', 'last',\n",
            "  'year', \"'\", 's', 'fall', 'in', 'oil', 'prices', 'made', 'feedstocks', 'dramatically', 'cheaper',\n",
            "  'and', 'at', 'the', 'same', 'time', 'the', 'american', 'dollar', 'was', 'weakening', 'against',\n",
            "  'foreign', 'currencies', '.', 'that', 'helped', 'boost', 'u', '.', 's', '.', 'chemical',\n",
            "  'exports', '.', 'also', 'helping', 'to', 'bring', 'supply', 'and', 'demand', 'into', 'balance',\n",
            "  'has', 'been', 'the', 'gradual', 'market', 'absorption', 'of', 'the', 'extra', 'chemical',\n",
            "  'manufacturing', 'capacity', 'created', 'by', 'middle', 'eastern', 'oil', 'producers', 'in',\n",
            "  'the', 'early', '1980s', '.', 'finally', ',', 'virtually', 'all', 'major', 'u', '.', 's', '.',\n",
            "  'chemical', 'manufacturers', 'have', 'embarked', 'on', 'an', 'extensive', 'corporate',\n",
            "  'restructuring', 'program', 'to', 'mothball', 'inefficient', 'plants', ',', 'trim', 'the',\n",
            "  'payroll', 'and', 'eliminate', 'unrelated', 'businesses', '.', 'the', 'restructuring', 'touched',\n",
            "  'off', 'a', 'flurry', 'of', 'friendly', 'and', 'hostile', 'takeover', 'attempts', '.', 'gaf', ',',\n",
            "  'which', 'made', 'an', 'unsuccessful', 'attempt', 'in', '1985', 'to', 'acquire', 'union',\n",
            "  'carbide', 'corp', '&', 'lt', ';', 'uk', '>,', 'recently', 'offered', 'three', 'billion', 'dlrs',\n",
            "  'for', 'borg', 'warner', 'corp', '&', 'lt', ';', 'bor', '>,', 'a', 'chicago', 'manufacturer',\n",
            "  'of', 'plastics', 'and', 'chemicals', '.', 'another', 'industry', 'powerhouse', ',', 'w', '.',\n",
            "  'r', '.', 'grace', '&', 'lt', ';', 'gra', '>', 'has', 'divested', 'its', 'retailing', ',',\n",
            "  'restaurant', 'and', 'fertilizer', 'businesses', 'to', 'raise', 'cash', 'for', 'chemical',\n",
            "  'acquisitions', '.', 'but', 'some', 'experts', 'worry', 'that', 'the', 'chemical', 'industry',\n",
            "  'may', 'be', 'headed', 'for', 'trouble', 'if', 'companies', 'continue', 'turning', 'their',\n",
            "  'back', 'on', 'the', 'manufacturing', 'of', 'staple', 'petrochemical', 'commodities', ',', 'such',\n",
            "  'as', 'ethylene', ',', 'in', 'favor', 'of', 'more', 'profitable', 'specialty', 'chemicals',\n",
            "  'that', 'are', 'custom', '-', 'designed', 'for', 'a', 'small', 'group', 'of', 'buyers', '.', '\"',\n",
            "  'companies', 'like', 'dupont', '&', 'lt', ';', 'dd', '>', 'and', 'monsanto', 'co', '&', 'lt', ';',\n",
            "  'mtc', '>', 'spent', 'the', 'past', 'two', 'or', 'three', 'years', 'trying', 'to', 'get', 'out',\n",
            "  'of', 'the', 'commodity', 'chemical', 'business', 'in', 'reaction', 'to', 'how', 'badly', 'the',\n",
            "  'market', 'had', 'deteriorated', ',\"', 'dosher', 'said', '.', '\"', 'but', 'i', 'think', 'they',\n",
            "  'will', 'eventually', 'kill', 'the', 'margins', 'on', 'the', 'profitable', 'chemicals', 'in',\n",
            "  'the', 'niche', 'market', '.\"', 'some', 'top', 'chemical', 'executives', 'share', 'the',\n",
            "  'concern', '.', '\"', 'the', 'challenge', 'for', 'our', 'industry', 'is', 'to', 'keep', 'from',\n",
            "  'getting', 'carried', 'away', 'and', 'repeating', 'past', 'mistakes', ',\"', 'gaf', \"'\", 's',\n",
            "  'heyman', 'cautioned', '.', '\"', 'the', 'shift', 'from', 'commodity', 'chemicals', 'may', 'be',\n",
            "  'ill', '-', 'advised', '.', 'specialty', 'businesses', 'do', 'not', 'stay', 'special', 'long',\n",
            "  '.\"', 'houston', '-', 'based', 'cain', 'chemical', ',', 'created', 'this', 'month', 'by', 'the',\n",
            "  'sterling', 'investment', 'banking', 'group', ',', 'believes', 'it', 'can', 'generate', '700',\n",
            "  'mln', 'dlrs', 'in', 'annual', 'sales', 'by', 'bucking', 'the', 'industry', 'trend', '.',\n",
            "  'chairman', 'gordon', 'cain', ',', 'who', 'previously', 'led', 'a', 'leveraged', 'buyout', 'of',\n",
            "  'dupont', \"'\", 's', 'conoco', 'inc', \"'\", 's', 'chemical', 'business', ',', 'has', 'spent', '1',\n",
            "  '.', '1', 'billion', 'dlrs', 'since', 'january', 'to', 'buy', 'seven', 'petrochemical', 'plants',\n",
            "  'along', 'the', 'texas', 'gulf', 'coast', '.', 'the', 'plants', 'produce', 'only', 'basic',\n",
            "  'commodity', 'petrochemicals', 'that', 'are', 'the', 'building', 'blocks', 'of', 'specialty',\n",
            "  'products', '.', '\"', 'this', 'kind', 'of', 'commodity', 'chemical', 'business', 'will', 'never',\n",
            "  'be', 'a', 'glamorous', ',', 'high', '-', 'margin', 'business', ',\"', 'cain', 'said', ',',\n",
            "  'adding', 'that', 'demand', 'is', 'expected', 'to', 'grow', 'by', 'about', 'three', 'pct',\n",
            "  'annually', '.', 'garo', 'armen', ',', 'an', 'analyst', 'with', 'dean', 'witter', 'reynolds', ',',\n",
            "  'said', 'chemical', 'makers', 'have', 'also', 'benefitted', 'by', 'increasing', 'demand', 'for',\n",
            "  'plastics', 'as', 'prices', 'become', 'more', 'competitive', 'with', 'aluminum', ',', 'wood',\n",
            "  'and', 'steel', 'products', '.', 'armen', 'estimated', 'the', 'upturn', 'in', 'the', 'chemical',\n",
            "  'business', 'could', 'last', 'as', 'long', 'as', 'four', 'or', 'five', 'years', ',', 'provided',\n",
            "  'the', 'u', '.', 's', '.', 'economy', 'continues', 'its', 'modest', 'rate', 'of', 'growth', '.',\n",
            "  '<END>'],\n",
            " ['<START>', 'turkey', 'calls', 'for', 'dialogue', 'to', 'solve', 'dispute', 'turkey', 'said',\n",
            "  'today', 'its', 'disputes', 'with', 'greece', ',', 'including', 'rights', 'on', 'the',\n",
            "  'continental', 'shelf', 'in', 'the', 'aegean', 'sea', ',', 'should', 'be', 'solved', 'through',\n",
            "  'negotiations', '.', 'a', 'foreign', 'ministry', 'statement', 'said', 'the', 'latest', 'crisis',\n",
            "  'between', 'the', 'two', 'nato', 'members', 'stemmed', 'from', 'the', 'continental', 'shelf',\n",
            "  'dispute', 'and', 'an', 'agreement', 'on', 'this', 'issue', 'would', 'effect', 'the', 'security',\n",
            "  ',', 'economy', 'and', 'other', 'rights', 'of', 'both', 'countries', '.', '\"', 'as', 'the',\n",
            "  'issue', 'is', 'basicly', 'political', ',', 'a', 'solution', 'can', 'only', 'be', 'found', 'by',\n",
            "  'bilateral', 'negotiations', ',\"', 'the', 'statement', 'said', '.', 'greece', 'has', 'repeatedly',\n",
            "  'said', 'the', 'issue', 'was', 'legal', 'and', 'could', 'be', 'solved', 'at', 'the',\n",
            "  'international', 'court', 'of', 'justice', '.', 'the', 'two', 'countries', 'approached', 'armed',\n",
            "  'confrontation', 'last', 'month', 'after', 'greece', 'announced', 'it', 'planned', 'oil',\n",
            "  'exploration', 'work', 'in', 'the', 'aegean', 'and', 'turkey', 'said', 'it', 'would', 'also',\n",
            "  'search', 'for', 'oil', '.', 'a', 'face', '-', 'off', 'was', 'averted', 'when', 'turkey',\n",
            "  'confined', 'its', 'research', 'to', 'territorrial', 'waters', '.', '\"', 'the', 'latest',\n",
            "  'crises', 'created', 'an', 'historic', 'opportunity', 'to', 'solve', 'the', 'disputes', 'between',\n",
            "  'the', 'two', 'countries', ',\"', 'the', 'foreign', 'ministry', 'statement', 'said', '.', 'turkey',\n",
            "  \"'\", 's', 'ambassador', 'in', 'athens', ',', 'nazmi', 'akiman', ',', 'was', 'due', 'to', 'meet',\n",
            "  'prime', 'minister', 'andreas', 'papandreou', 'today', 'for', 'the', 'greek', 'reply', 'to', 'a',\n",
            "  'message', 'sent', 'last', 'week', 'by', 'turkish', 'prime', 'minister', 'turgut', 'ozal', '.',\n",
            "  'the', 'contents', 'of', 'the', 'message', 'were', 'not', 'disclosed', '.', '<END>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNKy6j3as7xJ"
      },
      "source": [
        "### Question 2.1: Implement distinct_words [code] (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIgkQ47otdqZ"
      },
      "source": [
        "Write a method to work out the distinct words (word types) that occur in the corpus. You can do this with for loops, but it's more efficient to do it with Python list comprehensions. In particular, this may be useful to flatten a list of lists. If you're not familiar with Python list comprehensions in general, here's more information.\n",
        "\n",
        "Your returned corpus_words should be sorted. You can use python's sorted function for this.\n",
        "\n",
        "You may find it useful to use Python sets to remove duplicate words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTIH5vFetgjD"
      },
      "source": [
        "def distinct_words(corpus):\n",
        "    \"\"\" Determine a list of distinct words for the corpus.\n",
        "        Params:\n",
        "            corpus (list of list of strings): corpus of documents - eg [[\"hey\", \"I\", \"am\", \"toto\"], [\"hey\", \"I\", \"am\", \"tata\"]]\n",
        "        Return:\n",
        "            corpus_words (list of strings): sorted list of distinct words across the corpus\n",
        "            num_corpus_words (integer): number of distinct words across the corpus\n",
        "    \"\"\"\n",
        "    corpus_words = []\n",
        "    num_corpus_words = -1\n",
        "    \n",
        "    # ------------------\n",
        "    # Write your implementation here.w\n",
        "    #flattened_corpus = np.array(corpus, dtype=object).flatten()\n",
        "    flattened_corpus = np.concatenate(corpus).ravel()\n",
        "\n",
        "    #print(set(map(tuple, flattened_corpus)))\n",
        "    unique_flat_corpus = list(set(flattened_corpus))\n",
        "    \n",
        "    corpus_words = sorted(unique_flat_corpus)\n",
        "    num_corpus_words = len(corpus_words)\n",
        "    # ------------------\n",
        "\n",
        "    return corpus_words, num_corpus_words"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZX4dH8stmYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eddb9700-5d1f-42d9-832a-1693af141cb8"
      },
      "source": [
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this not an exhaustive check for correctness.\n",
        "# ---------------------\n",
        "\n",
        "# Define toy corpus\n",
        "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
        "test_corpus_words, num_corpus_words = distinct_words(test_corpus)\n",
        "\n",
        "# Correct answers\n",
        "ans_test_corpus_words = sorted([START_TOKEN, \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", END_TOKEN])\n",
        "ans_num_corpus_words = len(ans_test_corpus_words)\n",
        "\n",
        "# Test correct number of words\n",
        "assert(num_corpus_words == ans_num_corpus_words), \"Incorrect number of distinct words. Correct: {}. Yours: {}\".format(ans_num_corpus_words, num_corpus_words)\n",
        "\n",
        "# Test correct words\n",
        "assert (test_corpus_words == ans_test_corpus_words), \"Incorrect corpus_words.\\nCorrect: {}\\nYours:   {}\".format(str(ans_test_corpus_words), str(test_corpus_words))\n",
        "\n",
        "# Print Success\n",
        "print (\"-\" * 80)\n",
        "print(\"Passed All Tests!\")\n",
        "print (\"-\" * 80)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Passed All Tests!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86fD2hYr3fw8"
      },
      "source": [
        "### Question 2.2: Implement compute_co_occurrence_matrix [code] (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4MLCIa3lKw"
      },
      "source": [
        "Write a method that constructs a co-occurrence matrix for a certain window-size  n  (with a default of 4), considering words  n  before and  n  after the word in the center of the window. Here, we start to use numpy (np) to represent vectors, matrices, and tensors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag.mapping import join\n",
        "from collections import defaultdict\n",
        "from collections import Counter \n",
        "\n",
        "def compute_co_occurrence_matrix(corpus, window_size=4):\n",
        "    \"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
        "    \n",
        "        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller\n",
        "              number of co-occurring words.\n",
        "              \n",
        "              For example, if we take the document \"<START> All that glitters is not gold <END>\" with window size of 4,\n",
        "              \"All\" will co-occur with \"<START>\", \"that\", \"glitters\", \"is\", and \"not\".\n",
        "    \n",
        "        Params:\n",
        "            corpus (list of list of strings): corpus of documents\n",
        "            window_size (int): size of context window\n",
        "        Return:\n",
        "            M (a symmetric numpy matrix of shape (number of unique words in the corpus , number of unique words in the corpus)): \n",
        "                Co-occurence matrix of word counts. \n",
        "                The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.\n",
        "            word2ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.\n",
        "    \"\"\"\n",
        "    words, num_words = distinct_words(corpus)\n",
        "    M = None\n",
        "    word2ind = {}\n",
        "    \n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "\n",
        "    M = np.zeros((num_words, num_words))\n",
        "    word2ind = dict(zip(words, range(num_words)))\n",
        "\n",
        "    for sentence in corpus:\n",
        "        sentence_len = len(sentence)\n",
        "        for i, word in enumerate(sentence):\n",
        "            word_index = word2ind[word]\n",
        "\n",
        "            maximum = min(sentence_len, i + window_size + 1)\n",
        "            minimum = max(0, i - window_size)\n",
        "            for j in range(minimum, maximum):\n",
        "                if (i == j):\n",
        "                    continue\n",
        "\n",
        "                curr_word_index = word2ind[sentence[j]]\n",
        "                M[word_index][curr_word_index] += 1\n",
        "\n",
        "    # ------------------\n",
        "\n",
        "    return M, word2ind"
      ],
      "metadata": {
        "id": "eJDj_b5TY7e8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guUdCsM2BUuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7abdfb-57f7-4504-93c3-27064f945a5d"
      },
      "source": [
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this is not an exhaustive check for correctness.\n",
        "# ---------------------\n",
        "\n",
        "# Define toy corpus and get student's co-occurrence matrix\n",
        "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
        "M_test, word2ind_test = compute_co_occurrence_matrix(test_corpus, window_size=1)\n",
        "\n",
        "# Correct M and word2ind\n",
        "M_test_ans = np.array( \n",
        "    [[0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,],\n",
        "     [0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,],\n",
        "     [0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,],\n",
        "     [0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,],\n",
        "     [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,],\n",
        "     [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,],\n",
        "     [1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,],\n",
        "     [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,],\n",
        "     [0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,],\n",
        "     [1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,]]\n",
        ")\n",
        "ans_test_corpus_words = sorted([START_TOKEN, \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", END_TOKEN])\n",
        "word2ind_ans = dict(zip(ans_test_corpus_words, range(len(ans_test_corpus_words))))\n",
        "\n",
        "# Test correct word2ind\n",
        "assert (word2ind_ans == word2ind_test), \"Your word2ind is incorrect:\\nCorrect: {}\\nYours: {}\".format(word2ind_ans, word2ind_test)\n",
        "\n",
        "# Test correct M shape\n",
        "assert (M_test.shape == M_test_ans.shape), \"M matrix has incorrect shape.\\nCorrect: {}\\nYours: {}\".format(M_test.shape, M_test_ans.shape)\n",
        "\n",
        "# Test correct M values\n",
        "for w1 in word2ind_ans.keys():\n",
        "    idx1 = word2ind_ans[w1]\n",
        "    for w2 in word2ind_ans.keys():\n",
        "        idx2 = word2ind_ans[w2]\n",
        "        student = M_test[idx1, idx2]\n",
        "        correct = M_test_ans[idx1, idx2]\n",
        "        if student != correct:\n",
        "            print(\"Correct M:\")\n",
        "            print(M_test_ans)\n",
        "            print(\"Your M: \")\n",
        "            print(M_test)\n",
        "            raise AssertionError(\"Incorrect count at index ({}, {})=({}, {}) in matrix M. Yours has {} but should have {}.\".format(idx1, idx2, w1, w2, student, correct))\n",
        "\n",
        "# Print Success\n",
        "print (\"-\" * 80)\n",
        "print(\"Passed All Tests!\")\n",
        "print (\"-\" * 80)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Passed All Tests!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCC24T0WPyI2"
      },
      "source": [
        "### Question 2.3: Implement reduce_to_k_dim [code] (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ9XXG-WP2dZ"
      },
      "source": [
        "Construct a method that performs dimensionality reduction on the matrix to produce k-dimensional embeddings. Use SVD to take the top k components and produce a new matrix of k-dimensional embeddings.\n",
        "\n",
        "Note: All of numpy, scipy, and scikit-learn (sklearn) provide some implementation of SVD, but only scipy and sklearn provide an implementation of Truncated SVD, and only sklearn provides an efficient randomized algorithm for calculating large-scale Truncated SVD. So please use sklearn.decomposition.TruncatedSVD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jfqvOUOP8R6"
      },
      "source": [
        "def reduce_to_k_dim(M, k=2):\n",
        "    \"\"\" Reduce a co-occurence count matrix of dimensionality (num_corpus_words, num_corpus_words)\n",
        "        to a matrix of dimensionality (num_corpus_words, k) using the following SVD function from Scikit-Learn:\n",
        "            - http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
        "    \n",
        "        Params:\n",
        "            M (numpy matrix of shape (number of unique words in the corpus , number of unique words in the corpus)): co-occurence matrix of word counts\n",
        "            k (int): embedding size of each word after dimension reduction\n",
        "        Return:\n",
        "            M_reduced (numpy matrix of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.\n",
        "                    In terms of the SVD from math class, this actually returns U * S\n",
        "    \"\"\"    \n",
        "    n_iters = 10     # Use this parameter in your call to `TruncatedSVD`\n",
        "    M_reduced = None\n",
        "    print(\"Running Truncated SVD over %i words...\" % (M.shape[0]))\n",
        "    \n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    \n",
        "    # Random state set for reproducability \n",
        "    svd = TruncatedSVD(n_components=k, n_iter=n_iters, random_state=42)\n",
        "    M_reduced = svd.fit_transform(M)\n",
        "\n",
        "    # ------------------\n",
        "\n",
        "    print(\"Done.\")\n",
        "    return M_reduced"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rGeaWNuRAnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00e4cb3-ddc3-4221-f095-300402082387"
      },
      "source": [
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this is not an exhaustive check for correctness \n",
        "# In fact we only check that your M_reduced has the right dimensions.\n",
        "# ---------------------\n",
        "\n",
        "# Define toy corpus and run student code\n",
        "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
        "M_test, word2ind_test = compute_co_occurrence_matrix(test_corpus, window_size=1)\n",
        "M_test_reduced = reduce_to_k_dim(M_test, k=2)\n",
        "\n",
        "# Test proper dimensions\n",
        "assert (M_test_reduced.shape[0] == 10), \"M_reduced has {} rows; should have {}\".format(M_test_reduced.shape[0], 10)\n",
        "assert (M_test_reduced.shape[1] == 2), \"M_reduced has {} columns; should have {}\".format(M_test_reduced.shape[1], 2)\n",
        "\n",
        "# Print Success\n",
        "print (\"-\" * 80)\n",
        "print(\"Passed All Tests!\")\n",
        "print (\"-\" * 80)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Truncated SVD over 10 words...\n",
            "Done.\n",
            "--------------------------------------------------------------------------------\n",
            "Passed All Tests!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iTgMaquRQKB"
      },
      "source": [
        "### Question 2.4: Implement plot_embeddings [code] (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H629WACPRTg2"
      },
      "source": [
        "Here you will write a function to plot a set of 2D vectors in 2D space. For graphs, we will use Matplotlib (plt).\n",
        "\n",
        "For this example, you may find it useful to adapt this code. In the future, a good way to make a plot is to look at the Matplotlib gallery, find a plot that looks somewhat like what you want, and adapt the code they give."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'"
      ],
      "metadata": {
        "id": "VYglHcvXNRZS"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMfaxKfERT1P"
      },
      "source": [
        "def plot_embeddings(M_reduced, word2ind, words):\n",
        "    \"\"\" Plot in a scatterplot the embeddings of the words specified in the list \"words\".\n",
        "        NOTE: do not plot all the words listed in M_reduced / word2ind.\n",
        "        Include a label next to each point.\n",
        "        \n",
        "        Params:\n",
        "            M_reduced (numpy matrix of shape (number of unique words in the corpus , 2)): matrix of 2-dimensioal word embeddings\n",
        "            word2ind (dict): dictionary that maps word to indices for matrix M\n",
        "            words (list of strings): words whose embeddings we want to visualize\n",
        "    \"\"\"\n",
        "\n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    word_indexes_to_plot = [word2ind[word] for word in words]\n",
        "    values_to_plot = [M_reduced[word] for word in word_indexes_to_plot]\n",
        "\n",
        "    x = [item[1] for item in values_to_plot]\n",
        "    y = [item[0] for item in values_to_plot]\n",
        "\n",
        "    plot = plt.scatter(x, y)\n",
        "    plt.setp(plot, color='#7E1E9C', linewidth=10.0, alpha=0.5)\n",
        "\n",
        "    for i, text in enumerate(words):\n",
        "      plt.annotate(text, (x[i], y[i]))\n",
        "\n",
        "    plt.show()\n",
        "    # ------------------"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ5sOXmXRYOa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "a71b4388-cc52-4341-e385-4a73bd40d98e"
      },
      "source": [
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this is not an exhaustive check for correctness.\n",
        "# The plot produced should look like the \"test solution plot\" depicted below. \n",
        "# ---------------------\n",
        "\n",
        "print (\"-\" * 80)\n",
        "print (\"Outputted Plot:\")\n",
        "\n",
        "M_reduced_plot_test = np.array([[1, 1], [-1, -1], [1, -1], [-1, 1], [0, 0]])\n",
        "word2ind_plot_test = {'test1': 0, 'test2': 1, 'test3': 2, 'test4': 3, 'test5': 4}\n",
        "words = ['test1', 'test2', 'test3', 'test4', 'test5']\n",
        "plot_embeddings(M_reduced_plot_test, word2ind_plot_test, words)\n",
        "\n",
        "print (\"-\" * 80)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Outputted Plot:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 397.192756 248.518125\" width=\"397.192756pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 397.192756 248.518125 \nL 397.192756 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 44.845313 224.64 \nL 379.645313 224.64 \nL 379.645313 7.2 \nL 44.845313 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"me501b6b2a9\" style=\"stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\"/>\n    </defs>\n    <g clip-path=\"url(#p08656d9fb5)\">\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"364.427131\" xlink:href=\"#me501b6b2a9\" y=\"17.083636\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"60.063494\" xlink:href=\"#me501b6b2a9\" y=\"214.756364\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"60.063494\" xlink:href=\"#me501b6b2a9\" y=\"17.083636\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"364.427131\" xlink:href=\"#me501b6b2a9\" y=\"214.756364\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"212.245313\" xlink:href=\"#me501b6b2a9\" y=\"115.92\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m63a5b08892\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"60.063494\" xlink:href=\"#m63a5b08892\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.00 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(44.740838 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"98.108949\" xlink:href=\"#m63a5b08892\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.75 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(82.786293 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"136.154403\" xlink:href=\"#m63a5b08892\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.50 -->\n      <g transform=\"translate(120.831747 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"174.199858\" xlink:href=\"#m63a5b08892\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.25 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(158.877202 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"212.245313\" xlink:href=\"#m63a5b08892\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.00 -->\n      <g transform=\"translate(201.1125 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"250.290767\" xlink:href=\"#m63a5b08892\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.25 -->\n      <g transform=\"translate(239.157955 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"288.336222\" xlink:href=\"#m63a5b08892\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.50 -->\n      <g transform=\"translate(277.203409 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"326.381676\" xlink:href=\"#m63a5b08892\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.75 -->\n      <g transform=\"translate(315.248864 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"364.427131\" xlink:href=\"#m63a5b08892\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.00 -->\n      <g transform=\"translate(353.294318 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"md973cb4898\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#md973cb4898\" y=\"214.756364\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.00 -->\n      <g transform=\"translate(7.2 218.555582)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#md973cb4898\" y=\"190.047273\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.75 -->\n      <g transform=\"translate(7.2 193.846491)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#md973cb4898\" y=\"165.338182\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.50 -->\n      <g transform=\"translate(7.2 169.137401)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#md973cb4898\" y=\"140.629091\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.25 -->\n      <g transform=\"translate(7.2 144.42831)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#md973cb4898\" y=\"115.92\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.00 -->\n      <g transform=\"translate(15.579688 119.719219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#md973cb4898\" y=\"91.210909\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.25 -->\n      <g transform=\"translate(15.579688 95.010128)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#md973cb4898\" y=\"66.501818\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.50 -->\n      <g transform=\"translate(15.579688 70.301037)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#md973cb4898\" y=\"41.792727\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0.75 -->\n      <g transform=\"translate(15.579688 45.591946)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#md973cb4898\" y=\"17.083636\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 1.00 -->\n      <g transform=\"translate(15.579688 20.882855)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 44.845313 224.64 \nL 44.845313 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 379.645313 224.64 \nL 379.645313 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 44.845312 224.64 \nL 379.645313 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 44.845312 7.2 \nL 379.645313 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_19\">\n    <!-- test1 -->\n    <defs>\n     <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n    </defs>\n    <g transform=\"translate(364.427131 17.083636)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"192.041016\" xlink:href=\"#DejaVuSans-49\"/>\n    </g>\n   </g>\n   <g id=\"text_20\">\n    <!-- test2 -->\n    <g transform=\"translate(60.063494 214.756364)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"192.041016\" xlink:href=\"#DejaVuSans-50\"/>\n    </g>\n   </g>\n   <g id=\"text_21\">\n    <!-- test3 -->\n    <defs>\n     <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n    </defs>\n    <g transform=\"translate(60.063494 17.083636)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"192.041016\" xlink:href=\"#DejaVuSans-51\"/>\n    </g>\n   </g>\n   <g id=\"text_22\">\n    <!-- test4 -->\n    <defs>\n     <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n    </defs>\n    <g transform=\"translate(364.427131 214.756364)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"192.041016\" xlink:href=\"#DejaVuSans-52\"/>\n    </g>\n   </g>\n   <g id=\"text_23\">\n    <!-- test5 -->\n    <g transform=\"translate(212.245313 115.92)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"192.041016\" xlink:href=\"#DejaVuSans-53\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p08656d9fb5\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"44.845313\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRb0HnWqVCDL"
      },
      "source": [
        "### Question 2.5: Co-Occurrence Plot Analysis [written] (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkfAWdLFVFx-"
      },
      "source": [
        "Now we will put together all the parts you have written! We will compute the co-occurrence matrix with fixed window of 4 (the default window size), over the Reuters \"crude\" (oil) corpus. Then we will use TruncatedSVD to compute 2-dimensional embeddings of each word. TruncatedSVD returns U*S, so we need to normalize the returned vectors, so that all the vectors will appear around the unit circle (therefore closeness is directional closeness). Note: The line of code below that does the normalizing uses the NumPy concept of broadcasting. If you don't know about broadcasting, check out Computation on Arrays: Broadcasting by Jake VanderPlas.\n",
        "\n",
        "Run the below cell to produce the plot. It'll probably take a few seconds to run. What clusters together in 2-dimensional embedding space? What doesn't cluster together that you might think should have? Note: \"bpd\" stands for \"barrels per day\" and is a commonly used abbreviation in crude oil topic articles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3d0UK2iVFDM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "b94a52f7-6536-41a8-9084-f4348d38ae85"
      },
      "source": [
        "# -----------------------------\n",
        "# Run This Cell to Produce Your Plot\n",
        "# ------------------------------\n",
        "reuters_corpus = read_corpus()\n",
        "M_co_occurrence, word2ind_co_occurrence = compute_co_occurrence_matrix(reuters_corpus)\n",
        "M_reduced_co_occurrence = reduce_to_k_dim(M_co_occurrence, k=2)\n",
        "\n",
        "# Rescale (normalize) the rows to make them each of unit-length\n",
        "M_lengths = np.linalg.norm(M_reduced_co_occurrence, axis=1)\n",
        "M_normalized = M_reduced_co_occurrence / M_lengths[:, np.newaxis] # broadcasting\n",
        "\n",
        "words = ['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'iraq']\n",
        "\n",
        "plot_embeddings(M_normalized, word2ind_co_occurrence, words)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Truncated SVD over 8185 words...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 414.683381 248.518125\" width=\"414.683381pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 414.683381 248.518125 \nL 414.683381 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \nL 371.265625 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m72f73d7e8c\" style=\"stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\"/>\n    </defs>\n    <g clip-path=\"url(#pe633c210dc)\">\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"112.85396\" xlink:href=\"#m72f73d7e8c\" y=\"126.199121\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"51.683807\" xlink:href=\"#m72f73d7e8c\" y=\"214.756364\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"217.116827\" xlink:href=\"#m72f73d7e8c\" y=\"36.228505\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"286.701704\" xlink:href=\"#m72f73d7e8c\" y=\"17.083636\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"337.613025\" xlink:href=\"#m72f73d7e8c\" y=\"23.445542\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"198.015661\" xlink:href=\"#m72f73d7e8c\" y=\"47.146883\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"253.407158\" xlink:href=\"#m72f73d7e8c\" y=\"22.222441\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"143.9257\" xlink:href=\"#m72f73d7e8c\" y=\"91.528687\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"356.047443\" xlink:href=\"#m72f73d7e8c\" y=\"29.998859\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"226.023566\" xlink:href=\"#m72f73d7e8c\" y=\"31.975815\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m0eeaa7b36a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.988705\" xlink:href=\"#m0eeaa7b36a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.30 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(28.666049 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"85.544243\" xlink:href=\"#m0eeaa7b36a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.25 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(70.221587 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"127.099781\" xlink:href=\"#m0eeaa7b36a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.20 -->\n      <g transform=\"translate(111.777125 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"168.65532\" xlink:href=\"#m0eeaa7b36a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.15 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(153.332663 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"210.210858\" xlink:href=\"#m0eeaa7b36a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.10 -->\n      <g transform=\"translate(194.888202 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"251.766396\" xlink:href=\"#m0eeaa7b36a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.05 -->\n      <g transform=\"translate(236.44374 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"293.321934\" xlink:href=\"#m0eeaa7b36a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.00 -->\n      <g transform=\"translate(282.189122 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"334.877472\" xlink:href=\"#m0eeaa7b36a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.05 -->\n      <g transform=\"translate(323.74466 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m305585bb17\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m305585bb17\" y=\"200.110543\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.96 -->\n      <defs>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 203.909762)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m305585bb17\" y=\"154.317497\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.97 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(7.2 158.116715)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m305585bb17\" y=\"108.52445\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.98 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(7.2 112.323669)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m305585bb17\" y=\"62.731403\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.99 -->\n      <g transform=\"translate(7.2 66.530622)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m305585bb17\" y=\"16.938357\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.00 -->\n      <g transform=\"translate(7.2 20.737575)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.64 \nL 36.465625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 224.64 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.2 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_14\">\n    <!-- barrels -->\n    <defs>\n     <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n     <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n    </defs>\n    <g transform=\"translate(112.85396 126.199121)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"124.755859\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"164.119141\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"202.982422\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"264.505859\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"292.289062\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"text_15\">\n    <!-- bpd -->\n    <defs>\n     <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n     <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n    </defs>\n    <g transform=\"translate(51.683807 214.756364)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"126.953125\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_16\">\n    <!-- ecuador -->\n    <defs>\n     <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n     <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n     <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n    </defs>\n    <g transform=\"translate(217.116827 36.228505)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"61.523438\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"116.503906\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"179.882812\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"241.162109\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"304.638672\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"365.820312\" xlink:href=\"#DejaVuSans-114\"/>\n    </g>\n   </g>\n   <g id=\"text_17\">\n    <!-- energy -->\n    <defs>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n    </defs>\n    <g transform=\"translate(286.701704 17.083636)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"61.523438\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"124.902344\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"186.425781\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"225.789062\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"289.265625\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"text_18\">\n    <!-- industry -->\n    <defs>\n     <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n     <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n    </defs>\n    <g transform=\"translate(337.613025 23.445542)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"27.783203\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"91.162109\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"154.638672\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"218.017578\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"270.117188\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"309.326172\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"350.439453\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"text_19\">\n    <!-- kuwait -->\n    <defs>\n     <path d=\"M 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 31.109375 \nL 44.921875 54.6875 \nL 56.390625 54.6875 \nL 27.390625 29.109375 \nL 57.625 0 \nL 45.90625 0 \nL 18.109375 26.703125 \nL 18.109375 0 \nL 9.078125 0 \nz\n\" id=\"DejaVuSans-107\"/>\n     <path d=\"M 4.203125 54.6875 \nL 13.1875 54.6875 \nL 24.421875 12.015625 \nL 35.59375 54.6875 \nL 46.1875 54.6875 \nL 57.421875 12.015625 \nL 68.609375 54.6875 \nL 77.59375 54.6875 \nL 63.28125 0 \nL 52.6875 0 \nL 40.921875 44.828125 \nL 29.109375 0 \nL 18.5 0 \nz\n\" id=\"DejaVuSans-119\"/>\n    </defs>\n    <g transform=\"translate(198.015661 47.146883)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-107\"/>\n     <use x=\"54.785156\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"118.164062\" xlink:href=\"#DejaVuSans-119\"/>\n     <use x=\"199.951172\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"261.230469\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"289.013672\" xlink:href=\"#DejaVuSans-116\"/>\n    </g>\n   </g>\n   <g id=\"text_20\">\n    <!-- oil -->\n    <g transform=\"translate(253.407158 22.222441)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"61.181641\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"88.964844\" xlink:href=\"#DejaVuSans-108\"/>\n    </g>\n   </g>\n   <g id=\"text_21\">\n    <!-- output -->\n    <g transform=\"translate(143.9257 91.528687)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"61.181641\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"124.560547\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"163.769531\" xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"227.246094\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"290.625\" xlink:href=\"#DejaVuSans-116\"/>\n    </g>\n   </g>\n   <g id=\"text_22\">\n    <!-- petroleum -->\n    <defs>\n     <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n    </defs>\n    <g transform=\"translate(356.047443 29.998859)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"125\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"164.208984\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"203.072266\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"264.253906\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"292.037109\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"353.560547\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"416.939453\" xlink:href=\"#DejaVuSans-109\"/>\n    </g>\n   </g>\n   <g id=\"text_23\">\n    <!-- iraq -->\n    <defs>\n     <path d=\"M 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\nM 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nL 54.390625 -20.796875 \nL 45.40625 -20.796875 \nz\n\" id=\"DejaVuSans-113\"/>\n    </defs>\n    <g transform=\"translate(226.023566 31.975815)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"27.783203\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"68.896484\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"130.175781\" xlink:href=\"#DejaVuSans-113\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe633c210dc\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "A 2-dimensional embedding space is a graphical representation of a set of word embeddings, where each word is represented by a point in the space. Word embeddings are numerical representations of words that capture the meaning and context in which the words are used.\n",
        "\n",
        "A 2-dimensional embedding space, is read by:\n",
        " - Looking at the x-axis and y-axis labels. These should correspond to the dimensions of the embedding space.\n",
        " - Observing the positions of the points in the space. Words that are closer together in the space are typically more similar to each other in meaning or context, while words that are farther apart are typically less similar.\n",
        " - Looking for patterns in the positions of the points. For example, you might notice that certain words tend to cluster together in certain areas of the space. This could indicate that these words are related or have a similar meaning.\n",
        " - looking at the distances between points to get a sense of the similarity between different words is also possible. For example, if two points are very close together, it could indicate that the words represented by those points are very similar in meaning.\n",
        "\n",
        "It's important to keep in mind that the positions of the points in the embedding space are determined by the algorithm that was used to generate the embeddings. Different algorithms may produce different results, so it is important to consider the specific context in which the embeddings were created when interpreting the results.\n",
        "\n",
        "In figure 3s case that means all the words are\n",
        "very similar since they are located in the upper\n",
        "center of a [-1; 1] 2-dimentional space.\n",
        "\n",
        "Most words must be very similar in usage\n",
        "since only 3 out of the 10 words seem to be\n",
        "slightly off from the others. In fact, when look-\n",
        "ing closely these words (bpd, barrels and\n",
        "output) are related in that they represent or\n",
        "imply measures or output. berrels is a quan-\n",
        "tity, bpd is the barrels per day  daily produc-\n",
        "tion of barrels  which represent a quantity per\n",
        "day, and output represents what has been pro-\n",
        "duced or said differently a quantity. This may\n",
        "be considered as a first cluster of outcasts since\n",
        "they are linked with one another. A reason they\n",
        "may be outcasts is that they might be used in\n",
        "a slighly different manner from the other words,\n",
        "being used to evaluate quality or profitability of\n",
        "an exploitation rather than describing it.\n",
        "\n",
        "Another cluster seems to be iraq, kuwait,\n",
        "ecuador, and oil are locations that may in fact\n",
        "be used in the same way in a sentence, and for\n",
        "oil be used often with for locations.\n",
        "\n",
        "A third and final cluster can be seen as oil,\n",
        "energy, industry, petroleum which would\n",
        "make sense since those words would be used sim-\n",
        "ilarly in the documents studied here."
      ],
      "metadata": {
        "id": "4HVTaEqKRDck"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQg7l284V0oa"
      },
      "source": [
        "# Part 3. Prediction-based word vectors (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSNq-K6UzzDP"
      },
      "source": [
        "As discussed in class, more recently prediction-based word vectors have demonstrated better performance, such as word2vec and GloVe (which also utilizes the benefit of counts). If you're feeling adventurous, challenge yourself and try reading GloVe's original paper.\n",
        "\n",
        "Then run the following cells to load the GloVe vectors into memory. Note: If this is your first time to run these cells, i.e. download the embedding model, it will take a couple minutes to run. If you've run these cells before, rerunning them will load the model without redownloading it, which will take about 1 to 2 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqq7A2IWz011"
      },
      "source": [
        "def load_embedding_model():\n",
        "    \"\"\" Load GloVe Vectors\n",
        "        Return:\n",
        "            wv_from_bin: All 400000 embeddings, each lengh 200\n",
        "    \"\"\"\n",
        "    import gensim.downloader as api\n",
        "    wv_from_bin = api.load(\"glove-wiki-gigaword-200\")\n",
        "    print(\"Loaded vocab size %i\" % len(wv_from_bin.vocab.keys()))\n",
        "    return wv_from_bin"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYbJ59Jiz7OA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0746573d-6843-4ca9-bc31-be6a94e444a8"
      },
      "source": [
        "# -----------------------------------\n",
        "# Run Cell to Load Word Vectors\n",
        "# Note: This will take a couple minutes\n",
        "# -----------------------------------\n",
        "wv_from_bin = load_embedding_model()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded vocab size 400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edzctdyh0rDm"
      },
      "source": [
        "#### Note: If you are receiving a \"reset by peer\" error, rerun the cell to restart the download."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbGSRVPxjaT_"
      },
      "source": [
        "## Reducing dimensionality of Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXr1zGXSjddn"
      },
      "source": [
        "Let's directly compare the GloVe embeddings to those of the co-occurrence matrix. In order to avoid running out of memory, we will work with a sample of 10000 GloVe vectors instead. Run the following cells to:\n",
        "\n",
        "Put 10000 Glove vectors into a matrix M\n",
        "Run reduce_to_k_dim (your Truncated SVD function) to reduce the vectors from 200-dimensional to 2-dimensional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_xj1ApzjfOr"
      },
      "source": [
        "def get_matrix_of_vectors(wv_from_bin, required_words=['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'iraq']):\n",
        "    \"\"\" Put the GloVe vectors into a matrix M.\n",
        "        Param:\n",
        "            wv_from_bin: KeyedVectors object; the 400000 GloVe vectors loaded from file\n",
        "        Return:\n",
        "            M: numpy matrix shape (num words, 200) containing the vectors\n",
        "            word2ind: dictionary mapping each word to its row number in M\n",
        "    \"\"\"\n",
        "    import random\n",
        "    words = list(wv_from_bin.vocab.keys())\n",
        "    print(\"Shuffling words ...\")\n",
        "    random.seed(224)\n",
        "    random.shuffle(words)\n",
        "    words = words[:10000]\n",
        "    print(\"Putting %i words into word2ind and matrix M...\" % len(words))\n",
        "    word2ind = {}\n",
        "    M = []\n",
        "    curInd = 0\n",
        "    for w in words:\n",
        "        try:\n",
        "            M.append(wv_from_bin.word_vec(w))\n",
        "            word2ind[w] = curInd\n",
        "            curInd += 1\n",
        "        except KeyError:\n",
        "            continue\n",
        "    for w in required_words:\n",
        "        if w in words:\n",
        "            continue\n",
        "        try:\n",
        "            M.append(wv_from_bin.word_vec(w))\n",
        "            word2ind[w] = curInd\n",
        "            curInd += 1\n",
        "        except KeyError:\n",
        "            continue\n",
        "    M = np.stack(M)\n",
        "    print(\"Done.\")\n",
        "    return M, word2ind"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHVTZLiBjhN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220725f5-5723-4f0e-e3f5-4092c41c8da3"
      },
      "source": [
        "# -----------------------------------------------------------------\n",
        "# Run Cell to Reduce 200-Dimensional Word Embeddings to k Dimensions\n",
        "# Note: This should be quick to run\n",
        "# -----------------------------------------------------------------\n",
        "M, word2ind = get_matrix_of_vectors(wv_from_bin)\n",
        "M_reduced = reduce_to_k_dim(M, k=2)\n",
        "\n",
        "# Rescale (normalize) the rows to make them each of unit-length\n",
        "M_lengths = np.linalg.norm(M_reduced, axis=1)\n",
        "M_reduced_normalized = M_reduced / M_lengths[:, np.newaxis] # broadcasting"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffling words ...\n",
            "Putting 10000 words into word2ind and matrix M...\n",
            "Done.\n",
            "Running Truncated SVD over 10010 words...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdoZKWxijmHk"
      },
      "source": [
        "### Question 3.1: GloVe Plot Analysis [written] (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyDIugqjjo3R"
      },
      "source": [
        "Run the cell below to plot the 2D GloVe embeddings for ['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'iraq'].\n",
        "\n",
        "What clusters together in 2-dimensional embedding space? What doesn't cluster together that you think should have? How is the plot different from the one generated earlier from the co-occurrence matrix? What is a possible cause for the difference?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK438bCgjm98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "a2d97851-49c1-4289-84d9-88da7c9bf8b2"
      },
      "source": [
        "words = ['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'iraq']\n",
        "plot_embeddings(M_reduced_normalized, word2ind, words)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 396.790279 248.518125\" width=\"396.790279pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 396.790279 248.518125 \nL 396.790279 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"mc9d729bf6f\" style=\"stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\"/>\n    </defs>\n    <g clip-path=\"url(#p5b8450b044)\">\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"119.768605\" xlink:href=\"#mc9d729bf6f\" y=\"80.792248\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"45.321307\" xlink:href=\"#mc9d729bf6f\" y=\"214.756364\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"309.799241\" xlink:href=\"#mc9d729bf6f\" y=\"18.436544\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"349.684943\" xlink:href=\"#mc9d729bf6f\" y=\"17.090472\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"348.629341\" xlink:href=\"#mc9d729bf6f\" y=\"17.083636\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"241.018692\" xlink:href=\"#mc9d729bf6f\" y=\"28.834999\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"276.850422\" xlink:href=\"#mc9d729bf6f\" y=\"22.085787\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"172.727987\" xlink:href=\"#mc9d729bf6f\" y=\"51.208371\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"297.450423\" xlink:href=\"#mc9d729bf6f\" y=\"19.529295\"/>\n     <use style=\"fill:#7e1e9c;fill-opacity:0.5;stroke:#7e1e9c;stroke-opacity:0.5;stroke-width:10;\" x=\"303.114997\" xlink:href=\"#mc9d729bf6f\" y=\"18.987705\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m83fb787ef4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.866961\" xlink:href=\"#m83fb787ef4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(32.725555 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"105.096582\" xlink:href=\"#m83fb787ef4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(92.955176 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"165.326204\" xlink:href=\"#m83fb787ef4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(153.184797 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"225.555825\" xlink:href=\"#m83fb787ef4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(213.414419 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"285.785446\" xlink:href=\"#m83fb787ef4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(273.64404 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"346.015068\" xlink:href=\"#m83fb787ef4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.0 -->\n      <g transform=\"translate(338.063505 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mfa2acbae66\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfa2acbae66\" y=\"204.466807\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 208.266025)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfa2acbae66\" y=\"166.988759\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 170.787977)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfa2acbae66\" y=\"129.51071\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 133.309929)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfa2acbae66\" y=\"92.032662\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 95.831881)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfa2acbae66\" y=\"54.554614\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 58.353833)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfa2acbae66\" y=\"17.076566\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 20.875785)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_13\">\n    <!-- barrels -->\n    <defs>\n     <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n     <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n    </defs>\n    <g transform=\"translate(119.768605 80.792248)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"124.755859\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"164.119141\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"202.982422\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"264.505859\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"292.289062\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"text_14\">\n    <!-- bpd -->\n    <defs>\n     <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n     <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n    </defs>\n    <g transform=\"translate(45.321307 214.756364)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"126.953125\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_15\">\n    <!-- ecuador -->\n    <defs>\n     <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n     <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n     <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n    </defs>\n    <g transform=\"translate(309.799241 18.436544)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"61.523438\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"116.503906\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"179.882812\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"241.162109\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"304.638672\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"365.820312\" xlink:href=\"#DejaVuSans-114\"/>\n    </g>\n   </g>\n   <g id=\"text_16\">\n    <!-- energy -->\n    <defs>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n    </defs>\n    <g transform=\"translate(349.684943 17.090472)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"61.523438\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"124.902344\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"186.425781\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"225.789062\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"289.265625\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"text_17\">\n    <!-- industry -->\n    <defs>\n     <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n     <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n    </defs>\n    <g transform=\"translate(348.629341 17.083636)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"27.783203\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"91.162109\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"154.638672\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"218.017578\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"270.117188\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"309.326172\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"350.439453\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"text_18\">\n    <!-- kuwait -->\n    <defs>\n     <path d=\"M 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 31.109375 \nL 44.921875 54.6875 \nL 56.390625 54.6875 \nL 27.390625 29.109375 \nL 57.625 0 \nL 45.90625 0 \nL 18.109375 26.703125 \nL 18.109375 0 \nL 9.078125 0 \nz\n\" id=\"DejaVuSans-107\"/>\n     <path d=\"M 4.203125 54.6875 \nL 13.1875 54.6875 \nL 24.421875 12.015625 \nL 35.59375 54.6875 \nL 46.1875 54.6875 \nL 57.421875 12.015625 \nL 68.609375 54.6875 \nL 77.59375 54.6875 \nL 63.28125 0 \nL 52.6875 0 \nL 40.921875 44.828125 \nL 29.109375 0 \nL 18.5 0 \nz\n\" id=\"DejaVuSans-119\"/>\n    </defs>\n    <g transform=\"translate(241.018692 28.834999)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-107\"/>\n     <use x=\"54.785156\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"118.164062\" xlink:href=\"#DejaVuSans-119\"/>\n     <use x=\"199.951172\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"261.230469\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"289.013672\" xlink:href=\"#DejaVuSans-116\"/>\n    </g>\n   </g>\n   <g id=\"text_19\">\n    <!-- oil -->\n    <g transform=\"translate(276.850422 22.085787)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"61.181641\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"88.964844\" xlink:href=\"#DejaVuSans-108\"/>\n    </g>\n   </g>\n   <g id=\"text_20\">\n    <!-- output -->\n    <g transform=\"translate(172.727987 51.208371)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"61.181641\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"124.560547\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"163.769531\" xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"227.246094\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"290.625\" xlink:href=\"#DejaVuSans-116\"/>\n    </g>\n   </g>\n   <g id=\"text_21\">\n    <!-- petroleum -->\n    <defs>\n     <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n    </defs>\n    <g transform=\"translate(297.450423 19.529295)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"125\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"164.208984\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"203.072266\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"264.253906\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"292.037109\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"353.560547\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"416.939453\" xlink:href=\"#DejaVuSans-109\"/>\n    </g>\n   </g>\n   <g id=\"text_22\">\n    <!-- iraq -->\n    <defs>\n     <path d=\"M 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\nM 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nL 54.390625 -20.796875 \nL 45.40625 -20.796875 \nz\n\" id=\"DejaVuSans-113\"/>\n    </defs>\n    <g transform=\"translate(303.114997 18.987705)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"27.783203\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"68.896484\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"130.175781\" xlink:href=\"#DejaVuSans-113\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p5b8450b044\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39cCl0DQjuJN"
      },
      "source": [
        "Answer:\n",
        "\n",
        "As mentioned in question 2.5, the closeness of\n",
        "words to one another represents a similar mean-\n",
        "ing or usage in sentences. It can also mean they\n",
        "are often used together.\n",
        "\n",
        "First, it is important to point out that while\n",
        "the scale [1, 1] two-dimensional remains the\n",
        "same as in question 2.5, the graph is although\n",
        "representing a different range x-axis: [1, 0.1],\n",
        "y-axis: [0.2, 1] compared to x-axis: [0.30, 0.1],\n",
        "\n",
        "y-axis: [0.95, 1] for question 2.5. The values are\n",
        "thus more distributed throughout the range.\n",
        "Similarly to previous graph figure 3, most\n",
        "words are really close together in the upper cen-\n",
        "ter of the scale. Furthermore, the words that\n",
        "stick out from the pack are the same from those\n",
        "in figure 3.\n",
        "\n",
        "Although, the difference with bpd in this\n",
        "graph, figure 4 compared to bpd in figure 3 is\n",
        "that the point is much further down from other\n",
        "points meaning less related in meaning or usage.\n",
        "What is observed here is that bpd is excluded\n",
        "from its similar words. Furthermore, barrels\n",
        "and output are also separated from the other\n",
        "points but in a lesser manner. bpd and barrel\n",
        "should be close to one another since they are\n",
        "both measures of quantity. The output should\n",
        "also be relatively close as bpd represents the\n",
        "raw output for a day.\n",
        "\n",
        "While looking very similar to the previous\n",
        "graph figure 3 when omitting scale, bpd can-\n",
        "not be considered part of a cluster anymore.\n",
        "A possible reason for the difference between\n",
        "figure 3 from the previous question 3 and fig-\n",
        "ure 4 is that while co-occurence was used previ-\n",
        "ously meaning the times words occured next to\n",
        "each other, in this graph prediction-based word\n",
        "embedding is used, and the method to compute\n",
        "similarity may be slightly different.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toHZ2o-Ljwwm"
      },
      "source": [
        "## Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBZbtLYzj1R_"
      },
      "source": [
        "Now that we have word vectors, we need a way to quantify the similarity between individual words, according to these vectors. One such metric is cosine-similarity. We will be using this to find words that are \"close\" and \"far\" from one another.\n",
        "\n",
        "We can think of n-dimensional vectors as points in n-dimensional space. If we take this perspective L1 and L2 Distances help quantify the amount of space \"we must travel\" to get between these two points. Another approach is to examine the angle between two vectors. From trigonometry we know that:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLE4DOTNj69N"
      },
      "source": [
        "### Question 3.2: Words with Multiple Meanings (1.5 points) [code + written]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0LT0bH4kolN"
      },
      "source": [
        "Polysemes and homonyms are words that have more than one meaning (see this wiki page to learn more about the difference between polysemes and homonyms ). Find a word with at least two different meanings such that the top-10 most similar words (according to cosine similarity) contain related words from both meanings. For example, \"leaves\" has both \"go_away\" and \"a_structure_of_a_plant\" meaning in the top 10, and \"scoop\" has both \"handed_waffle_cone\" and \"lowdown\". You will probably need to try several polysemous or homonymic words before you find one.\n",
        "\n",
        "Please state the word you discover and the multiple meanings that occur in the top 10. Why do you think many of the polysemous or homonymic words you tried didn't work (i.e. the top-10 most similar words only contain one of the meanings of the words)?\n",
        "\n",
        "Note: You should use the wv_from_bin.most_similar(word) function to get the top 10 similar words. This function ranks all other words in the vocabulary with respect to their cosine similarity to the given word. For further assistance, please check the GenSim documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgoE4V3rj76o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de84274c-aafc-46cb-d918-68cf4015ae4f"
      },
      "source": [
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    # pprint.pprint(wv_from_bin.most_similar('sound')) # Example of failing one\n",
        "    pprint.pprint(wv_from_bin.most_similar('express'))\n",
        "\n",
        "    # ------------------"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('expressing', 0.5767321586608887),\n",
            " ('expressed', 0.5290095210075378),\n",
            " ('train', 0.5205782651901245),\n",
            " ('sympathy', 0.5139451622962952),\n",
            " ('trains', 0.5050660371780396),\n",
            " ('expresses', 0.49935826659202576),\n",
            " ('bus', 0.4954938292503357),\n",
            " ('regret', 0.49006834626197815),\n",
            " ('sorrow', 0.4864082932472229),\n",
            " ('travel', 0.47741514444351196)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z90e-p_jktYD"
      },
      "source": [
        "Answer: \n",
        "\n",
        "It is most probable that since the explored texts are published articles, most polysemous words are used in a certain sense and usually would not appear in both senses. For example '_sound_' which both means safe and a noise is only found as its noise definition. Although, in the case of express we can see that both the speed and transport definitions appear in the top 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBt1A0Y8kyqx"
      },
      "source": [
        "### Question 3.3: Synonyms & Antonyms (2 points) [code + written]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2gWr_Cvk3Tu"
      },
      "source": [
        "When considering Cosine Similarity, it's often more convenient to think of Cosine Distance, which is simply 1 - Cosine Similarity.\n",
        "\n",
        "Find three words  (w1,w2,w3)  where  w1  and  w2  are synonyms and  w1  and  w3  are antonyms, but Cosine Distance  (w1,w3)<  Cosine Distance  (w1,w2) .\n",
        "\n",
        "As an example,  w1 =\"happy\" is closer to  w3 =\"sad\" than to  w2 =\"cheerful\". Please find a different example that satisfies the above. Once you have found your example, please give a possible explanation for why this counter-intuitive result may have happened.\n",
        "\n",
        "You should use the the wv_from_bin.distance(w1, w2) function here in order to compute the cosine distance between two words. Please see the GenSim documentation for further assistance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRwHp4noktJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43d363d-f765-48fb-c51b-997c3a10aad1"
      },
      "source": [
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "\n",
        "    w1 = 'hello'\n",
        "    w2 = 'hi'\n",
        "    w3 = 'bye'\n",
        "\n",
        "    cos_w1_w2 = wv_from_bin.distance(w1, w2)\n",
        "    cos_w1_w3 = wv_from_bin.distance(w1, w3)\n",
        "\n",
        "    print(f'Cosine Distance w1-w2: {cos_w1_w2}')\n",
        "    print(f'Cosine Distance w1-w3: {cos_w1_w3}')\n",
        "\n",
        "    print(f'cosine Distance w1-w3 < w1-w2: {cos_w1_w3 < cos_w1_w2}')\n",
        "    # ------------------"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Distance w1-w2: 0.6250409185886383\n",
            "Cosine Distance w1-w3: 0.5616524815559387\n",
            "cosine Distance w1-w3 < w1-w2: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AD2asvrk7Y7"
      },
      "source": [
        "Answer:\n",
        "\n",
        "The cosine distance between two words is a measure of the distance between the vectors representing those words in a vector space. It is calculated by taking the angle between the vectors and converting it to a value between 0 and 1 using the formula 1 - cos(angle). Cosine distance ranges from 0 to 1, with a value of 0 indicating that the vectors are identical and a value of 1 indicating that the vectors are completely opposite.\n",
        "\n",
        "It is possible for the cosine distance between the words \"hello\" and \"bye\" to be lower than the cosine distance between the words \"hello\" and \"hi,\" even though \"bye\" and \"hello\" are antonyms and \"hi\" and \"hello\" are synonyms, depending on the vectors that are used to represent these words in a vector space.\n",
        "\n",
        "If the vectors for the words \"hello\" and \"hi\" are pointing in similar directions, and the vectors for the words \"hello\" and \"bye\" are also pointing in similar directions, but more similar than the vectors for \"hello\" and \"hi,\" the cosine distance between \"hello\" and \"bye\" will be lower than the cosine distance between \"hello\" and \"hi.\" This could happen if the vectors for \"bye\" and \"hello\" are more similar to each other than the vectors for \"hi\" and \"hello,\" for example.\n",
        "\n",
        "It's worth noting that the exact cosine distance between two words can vary depending on the context in which they are used and the other words that appear in the same context. In some cases, two words that are normally considered very different might have a lower cosine distance if they are used in similar contexts or if there are other words present that make the vectors for those words more similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0uNtlXZlAdy"
      },
      "source": [
        "### Question 3.4: Analogies with Word Vectors [written] (1.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqKCiSDhlEBf"
      },
      "source": [
        "Word vectors have been shown to sometimes exhibit the ability to solve analogies.\n",
        "\n",
        "As an example, for the analogy \"man : king :: woman : x\" (read: man is to king as woman is to x), what is x?\n",
        "\n",
        "In the cell below, we show you how to use word vectors to find x using the most_similar function from the GenSim documentation. The function finds words that are most similar to the words in the positive list and most dissimilar from the words in the negative list (while omitting the input words, which are often the most similar; see this paper). The answer to the analogy will have the highest cosine similarity (largest returned numerical value)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHlsY4kolA6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9135de8a-3344-43a9-c2c8-97c7097f7df8"
      },
      "source": [
        "# Run this cell to answer the analogy -- man : king :: woman : x\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'king'], negative=['man']))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.6978678703308105),\n",
            " ('princess', 0.6081745028495789),\n",
            " ('monarch', 0.5889754891395569),\n",
            " ('throne', 0.5775108933448792),\n",
            " ('prince', 0.5750998854637146),\n",
            " ('elizabeth', 0.546359658241272),\n",
            " ('daughter', 0.5399125814437866),\n",
            " ('kingdom', 0.5318052768707275),\n",
            " ('mother', 0.5168544054031372),\n",
            " ('crown', 0.5164472460746765)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv1gqPl5nQ4H"
      },
      "source": [
        "Let  m ,  k ,  w , and  x  denote the word vectors for man, king, woman, and the answer, respectively. Using only vectors  m ,  k ,  w , and the vector arithmetic operators  +  and    in your answer, what is the expression in which we are maximizing cosine similarity with  x ?\n",
        "\n",
        "Hint: Recall that word vectors are simply multi-dimensional vectors that represent a word. It might help to draw out a 2D example using arbitrary locations of each vector. Where would man and woman lie in the coordinate plane relative to king and the answer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zvj-YaOnTAY"
      },
      "source": [
        "Answer:\n",
        "\n",
        "The expression with which we maximise cosine\n",
        "similarity is the following:\n",
        "\n",
        "$$x = k  m + w$$\n",
        "\n",
        "If the man : king :: woman : x analogy is\n",
        "taken as example, and with the above expression\n",
        "in mind:\n",
        " - x would be the prediction (i.e : Queen)\n",
        " - k would be the word to transfer (i.e: king)\n",
        " - m would be the genre of the initial word (i.e: man)\n",
        " - w would be the targeted genre (i.e: woman)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLyzhOOfnuql"
      },
      "source": [
        "### Question 3.5: Finding Analogies [code + written] (1.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5xFEsKVnzT0"
      },
      "source": [
        "Find an example of analogy that holds according to these vectors (i.e. the intended word is ranked top). In your solution please state the full analogy in the form x:y :: a:b. If you believe the analogy is complicated, explain why the analogy holds in one or two sentences.\n",
        "\n",
        "Note: You may have to try many analogies to find one that works!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkrWfGGznRMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7248acfa-969e-48c9-e7cf-d8b4c6d08758"
      },
      "source": [
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    \n",
        "    # Run this cell to answer the analogy -- man : prince :: woman : x\n",
        "    print('First analogy: \"man : prince :: woman : x\":')\n",
        "    pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'prince'], negative=['man']))\n",
        "\n",
        "    # Run this cell to answer the analogy -- girl : sister :: boy : x\n",
        "    print('\\nSecond Analogy: \"girl : sister :: boy : x\": ')\n",
        "    pprint.pprint(wv_from_bin.most_similar(positive=['boy', 'sister'], negative=['girl']))\n",
        "    # ------------------"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First analogy: \"man : prince :: woman : x\":\n",
            "[('princess', 0.7453499436378479),\n",
            " ('duchess', 0.6067375540733337),\n",
            " ('daughter', 0.5600142478942871),\n",
            " ('queen', 0.5452842712402344),\n",
            " ('hrh', 0.5299034118652344),\n",
            " ('wife', 0.5115962028503418),\n",
            " ('marry', 0.5082696676254272),\n",
            " ('naruhito', 0.5037658214569092),\n",
            " ('mistress', 0.5026963949203491),\n",
            " ('crown', 0.4981675446033478)]\n",
            "\n",
            "Second Analogy: \"girl : sister :: boy : x\": \n",
            "[('brother', 0.7562326192855835),\n",
            " ('father', 0.7254698276519775),\n",
            " ('mother', 0.7100989818572998),\n",
            " ('son', 0.7058944702148438),\n",
            " ('cousin', 0.7000033855438232),\n",
            " ('daughter', 0.6871263384819031),\n",
            " ('uncle', 0.6804952025413513),\n",
            " ('siblings', 0.677232027053833),\n",
            " ('elder', 0.6522819995880127),\n",
            " ('nephew', 0.6461338996887207)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NygUqza7n8mn"
      },
      "source": [
        "Answer:\n",
        "\n",
        "Both `man : prince :: woman : x` and  `girl : sister :: boy : x` correctly identify the analogies. We thus have the feminine version of `prince` being `princess` and the masculine version of `sister` being `brother`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMbSmc52n-Ni"
      },
      "source": [
        "### Question 3.6: Incorrect Analogy [code + written] (1.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKhHs5uooAaD"
      },
      "source": [
        "Find an example of analogy that does not hold according to these vectors. In your solution, state the intended analogy in the form x:y :: a:b, and state the (incorrect) value of b according to the word vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayAfn_MPnzrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9cae946-5f24-4a31-da60-bcbdb540ef14"
      },
      "source": [
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "\n",
        "    # Run this cell to answer the analogy -- woman : wife :: man : b \n",
        "    # --> b should be husband\n",
        "    print('First analogy: \"woman : wife :: man : b\":')\n",
        "    missed_1 = wv_from_bin.most_similar(positive=['man', 'wife'], negative=['woman'])\n",
        "    pprint.pprint(missed_1)\n",
        "    print(f'Got \"{missed_1[0][0]}\" when expected \"husband\".')\n",
        "\n",
        "    # Run this cell to answer the analogy -- girl : brother :: boy : b\n",
        "    # --> b should be sister\n",
        "    print('\\nSecond Analogy: \"girl : brother :: boy : b\": ')\n",
        "    missed_2 = wv_from_bin.most_similar(positive=['girl', 'brother'], negative=['boy'])\n",
        "    pprint.pprint(missed_2)\n",
        "    print(f'Got \"{missed_2[0][0]}\" when expected \"sister\".')\n",
        "    # ------------------"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First analogy: \"woman : wife :: man : b\":\n",
            "[('father', 0.7467501163482666),\n",
            " ('brother', 0.745741069316864),\n",
            " ('husband', 0.7437037825584412),\n",
            " ('son', 0.7166001796722412),\n",
            " ('friend', 0.7085943222045898),\n",
            " ('his', 0.6684678792953491),\n",
            " ('cousin', 0.6388828754425049),\n",
            " ('daughter', 0.6335204243659973),\n",
            " ('mother', 0.6283376216888428),\n",
            " ('uncle', 0.6279417276382446)]\n",
            "Got \"father\" when expected \"husband\".\n",
            "\n",
            "Second Analogy: \"girl : brother :: boy : b\": \n",
            "[('daughter', 0.8058238625526428),\n",
            " ('cousin', 0.7796305418014526),\n",
            " ('son', 0.7571232914924622),\n",
            " ('wife', 0.7448716163635254),\n",
            " ('sister', 0.7441308498382568),\n",
            " ('father', 0.7369656562805176),\n",
            " ('niece', 0.7302137613296509),\n",
            " ('nephew', 0.7301906943321228),\n",
            " ('husband', 0.7162861824035645),\n",
            " ('mother', 0.7117223739624023)]\n",
            "Got \"daughter\" when expected \"sister\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsqq_EaXoDYl"
      },
      "source": [
        "Answer:\n",
        "\n",
        "Both `woman : wife :: man : b` and  `girl : brother :: boy : b` wrongly identified the analogies. We thus have the feminine version of `brother` being `daughter` instead of `sister` and the masculine version of `wife` being `father` instead of `husband`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sBlWGAmoGCy"
      },
      "source": [
        "### Question 3.7: Guided Analysis of Bias in Word Vectors [written] (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_rVPQteoINq"
      },
      "source": [
        "It's important to be cognizant of the biases (gender, race, sexual orientation etc.) implicit in our word embeddings. Bias can be dangerous because it can reinforce stereotypes through applications that employ these models.\n",
        "\n",
        "Run the cell below, to examine (a) which terms are most similar to \"woman\" and \"worker\" and most dissimilar to \"man\", and (b) which terms are most similar to \"man\" and \"worker\" and most dissimilar to \"woman\". Point out the difference between the list of female-associated words and the list of male-associated words, and explain how it is reflecting gender bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDlvsts2oBsp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb7c4e0-d90a-4c00-8672-7727c2db1edd"
      },
      "source": [
        "# Run this cell\n",
        "# Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be\n",
        "# most dissimilar from.\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'worker'], negative=['man']))\n",
        "print()\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['man', 'worker'], negative=['woman']))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('employee', 0.6375863552093506),\n",
            " ('workers', 0.6068919897079468),\n",
            " ('nurse', 0.5837947726249695),\n",
            " ('pregnant', 0.5363885164260864),\n",
            " ('mother', 0.5321309566497803),\n",
            " ('employer', 0.5127025842666626),\n",
            " ('teacher', 0.5099576711654663),\n",
            " ('child', 0.5096741914749146),\n",
            " ('homemaker', 0.5019454956054688),\n",
            " ('nurses', 0.4970572590827942)]\n",
            "\n",
            "[('workers', 0.6113258004188538),\n",
            " ('employee', 0.5983108282089233),\n",
            " ('working', 0.5615328550338745),\n",
            " ('laborer', 0.5442320108413696),\n",
            " ('unemployed', 0.5368517637252808),\n",
            " ('job', 0.5278826951980591),\n",
            " ('work', 0.5223963260650635),\n",
            " ('mechanic', 0.5088937282562256),\n",
            " ('worked', 0.505452036857605),\n",
            " ('factory', 0.4940453767776489)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BtOxfydoLZb"
      },
      "source": [
        "Answer:\n",
        "\n",
        "The list of female-associated words includes terms such as \"nurse,\" \"mother,\" \"teacher,\" and \"homemaker,\" which are often traditionally considered to be female-dominated occupations or roles. The list of male-associated words includes terms such as \"mechanic\" and \"laborer,\" which are also traditionally considered to be male-dominated occupations or roles.\n",
        "\n",
        "This difference between the two lists reflects gender bias, as it reflects the societal biases and stereotypes that have been encoded in the data used to train the word embeddings. These biases can have harmful consequences, as they can reinforce and perpetuate harmful stereotypes and discriminate against certain groups of people. It is important to be aware of these biases and take steps to mitigate them in any application that uses word embeddings or other language models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMsfYJyxoNWT"
      },
      "source": [
        "###  Question 3.8: Independent Analysis of Bias in Word Vectors [code + written] (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h42ajQDcodeV"
      },
      "source": [
        "Use the most_similar function to find another case where some bias is exhibited by the vectors. Please briefly explain the example of bias that you discover."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9d5cbx3oJsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c054541-089e-449c-a2e7-cf653033f8b8"
      },
      "source": [
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "\n",
        "    word_to_compare = \"wealthy\"\n",
        "\n",
        "    # Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be\n",
        "    # most dissimilar from.\n",
        "    pprint.pprint(wv_from_bin.most_similar(positive=['woman', word_to_compare], negative=['man']))\n",
        "    print()\n",
        "    pprint.pprint(wv_from_bin.most_similar(positive=['man', word_to_compare], negative=['woman']))\n",
        "\n",
        "    # ------------------"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('affluent', 0.6492576599121094),\n",
            " ('socialite', 0.5705443024635315),\n",
            " ('middle-class', 0.5464404225349426),\n",
            " ('aristocratic', 0.5330350399017334),\n",
            " ('businesswoman', 0.5314464569091797),\n",
            " ('marry', 0.5257409811019897),\n",
            " ('wealthier', 0.5169167518615723),\n",
            " ('elderly', 0.5112395882606506),\n",
            " ('marrying', 0.510892927646637),\n",
            " ('married', 0.5068483948707581)]\n",
            "\n",
            "[('wealthiest', 0.6119896173477173),\n",
            " ('businessman', 0.5537059307098389),\n",
            " ('rich', 0.5525563955307007),\n",
            " ('businessmen', 0.5454820394515991),\n",
            " ('affluent', 0.5427639484405518),\n",
            " ('richest', 0.5321693420410156),\n",
            " ('tycoons', 0.5197821855545044),\n",
            " ('billionaire', 0.5065683126449585),\n",
            " ('millionaire', 0.49499309062957764),\n",
            " ('fortune', 0.4918596148490906)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDBxYCeEolk5"
      },
      "source": [
        "Answer:\n",
        "\n",
        "The list of female-associated words includes terms such as `marry` and `marrying`, `married` ,which are often traditionally associated with wealthy women. Supposing that woman cannot make their own money and have to rely on men which is completely false. The list of male-associated words includes terms such as `businessman`, `tycoons`, `affluent`, and `billionaire`, which are also traditionally associated with men and wealth. But this time putting glory on the men again. This is hugely biased because a man could be a `son` or a `husband` as much as a woman can be a `businesswoman` or `affluent` of her own right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNaetQ4donRi"
      },
      "source": [
        "### Question 3.9: Thinking About Bias [written] (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mktU3tdqtzp"
      },
      "source": [
        "Give one explanation of how bias gets into the word vectors. What is an experiment that you could do to test for or to measure this source of bias?\n",
        "\n",
        "Write your answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "One way that bias can get into word vectors is through the data that is used to train the word embedding model. If the data used to train the model reflects societal biases and stereotypes, then the word vectors produced by the model may also reflect these biases.\n",
        "\n",
        "One experiment that could be used to test for or measure this source of bias is to evaluate the word vectors on a set of benchmarks specifically designed to measure bias. There are several such benchmarks available, such as the Word Embedding Association Test (WEAT) and the Word Embedding Association Test for Gender (WEAT-G). These benchmarks allows one to quantitatively measure the degree of bias present in a given set of word vectors by comparing the similarity between pairs of words that are related to a particular bias (e.g. gender, race, sexual orientation, etc.) against the similarity between pairs of words that are not related to that bias.\n",
        "\n",
        "Another way to test for or measure bias in word vectors is to manually examine the most similar words for a given word and see if the resulting list reflects societal biases and stereotypes. For example, if we find that the most similar words for the word \"woman\" include terms such as \"nurse,\" \"homemaker,\" and \"secretary,\" while the most similar words for the word \"man\" include terms such as \"businessman,\" \"engineer,\" and \"doctor,\" this may indicate that the word vectors are reflecting societal biases and stereotypes about the roles and occupations of men and women, which is what we have observed in this practical.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-1YihXSxubeS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXQ2d7OsmLl"
      },
      "source": [
        "# Part 4. Prediction-based sentence vectors (13 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOP9j0mV2rvU"
      },
      "source": [
        "Sentence embeddings are a more powerful representation than word embeddings. They allow you to have out-of-the-box sentence representation of sequences of tokens which is closer to what you would have in reality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ3pVRQ8wE4P"
      },
      "source": [
        "### Question 4.1: How would you represent a sentence with Glove? What are the limits of your proposed implementation? [written] (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1w30iYj0YJn"
      },
      "source": [
        "Answer:\n",
        "\n",
        "To represent a sentence with GloVe (Global Vectors for Word Representation), we can simply take the mean of the word vectors for all of the words in the sentence. This will give us a single vector that represents the overall meaning of the sentence.\n",
        "\n",
        "For example, given the sentence \"The cat sat on the mat,\" we can represent it with GloVe by taking the mean of the word vectors for \"the,\" \"cat,\" \"sat,\" \"on,\" \"the,\" and \"mat.\" This will give us a single vector that captures the overall meaning of the sentence.\n",
        "\n",
        "One limitation of this approach is that it does not take into account the order or arrangement of the words in the sentence. The meaning of a sentence can often be influenced by the order in which its words are arranged, and this information is lost when we simply take the mean of the word vectors.\n",
        "\n",
        "Another limitation is that this approach does not capture any context beyond the words themselves. In natural language, the meaning of a word can be influenced by the words that come before or after it, and this information is not captured by simply taking the mean of the word vectors.\n",
        "\n",
        "To overcome these limitations, more advanced approaches to sentence embedding may be used, such as using recurrent neural networks (RNNs) or transformers to encode the entire sentence and capture the context and order of the words within it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2n3vp8g3AEe"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9F_tbMr3CZT"
      },
      "source": [
        "%%capture\n",
        "!pip install -U sentence-transformers"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBTJnO606Tpc"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np "
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnidR9Gg2697"
      },
      "source": [
        "def load_embedding_model():\n",
        "    \"\"\" Load SentenceBERT Vectors\n",
        "        Return:\n",
        "            embedder: sentence embedder \n",
        "    \"\"\"\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    \n",
        "    embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    return embedder"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qzL9oBS4Zoc"
      },
      "source": [
        "%%capture\n",
        "embedder = load_embedding_model()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKkFzRHe6bEm"
      },
      "source": [
        "Inspired by the above, choose the appropriate way to plot the below clusters. Do they make sense to you? What would you improve to get a meaningful plot?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-o3T8Wz-Feb"
      },
      "source": [
        "### Question 4.2. Evaluate clustering quality of SentenceBERT. What makes it good at clustering sentences? Which method of the two below would you go for? [written] (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqHOmWtqyNo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e1c0964-e1b8-47b3-b3d2-c4dd033d1b1e"
      },
      "source": [
        "# Corpus with example sentences\n",
        "corpus = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'A man is eating pasta.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'The baby is carried by the woman',\n",
        "          'A man is riding a horse.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'Someone in a gorilla costume is playing a set of drums.',\n",
        "          'A cheetah is running behind its prey.',\n",
        "          'A cheetah chases prey on across a field.'\n",
        "          ]\n",
        "corpus_embeddings = embedder.encode(corpus)\n",
        "\n",
        "# Perform kmean clustering\n",
        "num_clusters = 5\n",
        "clustering_model = KMeans(n_clusters=num_clusters)\n",
        "clustering_model.fit(corpus_embeddings)\n",
        "cluster_assignment = clustering_model.labels_\n",
        "\n",
        "clustered_sentences = [[] for i in range(num_clusters)]\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "\n",
        "for i, cluster in enumerate(clustered_sentences):\n",
        "    print(\"Cluster \", i+1)\n",
        "    print(cluster)\n",
        "    print(\"\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster  1\n",
            "['A man is riding a horse.', 'A man is riding a white horse on an enclosed ground.']\n",
            "\n",
            "Cluster  2\n",
            "['A cheetah is running behind its prey.', 'A cheetah chases prey on across a field.']\n",
            "\n",
            "Cluster  3\n",
            "['The girl is carrying a baby.', 'The baby is carried by the woman']\n",
            "\n",
            "Cluster  4\n",
            "['A man is eating food.', 'A man is eating a piece of bread.', 'A man is eating pasta.']\n",
            "\n",
            "Cluster  5\n",
            "['A monkey is playing drums.', 'Someone in a gorilla costume is playing a set of drums.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4wF5uTy50Nt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8c91a5-7653-47a3-fd54-54b0190c33e9"
      },
      "source": [
        "# Corpus with example sentences\n",
        "corpus = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'A man is eating pasta.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'The baby is carried by the woman',\n",
        "          'A man is riding a horse.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'Someone in a gorilla costume is playing a set of drums.',\n",
        "          'A cheetah is running behind its prey.',\n",
        "          'A cheetah chases prey on across a field.'\n",
        "          ]\n",
        "corpus_embeddings = embedder.encode(corpus)\n",
        "\n",
        "# Normalize the embeddings to unit length\n",
        "corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "# Perform kmean clustering\n",
        "clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=1.5) #, affinity='cosine', linkage='average', distance_threshold=0.4)\n",
        "clustering_model.fit(corpus_embeddings)\n",
        "cluster_assignment = clustering_model.labels_\n",
        "\n",
        "clustered_sentences = {}\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    if cluster_id not in clustered_sentences:\n",
        "        clustered_sentences[cluster_id] = []\n",
        "\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "\n",
        "for i, cluster in clustered_sentences.items():\n",
        "    print(\"Cluster \", i+1)\n",
        "    print(cluster)\n",
        "    print(\"\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster  1\n",
            "['A man is eating food.', 'A man is eating a piece of bread.', 'A man is eating pasta.']\n",
            "\n",
            "Cluster  5\n",
            "['The girl is carrying a baby.', 'The baby is carried by the woman']\n",
            "\n",
            "Cluster  2\n",
            "['A man is riding a horse.', 'A man is riding a white horse on an enclosed ground.']\n",
            "\n",
            "Cluster  3\n",
            "['A monkey is playing drums.', 'Someone in a gorilla costume is playing a set of drums.']\n",
            "\n",
            "Cluster  4\n",
            "['A cheetah is running behind its prey.', 'A cheetah chases prey on across a field.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(clustered_sentences.items())"
      ],
      "metadata": {
        "id": "gY7mj5xzFqCI"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "\n",
        "def plot_dendrogram(model, **kwargs):\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "\n",
        "    # create the counts of samples under each node\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "\n",
        "    linkage_matrix = np.column_stack(\n",
        "        [model.children_, model.distances_, counts]\n",
        "    ).astype(float)\n",
        "\n",
        "    # Plot the corresponding dendrogram\n",
        "    dendrogram(linkage_matrix, **kwargs)\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "#X = iris.data\n",
        "X = data\n",
        "\n",
        "\n",
        "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
        "# plot the top three levels of the dendrogram\n",
        "plot_dendrogram(clustering_model, truncate_mode=\"level\", p=4)\n",
        "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "p0CaaHY_IjZA",
        "outputId": "daeb4987-753c-48db-df37-507056bdfd30"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"279.25pt\" version=\"1.1\" viewBox=\"0 0 378.465625 279.25\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 279.25 \nL 378.465625 279.25 \nL 378.465625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 239.758125 \nL 371.265625 239.758125 \nL 371.265625 22.318125 \nL 36.465625 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"text_1\">\n      <!-- 3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(47.866307 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"text_2\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(78.30267 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(108.739034 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"text_4\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(139.175398 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"text_5\">\n      <!-- 1 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(169.611761 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"text_6\">\n      <!-- 9 -->\n      <defs>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n      </defs>\n      <g transform=\"translate(200.048125 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"text_7\">\n      <!-- 10 -->\n      <g transform=\"translate(226.666989 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(260.920852 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"text_9\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(291.357216 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"text_10\">\n      <!-- 7 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(321.79358 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"text_11\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(352.229943 255.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_12\">\n     <!-- Number of points in node (or index of point if no parenthesis). -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n      <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n      <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n     </defs>\n     <g transform=\"translate(48.622656 269.970312)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"74.804688\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"138.183594\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"235.595703\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"299.072266\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"360.595703\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"401.708984\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"433.496094\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"494.677734\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"529.882812\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.669922\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"625.146484\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"686.328125\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"714.111328\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"777.490234\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"816.699219\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"868.798828\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"900.585938\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"928.369141\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"991.748047\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1023.535156\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1086.914062\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1148.095703\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1211.572266\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1273.095703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1304.882812\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"1343.896484\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1405.078125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1446.191406\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1477.978516\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1505.761719\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1569.140625\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1632.617188\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1692.390625\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"1751.570312\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1783.357422\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1844.539062\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"1879.744141\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1911.53125\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1975.007812\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"2036.189453\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"2063.972656\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"2127.351562\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"2166.560547\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"2198.347656\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"2226.130859\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"2261.335938\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"2293.123047\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"2356.501953\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"2417.683594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"2449.470703\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"2512.947266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"2574.226562\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"2613.089844\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"2674.613281\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"2737.992188\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"2777.201172\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"2840.580078\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"2902.103516\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"2954.203125\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"2981.986328\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"3034.085938\" xlink:href=\"#DejaVuSans-41\"/>\n      <use x=\"3073.099609\" xlink:href=\"#DejaVuSans-46\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m9e2bc47eb1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9e2bc47eb1\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.00 -->\n      <g transform=\"translate(7.2 243.557344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9e2bc47eb1\" y=\"214.149765\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.25 -->\n      <g transform=\"translate(7.2 217.948984)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9e2bc47eb1\" y=\"188.541405\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.50 -->\n      <g transform=\"translate(7.2 192.340623)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9e2bc47eb1\" y=\"162.933045\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.75 -->\n      <g transform=\"translate(7.2 166.732263)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9e2bc47eb1\" y=\"137.324684\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 1.00 -->\n      <g transform=\"translate(7.2 141.123903)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9e2bc47eb1\" y=\"111.716324\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 1.25 -->\n      <g transform=\"translate(7.2 115.515543)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9e2bc47eb1\" y=\"86.107964\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 1.50 -->\n      <g transform=\"translate(7.2 89.907183)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9e2bc47eb1\" y=\"60.499604\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 1.75 -->\n      <g transform=\"translate(7.2 64.298823)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9e2bc47eb1\" y=\"34.891244\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 2.00 -->\n      <g transform=\"translate(7.2 38.690463)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"LineCollection_1\">\n    <path clip-path=\"url(#p978e46a268)\" d=\"M 51.683807 239.758125 \nL 51.683807 170.474692 \nL 82.12017 170.474692 \nL 82.12017 239.758125 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"LineCollection_2\">\n    <path clip-path=\"url(#p978e46a268)\" d=\"M 142.992898 239.758125 \nL 142.992898 168.104043 \nL 173.429261 168.104043 \nL 173.429261 239.758125 \n\" style=\"fill:none;stroke:#2ca02c;stroke-width:1.5;\"/>\n    <path clip-path=\"url(#p978e46a268)\" d=\"M 112.556534 239.758125 \nL 112.556534 144.623877 \nL 158.21108 144.623877 \nL 158.21108 168.104043 \n\" style=\"fill:none;stroke:#2ca02c;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"LineCollection_3\">\n    <path clip-path=\"url(#p978e46a268)\" d=\"M 203.865625 239.758125 \nL 203.865625 179.213347 \nL 234.301989 179.213347 \nL 234.301989 239.758125 \n\" style=\"fill:none;stroke:#d62728;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"LineCollection_4\">\n    <path clip-path=\"url(#p978e46a268)\" d=\"M 264.738352 239.758125 \nL 264.738352 165.450745 \nL 295.174716 165.450745 \nL 295.174716 239.758125 \n\" style=\"fill:none;stroke:#9467bd;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"LineCollection_5\">\n    <path clip-path=\"url(#p978e46a268)\" d=\"M 325.61108 239.758125 \nL 325.61108 153.234091 \nL 356.047443 153.234091 \nL 356.047443 239.758125 \n\" style=\"fill:none;stroke:#8c564b;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"LineCollection_6\">\n    <path clip-path=\"url(#p978e46a268)\" d=\"M 279.956534 165.450745 \nL 279.956534 62.617432 \nL 340.829261 62.617432 \nL 340.829261 153.234091 \n\" style=\"fill:none;stroke:#1f77b4;stroke-width:1.5;\"/>\n    <path clip-path=\"url(#p978e46a268)\" d=\"M 219.083807 179.213347 \nL 219.083807 56.373708 \nL 310.392898 56.373708 \nL 310.392898 62.617432 \n\" style=\"fill:none;stroke:#1f77b4;stroke-width:1.5;\"/>\n    <path clip-path=\"url(#p978e46a268)\" d=\"M 135.383807 144.623877 \nL 135.383807 42.394076 \nL 264.738352 42.394076 \nL 264.738352 56.373708 \n\" style=\"fill:none;stroke:#1f77b4;stroke-width:1.5;\"/>\n    <path clip-path=\"url(#p978e46a268)\" d=\"M 66.901989 170.474692 \nL 66.901989 32.672411 \nL 200.06108 32.672411 \nL 200.06108 42.394076 \n\" style=\"fill:none;stroke:#1f77b4;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 239.758125 \nL 36.465625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 239.758125 \nL 371.265625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 239.758125 \nL 371.265625 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 22.318125 \nL 371.265625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_22\">\n    <!-- Hierarchical Clustering Dendrogram -->\n    <defs>\n     <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 43.015625 \nL 55.515625 43.015625 \nL 55.515625 72.90625 \nL 65.375 72.90625 \nL 65.375 0 \nL 55.515625 0 \nL 55.515625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-72\"/>\n     <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     <path d=\"M 64.40625 67.28125 \nL 64.40625 56.890625 \nQ 59.421875 61.53125 53.78125 63.8125 \nQ 48.140625 66.109375 41.796875 66.109375 \nQ 29.296875 66.109375 22.65625 58.46875 \nQ 16.015625 50.828125 16.015625 36.375 \nQ 16.015625 21.96875 22.65625 14.328125 \nQ 29.296875 6.6875 41.796875 6.6875 \nQ 48.140625 6.6875 53.78125 8.984375 \nQ 59.421875 11.28125 64.40625 15.921875 \nL 64.40625 5.609375 \nQ 59.234375 2.09375 53.4375 0.328125 \nQ 47.65625 -1.421875 41.21875 -1.421875 \nQ 24.65625 -1.421875 15.125 8.703125 \nQ 5.609375 18.84375 5.609375 36.375 \nQ 5.609375 53.953125 15.125 64.078125 \nQ 24.65625 74.21875 41.21875 74.21875 \nQ 47.75 74.21875 53.53125 72.484375 \nQ 59.328125 70.75 64.40625 67.28125 \nz\n\" id=\"DejaVuSans-67\"/>\n     <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     <path d=\"M 19.671875 64.796875 \nL 19.671875 8.109375 \nL 31.59375 8.109375 \nQ 46.6875 8.109375 53.6875 14.9375 \nQ 60.6875 21.78125 60.6875 36.53125 \nQ 60.6875 51.171875 53.6875 57.984375 \nQ 46.6875 64.796875 31.59375 64.796875 \nz\nM 9.8125 72.90625 \nL 30.078125 72.90625 \nQ 51.265625 72.90625 61.171875 64.09375 \nQ 71.09375 55.28125 71.09375 36.53125 \nQ 71.09375 17.671875 61.125 8.828125 \nQ 51.171875 0 30.078125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-68\"/>\n    </defs>\n    <g transform=\"translate(95.997813 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"75.195312\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"102.978516\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"164.501953\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"205.615234\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"266.894531\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"305.757812\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"360.738281\" xlink:href=\"#DejaVuSans-104\"/>\n     <use x=\"424.117188\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"451.900391\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"506.880859\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"568.160156\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"595.943359\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"627.730469\" xlink:href=\"#DejaVuSans-67\"/>\n     <use x=\"697.554688\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"725.337891\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"788.716797\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"840.816406\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"880.025391\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"941.548828\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"982.662109\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"1010.445312\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"1073.824219\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"1137.300781\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1169.087891\" xlink:href=\"#DejaVuSans-68\"/>\n     <use x=\"1246.089844\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1307.613281\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"1370.992188\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"1434.46875\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"1473.332031\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"1534.513672\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"1597.990234\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"1639.103516\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"1700.382812\" xlink:href=\"#DejaVuSans-109\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p978e46a268\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "SentenceBERT is a type of transformer-based language model that has been pre-trained on a large dataset of sentences. It is designed to be able to understand the meaning and context of a sentence and to be able to represent that meaning in a numerical form, known as an embedding. This ability to represent the meaning of a sentence in a numerical form makes SentenceBERT well-suited for use in natural language processing tasks such as sentence clustering.\n",
        "\n",
        "There are several factors that contribute to the effectiveness of SentenceBERT for clustering sentences:\n",
        "\n",
        " 1. Pre-training on a large dataset: By pre-training SentenceBERT on a large dataset of sentences, it has learned to understand the meaning and context of a wide range of sentences, which makes it better at understanding the meaning of new sentences it has not seen before.\n",
        " 2. Use of transformer architecture: The transformer architecture used in SentenceBERT allows it to capture long-range dependencies between words in a sentence, which is important for understanding the meaning of a sentence.\n",
        " 3. Attention mechanism: The attention mechanism in SentenceBERT allows it to focus on specific words or phrases in a sentence and to weight their importance when representing the meaning of the sentence. This can be useful for identifying key phrases that are important for clustering sentences.\n",
        " 4. Sentence embeddings: SentenceBERT produces sentence embeddings that represent the meaning of a sentence in a numerical form. These embeddings can be used to compare the similarity between sentences, which is useful for clustering.\n",
        "\n",
        "Overall, the combination of these factors makes SentenceBERT a powerful tool for clustering sentences and for other natural language processing tasks."
      ],
      "metadata": {
        "id": "Q4xghQ7f3X1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: (which of the two methods).\n",
        "\n",
        "In the term of the answers both methods obtain the exact same results in this case. Although, there is a clear way to distinguish both technics:\n",
        " - Agglomerative Clustering: \"Recursively merges pair of clusters of sample data; uses linkage distance.\" - [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html).\n",
        "  - Although is computationally expensive. - [2.3.6. Hierarchical clustering - sklearn's doc](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering)\n",
        " - K-means Clustering: \"In practice, the k-means algorithm is very fast (one of the fastest clustering algorithms available), but it falls in local minima. Thats why it can be useful to restart it several times.\" - [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
        "\n",
        "It thus means that a choice needs to be made between quality of prediction and optimisation / complexity. If the goal is to get a somewhat correct result very fast, then K-means is one of the fastest clustering algorithms. Although it has a limit in the number of connections it looks for meaning it may be less precise than Agglomerative Clustering. On its end agglomerative clustering does not fall in nearly as many problems in terms of local minima of prediction constraints. It will create as many pairs (clusters) as needed and compare each one again each other pair until having the best clusters. This makes it much more reliable but also much slower. If the importance is placed on results quality and the corpus is resonable, Agglomerative clustering may be a great option. On the other end, if speed is a top priority or the corpus is extremly large, using K-means may seem to be a better option."
      ],
      "metadata": {
        "id": "eoUVKg2CKWo0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44mDLKmVyOUu"
      },
      "source": [
        "### Question 4.3: SentenceBERT Plot Analysis [written] (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_ykELvWt7ZX"
      },
      "source": [
        "Plot the above corpus with your favorite method in a 2-dimensional space. Comment on the output. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_co_occurrence_matrix(corpus, window_size):\n",
        "\n",
        "    words = sorted(list(set([word.replace('.', '') for words in corpus for word in words.split(' ')])))\n",
        "    num_words = len(words)\n",
        "\n",
        "    M = np.zeros((num_words, num_words))\n",
        "    word2Ind = dict(zip(words, range(num_words)))\n",
        "\n",
        "    for doc in corpus:\n",
        "        doc = doc.split()\n",
        "        cur_idx = 0\n",
        "        doc_len = len(doc)\n",
        "\n",
        "        while cur_idx < doc_len:\n",
        "            left = max(cur_idx - window_size, 0)\n",
        "            right = min(cur_idx + window_size + 1, doc_len)\n",
        "            words_to_add = doc[left : cur_idx] + doc[cur_idx + 1 : right]\n",
        "            focus_word = doc[cur_idx].replace('.', '')\n",
        "\n",
        "            for word in words_to_add:\n",
        "                word = word.replace('.', '')\n",
        "                outside_idx = word2Ind[word]\n",
        "                M[outside_idx, word2Ind[focus_word]] += 1\n",
        "\n",
        "            cur_idx += 1\n",
        "\n",
        "    return M, word2Ind"
      ],
      "metadata": {
        "id": "IHEh-AexO0om"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_embeddings(M_reduced, word2ind, word_lists, w, h):\n",
        "    \"\"\" Plot in a scatterplot the embeddings of the words specified in the list \"words\".\n",
        "        NOTE: do not plot all the words listed in M_reduced / word2ind.\n",
        "        Include a label next to each point.\n",
        "        \n",
        "        Params:\n",
        "            M_reduced (numpy matrix of shape (number of unique words in the corpus , 2)): matrix of 2-dimensioal word embeddings\n",
        "            word2ind (dict): dictionary that maps word to indices for matrix M\n",
        "            words (list of strings): words whose embeddings we want to visualize\n",
        "    \"\"\"\n",
        "\n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    fig, axs = plt.subplots(h, w, figsize=(10, 3 * h))\n",
        "\n",
        "    plt.subplots_adjust(left=0.1,\n",
        "                    bottom=0.1, \n",
        "                    right=0.9, \n",
        "                    top=0.9, \n",
        "                    wspace=0.4, \n",
        "                    hspace=0.4)\n",
        "    w_curr = 0\n",
        "    h_curr = 0\n",
        "\n",
        "    for words, title in word_lists:\n",
        "        word_indexes_to_plot = [word2ind[word] for word in words]\n",
        "        values_to_plot = [M_reduced[word] for word in word_indexes_to_plot]\n",
        "\n",
        "        x = [item[1] for item in values_to_plot]\n",
        "        y = [item[0] for item in values_to_plot]\n",
        "\n",
        "        axs[h_curr, w_curr].scatter(x, y)\n",
        "        axs[h_curr, w_curr].set_title(title)\n",
        "        #plt.setp(ax, color='#7E1E9C', linewidth=10.0, alpha=0.5)\n",
        "\n",
        "        for i, text in enumerate(words):\n",
        "            axs[h_curr, w_curr].annotate(text, (x[i], y[i]))\n",
        "\n",
        "\n",
        "\n",
        "        if w_curr == w - 1:\n",
        "            w_curr = 0\n",
        "            h_curr += 1\n",
        "        else:\n",
        "            w_curr += 1\n",
        "\n",
        "    for ax in axs.flat:\n",
        "        if not bool(ax.has_data()):\n",
        "            fig.delaxes(ax)\n",
        "    fig.show()\n",
        "    \n",
        "    # -----------------"
      ],
      "metadata": {
        "id": "JLsvgmbsU6H7"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M, word2ind = compute_co_occurrence_matrix(corpus, 1)\n",
        "M_reduced = reduce_to_k_dim(M, k=2)\n",
        "\n",
        "words = sorted(list(set([word for words in corpus for word in words.split()])))\n",
        "# Rescale (normalize) the rows to make them each of unit-length\n",
        "M_lengths = np.linalg.norm(M_reduced, axis=1)\n",
        "M_reduced_normalized = M_reduced / M_lengths[:, np.newaxis] # broadcasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyVS1529Nc4m",
        "outputId": "27f6144e-7286-444e-828c-03ad1ee7729e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Truncated SVD over 41 words...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\n",
        "    (['man', 'eating', 'pasta', 'bread', 'food'], 'Cluster 1 - eating'),\n",
        "    (['man', 'riding', 'horse', 'white', 'ground', 'food'], 'cluster 2 + food - riding'), \n",
        "    (['monkey', 'playing', 'drums', 'costume', 'gorilla', 'food'], 'cluster 3 + food - Monkeys and drums'),\n",
        "    (['cheetah', 'running', 'behind', 'chases' ,'food'], 'cluster 4 + food - Cheetahs'),\n",
        "    (['baby', 'girl', 'woman', 'carrying', 'carried', 'food'], 'cluster 5 + food - Babies')\n",
        "]\n",
        "plot_embeddings(M_reduced_normalized, word2ind, words, 2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "nfAj6fGoUJRL",
        "outputId": "b2545ad6-6e86-49a7-ba0f-c833f08c28b9"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x648 with 5 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"564.59625pt\" version=\"1.1\" viewBox=\"0 0 656.017472 564.59625\" width=\"656.017472pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 564.59625 \nL 656.017472 564.59625 \nL 656.017472 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 49.190625 158.739178 \nL 289.190625 158.739178 \nL 289.190625 22.318125 \nL 49.190625 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m291bf2d360\" style=\"stroke:#1f77b4;\"/>\n    </defs>\n    <g clip-path=\"url(#p18dd5531c6)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.099716\" xlink:href=\"#m291bf2d360\" y=\"152.538221\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.245747\" xlink:href=\"#m291bf2d360\" y=\"152.11025\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"278.281534\" xlink:href=\"#m291bf2d360\" y=\"152.201605\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"139.295867\" xlink:href=\"#m291bf2d360\" y=\"28.519082\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"278.281534\" xlink:href=\"#m291bf2d360\" y=\"152.201605\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m10062fec22\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"76.695245\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(64.553839 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"107.546176\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(95.40477 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.397107\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(126.255701 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"169.248038\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.0 -->\n      <g transform=\"translate(161.296476 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.098969\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.2 -->\n      <g transform=\"translate(192.147407 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.9499\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.4 -->\n      <g transform=\"translate(222.998337 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"261.800831\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.6 -->\n      <g transform=\"translate(253.849268 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"me092e2005c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"155.534491\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.7 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(26.2875 159.33371)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"110.328\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(26.2875 114.127219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"65.12151\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.9 -->\n      <defs>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n      </defs>\n      <g transform=\"translate(26.2875 68.920729)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 49.190625 158.739178 \nL 49.190625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 289.190625 158.739178 \nL 289.190625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 49.190625 158.739178 \nL 289.190625 158.739178 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 49.190625 22.318125 \nL 289.190625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_11\">\n    <!-- man -->\n    <defs>\n     <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n     <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n    </defs>\n    <g transform=\"translate(60.099716 152.538221)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"158.691406\" xlink:href=\"#DejaVuSans-110\"/>\n    </g>\n   </g>\n   <g id=\"text_12\">\n    <!-- eating -->\n    <defs>\n     <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n     <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n    </defs>\n    <g transform=\"translate(60.245747 152.11025)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"61.523438\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"122.802734\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"162.011719\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"189.794922\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"253.173828\" xlink:href=\"#DejaVuSans-103\"/>\n    </g>\n   </g>\n   <g id=\"text_13\">\n    <!-- pasta -->\n    <defs>\n     <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n    </defs>\n    <g transform=\"translate(278.281534 152.201605)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"124.755859\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"176.855469\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"216.064453\" xlink:href=\"#DejaVuSans-97\"/>\n    </g>\n   </g>\n   <g id=\"text_14\">\n    <!-- bread -->\n    <defs>\n     <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n    </defs>\n    <g transform=\"translate(139.295867 28.519082)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"102.339844\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"163.863281\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"225.142578\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_15\">\n    <!-- food -->\n    <defs>\n     <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n     <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n    </defs>\n    <g transform=\"translate(278.281534 152.201605)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"35.205078\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"96.386719\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"157.568359\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_16\">\n    <!-- Cluster 1 - eating -->\n    <defs>\n     <path d=\"M 64.40625 67.28125 \nL 64.40625 56.890625 \nQ 59.421875 61.53125 53.78125 63.8125 \nQ 48.140625 66.109375 41.796875 66.109375 \nQ 29.296875 66.109375 22.65625 58.46875 \nQ 16.015625 50.828125 16.015625 36.375 \nQ 16.015625 21.96875 22.65625 14.328125 \nQ 29.296875 6.6875 41.796875 6.6875 \nQ 48.140625 6.6875 53.78125 8.984375 \nQ 59.421875 11.28125 64.40625 15.921875 \nL 64.40625 5.609375 \nQ 59.234375 2.09375 53.4375 0.328125 \nQ 47.65625 -1.421875 41.21875 -1.421875 \nQ 24.65625 -1.421875 15.125 8.703125 \nQ 5.609375 18.84375 5.609375 36.375 \nQ 5.609375 53.953125 15.125 64.078125 \nQ 24.65625 74.21875 41.21875 74.21875 \nQ 47.75 74.21875 53.53125 72.484375 \nQ 59.328125 70.75 64.40625 67.28125 \nz\n\" id=\"DejaVuSans-67\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n     <path d=\"M 4.890625 31.390625 \nL 31.203125 31.390625 \nL 31.203125 23.390625 \nL 4.890625 23.390625 \nz\n\" id=\"DejaVuSans-45\"/>\n    </defs>\n    <g transform=\"translate(117.193125 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-67\"/>\n     <use x=\"69.824219\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"97.607422\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"160.986328\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"213.085938\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"252.294922\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"313.818359\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"354.931641\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"386.71875\" xlink:href=\"#DejaVuSans-49\"/>\n     <use x=\"450.341797\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"482.128906\" xlink:href=\"#DejaVuSans-45\"/>\n     <use x=\"518.212891\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"550\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"611.523438\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"672.802734\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"712.011719\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"739.794922\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"803.173828\" xlink:href=\"#DejaVuSans-103\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 385.190625 158.739178 \nL 625.190625 158.739178 \nL 625.190625 22.318125 \nL 385.190625 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_2\">\n    <g clip-path=\"url(#pa964f21a9d)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"396.099716\" xlink:href=\"#m291bf2d360\" y=\"152.538221\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"396.421833\" xlink:href=\"#m291bf2d360\" y=\"149.656551\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"411.264898\" xlink:href=\"#m291bf2d360\" y=\"33.211366\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"411.950411\" xlink:href=\"#m291bf2d360\" y=\"28.519082\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"404.204597\" xlink:href=\"#m291bf2d360\" y=\"84.862119\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"614.281534\" xlink:href=\"#m291bf2d360\" y=\"151.509032\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_8\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"389.557047\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0.75 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(374.234391 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"428.120711\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 0.50 -->\n      <g transform=\"translate(412.798054 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"466.684374\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 0.25 -->\n      <g transform=\"translate(451.361718 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"505.248038\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 0.00 -->\n      <g transform=\"translate(494.115226 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"543.811702\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 0.25 -->\n      <g transform=\"translate(532.678889 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"582.375365\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 0.50 -->\n      <g transform=\"translate(571.242553 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"620.939029\" xlink:href=\"#m10062fec22\" y=\"158.739178\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 0.75 -->\n      <g transform=\"translate(609.806217 173.337615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_4\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"385.190625\" xlink:href=\"#me092e2005c\" y=\"134.055767\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 0.72 -->\n      <g transform=\"translate(355.925 137.854986)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"385.190625\" xlink:href=\"#me092e2005c\" y=\"106.412326\"/>\n      </g>\n     </g>\n     <g id=\"text_25\">\n      <!-- 0.74 -->\n      <g transform=\"translate(355.925 110.211544)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"385.190625\" xlink:href=\"#me092e2005c\" y=\"78.768884\"/>\n      </g>\n     </g>\n     <g id=\"text_26\">\n      <!-- 0.76 -->\n      <g transform=\"translate(355.925 82.568103)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"385.190625\" xlink:href=\"#me092e2005c\" y=\"51.125442\"/>\n      </g>\n     </g>\n     <g id=\"text_27\">\n      <!-- 0.78 -->\n      <g transform=\"translate(355.925 54.924661)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"385.190625\" xlink:href=\"#me092e2005c\" y=\"23.482001\"/>\n      </g>\n     </g>\n     <g id=\"text_28\">\n      <!-- 0.80 -->\n      <g transform=\"translate(355.925 27.28122)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 385.190625 158.739178 \nL 385.190625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 625.190625 158.739178 \nL 625.190625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 385.190625 158.739178 \nL 625.190625 158.739178 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 385.190625 22.318125 \nL 625.190625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_29\">\n    <!-- man -->\n    <g transform=\"translate(396.099716 152.538221)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"158.691406\" xlink:href=\"#DejaVuSans-110\"/>\n    </g>\n   </g>\n   <g id=\"text_30\">\n    <!-- riding -->\n    <g transform=\"translate(396.421833 149.656551)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"41.113281\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"68.896484\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"132.373047\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"160.15625\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"223.535156\" xlink:href=\"#DejaVuSans-103\"/>\n    </g>\n   </g>\n   <g id=\"text_31\">\n    <!-- horse -->\n    <defs>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n    </defs>\n    <g transform=\"translate(411.264898 33.211366)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-104\"/>\n     <use x=\"63.378906\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"124.560547\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"165.673828\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"217.773438\" xlink:href=\"#DejaVuSans-101\"/>\n    </g>\n   </g>\n   <g id=\"text_32\">\n    <!-- white -->\n    <defs>\n     <path d=\"M 4.203125 54.6875 \nL 13.1875 54.6875 \nL 24.421875 12.015625 \nL 35.59375 54.6875 \nL 46.1875 54.6875 \nL 57.421875 12.015625 \nL 68.609375 54.6875 \nL 77.59375 54.6875 \nL 63.28125 0 \nL 52.6875 0 \nL 40.921875 44.828125 \nL 29.109375 0 \nL 18.5 0 \nz\n\" id=\"DejaVuSans-119\"/>\n    </defs>\n    <g transform=\"translate(411.950411 28.519082)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-119\"/>\n     <use x=\"81.787109\" xlink:href=\"#DejaVuSans-104\"/>\n     <use x=\"145.166016\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"172.949219\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"212.158203\" xlink:href=\"#DejaVuSans-101\"/>\n    </g>\n   </g>\n   <g id=\"text_33\">\n    <!-- ground -->\n    <g transform=\"translate(404.204597 84.862119)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"102.339844\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"163.521484\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"226.900391\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"290.279297\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_34\">\n    <!-- food -->\n    <g transform=\"translate(614.281534 151.509032)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"35.205078\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"96.386719\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"157.568359\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_35\">\n    <!-- cluster 2 + food - riding -->\n    <defs>\n     <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n     <path d=\"M 46 62.703125 \nL 46 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 46 27.203125 \nL 46 0 \nL 37.796875 0 \nL 37.796875 27.203125 \nL 10.59375 27.203125 \nL 10.59375 35.5 \nL 37.796875 35.5 \nL 37.796875 62.703125 \nz\n\" id=\"DejaVuSans-43\"/>\n    </defs>\n    <g transform=\"translate(433.756875 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"54.980469\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"82.763672\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"146.142578\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"198.242188\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"237.451172\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"298.974609\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"340.087891\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"371.875\" xlink:href=\"#DejaVuSans-50\"/>\n     <use x=\"435.498047\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"467.285156\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"551.074219\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"582.861328\" xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"618.066406\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"679.248047\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"740.429688\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"803.90625\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"835.693359\" xlink:href=\"#DejaVuSans-45\"/>\n     <use x=\"871.777344\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"903.564453\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"944.677734\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"972.460938\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"1035.9375\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"1063.720703\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"1127.099609\" xlink:href=\"#DejaVuSans-103\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_12\">\n    <path d=\"M 49.190625 349.728651 \nL 289.190625 349.728651 \nL 289.190625 213.307599 \nL 49.190625 213.307599 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_3\">\n    <g clip-path=\"url(#p207673fcca)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.099716\" xlink:href=\"#m291bf2d360\" y=\"343.527694\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.329091\" xlink:href=\"#m291bf2d360\" y=\"342.829413\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"275.744689\" xlink:href=\"#m291bf2d360\" y=\"335.630436\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"62.766049\" xlink:href=\"#m291bf2d360\" y=\"335.587812\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"132.074799\" xlink:href=\"#m291bf2d360\" y=\"219.508556\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"278.281534\" xlink:href=\"#m291bf2d360\" y=\"343.177764\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_5\">\n    <g id=\"xtick_15\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"76.695245\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_36\">\n      <!-- 0.6 -->\n      <g transform=\"translate(64.553839 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"107.546176\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_37\">\n      <!-- 0.4 -->\n      <g transform=\"translate(95.40477 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_17\">\n     <g id=\"line2d_25\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.397107\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_38\">\n      <!-- 0.2 -->\n      <g transform=\"translate(126.255701 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_18\">\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"169.248038\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_39\">\n      <!-- 0.0 -->\n      <g transform=\"translate(161.296476 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_19\">\n     <g id=\"line2d_27\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.098969\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_40\">\n      <!-- 0.2 -->\n      <g transform=\"translate(192.147407 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_20\">\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.9499\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_41\">\n      <!-- 0.4 -->\n      <g transform=\"translate(222.998337 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_21\">\n     <g id=\"line2d_29\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"261.800831\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_42\">\n      <!-- 0.6 -->\n      <g transform=\"translate(253.849268 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_6\">\n    <g id=\"ytick_9\">\n     <g id=\"line2d_30\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"346.642483\"/>\n      </g>\n     </g>\n     <g id=\"text_43\">\n      <!-- 0.70 -->\n      <g transform=\"translate(19.925 350.441702)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_31\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"323.145161\"/>\n      </g>\n     </g>\n     <g id=\"text_44\">\n      <!-- 0.75 -->\n      <g transform=\"translate(19.925 326.94438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_32\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"299.647839\"/>\n      </g>\n     </g>\n     <g id=\"text_45\">\n      <!-- 0.80 -->\n      <g transform=\"translate(19.925 303.447058)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_33\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"276.150518\"/>\n      </g>\n     </g>\n     <g id=\"text_46\">\n      <!-- 0.85 -->\n      <g transform=\"translate(19.925 279.949736)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_34\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"252.653196\"/>\n      </g>\n     </g>\n     <g id=\"text_47\">\n      <!-- 0.90 -->\n      <g transform=\"translate(19.925 256.452415)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_35\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"229.155874\"/>\n      </g>\n     </g>\n     <g id=\"text_48\">\n      <!-- 0.95 -->\n      <g transform=\"translate(19.925 232.955093)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 49.190625 349.728651 \nL 49.190625 213.307599 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 289.190625 349.728651 \nL 289.190625 213.307599 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 49.190625 349.728651 \nL 289.190625 349.728651 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 49.190625 213.307599 \nL 289.190625 213.307599 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_49\">\n    <!-- monkey -->\n    <defs>\n     <path d=\"M 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 31.109375 \nL 44.921875 54.6875 \nL 56.390625 54.6875 \nL 27.390625 29.109375 \nL 57.625 0 \nL 45.90625 0 \nL 18.109375 26.703125 \nL 18.109375 0 \nL 9.078125 0 \nz\n\" id=\"DejaVuSans-107\"/>\n     <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n    </defs>\n    <g transform=\"translate(60.099716 343.527694)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"221.972656\" xlink:href=\"#DejaVuSans-107\"/>\n     <use x=\"276.257812\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"337.78125\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"text_50\">\n    <!-- playing -->\n    <g transform=\"translate(60.329091 342.829413)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"91.259766\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"152.539062\" xlink:href=\"#DejaVuSans-121\"/>\n     <use x=\"211.71875\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"239.501953\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"302.880859\" xlink:href=\"#DejaVuSans-103\"/>\n    </g>\n   </g>\n   <g id=\"text_51\">\n    <!-- drums -->\n    <g transform=\"translate(275.744689 335.630436)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"104.589844\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"167.96875\" xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"265.380859\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"text_52\">\n    <!-- costume -->\n    <g transform=\"translate(62.766049 335.587812)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"54.980469\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"116.162109\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"168.261719\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"207.470703\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"270.849609\" xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"368.261719\" xlink:href=\"#DejaVuSans-101\"/>\n    </g>\n   </g>\n   <g id=\"text_53\">\n    <!-- gorilla -->\n    <g transform=\"translate(132.074799 219.508556)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"124.658203\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"165.771484\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"193.554688\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"221.337891\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"249.121094\" xlink:href=\"#DejaVuSans-97\"/>\n    </g>\n   </g>\n   <g id=\"text_54\">\n    <!-- food -->\n    <g transform=\"translate(278.281534 343.177764)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"35.205078\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"96.386719\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"157.568359\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_55\">\n    <!-- cluster 3 + food - Monkeys and drums -->\n    <defs>\n     <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n     <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n    </defs>\n    <g transform=\"translate(54.55125 207.307599)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"54.980469\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"82.763672\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"146.142578\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"198.242188\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"237.451172\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"298.974609\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"340.087891\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"371.875\" xlink:href=\"#DejaVuSans-51\"/>\n     <use x=\"435.498047\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"467.285156\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"551.074219\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"582.861328\" xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"618.066406\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"679.248047\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"740.429688\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"803.90625\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"835.693359\" xlink:href=\"#DejaVuSans-45\"/>\n     <use x=\"871.777344\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"903.564453\" xlink:href=\"#DejaVuSans-77\"/>\n     <use x=\"989.84375\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"1051.025391\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"1114.404297\" xlink:href=\"#DejaVuSans-107\"/>\n     <use x=\"1168.689453\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1230.212891\" xlink:href=\"#DejaVuSans-121\"/>\n     <use x=\"1289.392578\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"1341.492188\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1373.279297\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"1434.558594\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"1497.9375\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"1561.414062\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1593.201172\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"1656.677734\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"1697.791016\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"1761.169922\" xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"1858.582031\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_4\">\n   <g id=\"patch_17\">\n    <path d=\"M 385.190625 349.728651 \nL 625.190625 349.728651 \nL 625.190625 213.307599 \nL 385.190625 213.307599 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_4\">\n    <g clip-path=\"url(#p9a21553d01)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"396.099716\" xlink:href=\"#m291bf2d360\" y=\"343.527694\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"396.167398\" xlink:href=\"#m291bf2d360\" y=\"328.386235\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"613.793072\" xlink:href=\"#m291bf2d360\" y=\"219.508556\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"614.281534\" xlink:href=\"#m291bf2d360\" y=\"328.228712\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"614.217273\" xlink:href=\"#m291bf2d360\" y=\"313.870021\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_7\">\n    <g id=\"xtick_22\">\n     <g id=\"line2d_36\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"389.577374\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_56\">\n      <!-- 0.75 -->\n      <g transform=\"translate(374.254718 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_23\">\n     <g id=\"line2d_37\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"428.126522\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_57\">\n      <!-- 0.50 -->\n      <g transform=\"translate(412.803866 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_24\">\n     <g id=\"line2d_38\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"466.67567\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_58\">\n      <!-- 0.25 -->\n      <g transform=\"translate(451.353014 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_25\">\n     <g id=\"line2d_39\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"505.224818\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_59\">\n      <!-- 0.00 -->\n      <g transform=\"translate(494.092006 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_26\">\n     <g id=\"line2d_40\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"543.773966\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_60\">\n      <!-- 0.25 -->\n      <g transform=\"translate(532.641154 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_27\">\n     <g id=\"line2d_41\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"582.323114\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_61\">\n      <!-- 0.50 -->\n      <g transform=\"translate(571.190301 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_28\">\n     <g id=\"line2d_42\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"620.872262\" xlink:href=\"#m10062fec22\" y=\"349.728651\"/>\n      </g>\n     </g>\n     <g id=\"text_62\">\n      <!-- 0.75 -->\n      <g transform=\"translate(609.739449 364.327089)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_8\">\n    <g id=\"ytick_15\">\n     <g id=\"line2d_43\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"385.190625\" xlink:href=\"#me092e2005c\" y=\"326.709055\"/>\n      </g>\n     </g>\n     <g id=\"text_63\">\n      <!-- 0.707 -->\n      <g transform=\"translate(349.5625 330.508274)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_16\">\n     <g id=\"line2d_44\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"385.190625\" xlink:href=\"#me092e2005c\" y=\"292.249446\"/>\n      </g>\n     </g>\n     <g id=\"text_64\">\n      <!-- 0.708 -->\n      <g transform=\"translate(349.5625 296.048664)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_17\">\n     <g id=\"line2d_45\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"385.190625\" xlink:href=\"#me092e2005c\" y=\"257.789836\"/>\n      </g>\n     </g>\n     <g id=\"text_65\">\n      <!-- 0.709 -->\n      <g transform=\"translate(349.5625 261.589055)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_18\">\n     <g id=\"line2d_46\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"385.190625\" xlink:href=\"#me092e2005c\" y=\"223.330227\"/>\n      </g>\n     </g>\n     <g id=\"text_66\">\n      <!-- 0.710 -->\n      <g transform=\"translate(349.5625 227.129445)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 385.190625 349.728651 \nL 385.190625 213.307599 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 625.190625 349.728651 \nL 625.190625 213.307599 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 385.190625 349.728651 \nL 625.190625 349.728651 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 385.190625 213.307599 \nL 625.190625 213.307599 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_67\">\n    <!-- cheetah -->\n    <g transform=\"translate(396.099716 343.527694)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"54.980469\" xlink:href=\"#DejaVuSans-104\"/>\n     <use x=\"118.359375\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"179.882812\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"241.40625\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"280.615234\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"341.894531\" xlink:href=\"#DejaVuSans-104\"/>\n    </g>\n   </g>\n   <g id=\"text_68\">\n    <!-- running -->\n    <g transform=\"translate(396.167398 328.386235)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"41.113281\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"104.492188\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"167.871094\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"231.25\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"259.033203\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"322.412109\" xlink:href=\"#DejaVuSans-103\"/>\n    </g>\n   </g>\n   <g id=\"text_69\">\n    <!-- behind -->\n    <g transform=\"translate(613.793072 219.508556)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"125\" xlink:href=\"#DejaVuSans-104\"/>\n     <use x=\"188.378906\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"216.162109\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"279.541016\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_70\">\n    <!-- chases -->\n    <g transform=\"translate(614.281534 328.228712)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"54.980469\" xlink:href=\"#DejaVuSans-104\"/>\n     <use x=\"118.359375\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"179.638672\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"231.738281\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"293.261719\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"text_71\">\n    <!-- food -->\n    <g transform=\"translate(614.217273 313.870021)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"35.205078\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"96.386719\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"157.568359\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_72\">\n    <!-- cluster 4 + food - Cheetahs -->\n    <g transform=\"translate(422.644688 207.307599)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"54.980469\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"82.763672\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"146.142578\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"198.242188\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"237.451172\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"298.974609\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"340.087891\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"371.875\" xlink:href=\"#DejaVuSans-52\"/>\n     <use x=\"435.498047\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"467.285156\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"551.074219\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"582.861328\" xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"618.066406\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"679.248047\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"740.429688\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"803.90625\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"835.693359\" xlink:href=\"#DejaVuSans-45\"/>\n     <use x=\"871.777344\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"903.564453\" xlink:href=\"#DejaVuSans-67\"/>\n     <use x=\"973.388672\" xlink:href=\"#DejaVuSans-104\"/>\n     <use x=\"1036.767578\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1098.291016\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1159.814453\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"1199.023438\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"1260.302734\" xlink:href=\"#DejaVuSans-104\"/>\n     <use x=\"1323.681641\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_5\">\n   <g id=\"patch_22\">\n    <path d=\"M 49.190625 540.718125 \nL 289.190625 540.718125 \nL 289.190625 404.297072 \nL 49.190625 404.297072 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_5\">\n    <g clip-path=\"url(#pa8e664d17c)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.374415\" xlink:href=\"#m291bf2d360\" y=\"412.114156\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.103316\" xlink:href=\"#m291bf2d360\" y=\"501.733422\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"278.281534\" xlink:href=\"#m291bf2d360\" y=\"534.517168\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.379316\" xlink:href=\"#m291bf2d360\" y=\"410.498029\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.099716\" xlink:href=\"#m291bf2d360\" y=\"502.926658\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"278.113872\" xlink:href=\"#m291bf2d360\" y=\"478.938401\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_9\">\n    <g id=\"xtick_29\">\n     <g id=\"line2d_47\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"76.64338\" xlink:href=\"#m10062fec22\" y=\"540.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_73\">\n      <!-- 0.6 -->\n      <g transform=\"translate(64.501974 555.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_30\">\n     <g id=\"line2d_48\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"107.476589\" xlink:href=\"#m10062fec22\" y=\"540.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_74\">\n      <!-- 0.4 -->\n      <g transform=\"translate(95.335183 555.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_31\">\n     <g id=\"line2d_49\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.309798\" xlink:href=\"#m10062fec22\" y=\"540.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_75\">\n      <!-- 0.2 -->\n      <g transform=\"translate(126.168392 555.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_32\">\n     <g id=\"line2d_50\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"169.143008\" xlink:href=\"#m10062fec22\" y=\"540.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_76\">\n      <!-- 0.0 -->\n      <g transform=\"translate(161.191445 555.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_33\">\n     <g id=\"line2d_51\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"199.976217\" xlink:href=\"#m10062fec22\" y=\"540.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_77\">\n      <!-- 0.2 -->\n      <g transform=\"translate(192.024655 555.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_34\">\n     <g id=\"line2d_52\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.809426\" xlink:href=\"#m10062fec22\" y=\"540.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_78\">\n      <!-- 0.4 -->\n      <g transform=\"translate(222.857864 555.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_35\">\n     <g id=\"line2d_53\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"261.642636\" xlink:href=\"#m10062fec22\" y=\"540.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_79\">\n      <!-- 0.6 -->\n      <g transform=\"translate(253.691073 555.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_10\">\n    <g id=\"ytick_19\">\n     <g id=\"line2d_54\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"523.496541\"/>\n      </g>\n     </g>\n     <g id=\"text_80\">\n      <!-- 0.7065 -->\n      <g transform=\"translate(7.2 527.29576)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_20\">\n     <g id=\"line2d_55\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"497.964193\"/>\n      </g>\n     </g>\n     <g id=\"text_81\">\n      <!-- 0.7070 -->\n      <g transform=\"translate(7.2 501.763412)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_21\">\n     <g id=\"line2d_56\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"472.431845\"/>\n      </g>\n     </g>\n     <g id=\"text_82\">\n      <!-- 0.7075 -->\n      <g transform=\"translate(7.2 476.231064)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_22\">\n     <g id=\"line2d_57\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"446.899497\"/>\n      </g>\n     </g>\n     <g id=\"text_83\">\n      <!-- 0.7080 -->\n      <g transform=\"translate(7.2 450.698716)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_23\">\n     <g id=\"line2d_58\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#me092e2005c\" y=\"421.36715\"/>\n      </g>\n     </g>\n     <g id=\"text_84\">\n      <!-- 0.7085 -->\n      <g transform=\"translate(7.2 425.166368)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 49.190625 540.718125 \nL 49.190625 404.297072 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 289.190625 540.718125 \nL 289.190625 404.297072 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 49.190625 540.718125 \nL 289.190625 540.718125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 49.190625 404.297072 \nL 289.190625 404.297072 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_85\">\n    <!-- baby -->\n    <g transform=\"translate(60.374415 412.114156)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"124.755859\" xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"188.232422\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"text_86\">\n    <!-- girl -->\n    <g transform=\"translate(60.103316 501.733422)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"91.259766\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"132.373047\" xlink:href=\"#DejaVuSans-108\"/>\n    </g>\n   </g>\n   <g id=\"text_87\">\n    <!-- woman -->\n    <g transform=\"translate(278.281534 534.517168)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-119\"/>\n     <use x=\"81.787109\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"142.96875\" xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"240.380859\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"301.660156\" xlink:href=\"#DejaVuSans-110\"/>\n    </g>\n   </g>\n   <g id=\"text_88\">\n    <!-- carrying -->\n    <g transform=\"translate(60.379316 410.498029)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"54.980469\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"116.259766\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"155.623047\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"196.736328\" xlink:href=\"#DejaVuSans-121\"/>\n     <use x=\"255.916016\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"283.699219\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"347.078125\" xlink:href=\"#DejaVuSans-103\"/>\n    </g>\n   </g>\n   <g id=\"text_89\">\n    <!-- carried -->\n    <g transform=\"translate(60.099716 502.926658)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"54.980469\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"116.259766\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"155.623047\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"196.736328\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"224.519531\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"286.042969\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_90\">\n    <!-- food -->\n    <g transform=\"translate(278.113872 478.938401)scale(0.1 -0.1)\">\n     <use xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"35.205078\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"96.386719\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"157.568359\" xlink:href=\"#DejaVuSans-100\"/>\n    </g>\n   </g>\n   <g id=\"text_91\">\n    <!-- cluster 5 + food - Babies -->\n    <defs>\n     <path d=\"M 19.671875 34.8125 \nL 19.671875 8.109375 \nL 35.5 8.109375 \nQ 43.453125 8.109375 47.28125 11.40625 \nQ 51.125 14.703125 51.125 21.484375 \nQ 51.125 28.328125 47.28125 31.5625 \nQ 43.453125 34.8125 35.5 34.8125 \nz\nM 19.671875 64.796875 \nL 19.671875 42.828125 \nL 34.28125 42.828125 \nQ 41.5 42.828125 45.03125 45.53125 \nQ 48.578125 48.25 48.578125 53.8125 \nQ 48.578125 59.328125 45.03125 62.0625 \nQ 41.5 64.796875 34.28125 64.796875 \nz\nM 9.8125 72.90625 \nL 35.015625 72.90625 \nQ 46.296875 72.90625 52.390625 68.21875 \nQ 58.5 63.53125 58.5 54.890625 \nQ 58.5 48.1875 55.375 44.234375 \nQ 52.25 40.28125 46.1875 39.3125 \nQ 53.46875 37.75 57.5 32.78125 \nQ 61.53125 27.828125 61.53125 20.40625 \nQ 61.53125 10.640625 54.890625 5.3125 \nQ 48.25 0 35.984375 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-66\"/>\n    </defs>\n    <g transform=\"translate(94.890938 398.297072)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"54.980469\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"82.763672\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"146.142578\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"198.242188\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"237.451172\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"298.974609\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"340.087891\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"371.875\" xlink:href=\"#DejaVuSans-53\"/>\n     <use x=\"435.498047\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"467.285156\" xlink:href=\"#DejaVuSans-43\"/>\n     <use x=\"551.074219\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"582.861328\" xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"618.066406\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"679.248047\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"740.429688\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"803.90625\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"835.693359\" xlink:href=\"#DejaVuSans-45\"/>\n     <use x=\"871.777344\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"903.564453\" xlink:href=\"#DejaVuSans-66\"/>\n     <use x=\"972.167969\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"1033.447266\" xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"1096.923828\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"1124.707031\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1186.230469\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p18dd5531c6\">\n   <rect height=\"136.421053\" width=\"240\" x=\"49.190625\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"pa964f21a9d\">\n   <rect height=\"136.421053\" width=\"240\" x=\"385.190625\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p207673fcca\">\n   <rect height=\"136.421053\" width=\"240\" x=\"49.190625\" y=\"213.307599\"/>\n  </clipPath>\n  <clipPath id=\"p9a21553d01\">\n   <rect height=\"136.421053\" width=\"240\" x=\"385.190625\" y=\"213.307599\"/>\n  </clipPath>\n  <clipPath id=\"pa8e664d17c\">\n   <rect height=\"136.421053\" width=\"240\" x=\"49.190625\" y=\"404.297072\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXqSyMyy-bm8"
      },
      "source": [
        "### Question 4.4: Independent Analysis of Bias in Word Vectors [code + written] (4 points) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZynvZnq-nqk"
      },
      "source": [
        "Select a corpus of interest, or examples of interest and shed light on one source of bias from SentenceBERT."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "pip install datasets"
      ],
      "metadata": {
        "id": "4uqJ4g8NlgVl"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset found at https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
        "%%capture\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "WjfaEbKkleTP"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "\n",
        "def get_most_similar(corpus, query, col, nb_samples=100, col_dict=None):\n",
        "    if col_dict:\n",
        "        col = col_dict[col]\n",
        "\n",
        "    # Inspired by \n",
        "    # https://www.sbert.net/examples/applications/semantic-search/README.html#speed-optimization\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    \n",
        "    corpus_embeddings = model.encode(corpus[col].values[:nb_samples], convert_to_tensor=True, normalize_embeddings=True)\n",
        "    query_embeddings = model.encode(query, convert_to_tensor=True, normalize_embeddings=True)\n",
        "\n",
        "    corpus_embeddings = corpus_embeddings#.to('cuda')\n",
        "    corpus_embeddings = util.normalize_embeddings(corpus_embeddings)\n",
        "\n",
        "    query_embeddings = query_embeddings#.to('cuda')\n",
        "    query_embeddings = util.normalize_embeddings(query_embeddings)\n",
        "    \n",
        "    hits = util.semantic_search(query_embeddings, corpus_embeddings, score_function=util.dot_score)\n",
        "    for hit in hits[0]:\n",
        "        print(f'score: {round(hit[\"score\"], 4)} -- text: { corpus.loc[hit[\"corpus_id\"], [col]].values }')\n"
      ],
      "metadata": {
        "id": "SHkK29xWjR--"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "dataset = load_dataset(\"flax-sentence-embeddings/stackexchange_titlebody_best_and_down_voted_answer_jsonl\", \"skeptics\")\n",
        "\n",
        "corpus = dataset['train'].to_pandas()\n",
        "col_dict = {'up': \"upvoted_answer\", 'down': 'downvoted_answer', 'qu': 'title_body'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "afXpTTJa66Qs",
        "outputId": "551247c0-ef46-41d4-8957-b1e04d0518f0"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset stackexchange_titlebody_best_and_down_voted_answer_jsonl (/root/.cache/huggingface/datasets/flax-sentence-embeddings___stackexchange_titlebody_best_and_down_voted_answer_jsonl/skeptics/1.1.0/a767719a162391b61f7fecca12b41572102b8cf2909d9c06f55eb7a70c7aa579)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_in = corpus\n",
        "query_in = [\"The Covid vaccine is\"]\n",
        "\n",
        "get_most_similar(corpus_in, query_in, col='down', nb_samples=200, col_dict=col_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka2JzQ4BjU0C",
        "outputId": "6fe1291f-79d1-4f2d-9415-cc6f1d2be5af"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: 0.5851 -- text: ['Vaccination is a barbarous practice, and it is one of the most fatal of all the delusions current in our time, not to be found even among the so-called savage races of the world. Its supporters are not content with its adoption by those who have no objection to it, but seek to impose it with the aid of penal laws and rigorous punishments on all people alike.\\n\\n\\nA Guide to Health Chapter 6']\n",
            "score: 0.5448 -- text: ['One thing is certain.  In the book \"Vaccines, are they really safe and effective?\"  page 20-21  Says that in 1959 , Bernice Eddy discovered that polio vaccines being administered throughout the world contained an infectious agent capable of causing cancer.   SV-40  is what is was.  Here is how it works    1. Monkey kidneys are used to develop polio vaccines  2. SV-40 , a cancer causing virus , thrived in monkey kidneys.    3. Polio vaccines were contaminated   4.  Millions of people in the USA and throughout the world were infected   5. Cancer rates have increased.  SV-40 is found in the brain tumors, bone cancers, lung cancers and leukemia.  \\n\\nSource:   National Morbidity Reports taken from the U.S. Public Health surveillance reports.  Lancet ( April 18, 1950)  pp. 659-63.\\n\\nVaccines are one of many sources of cancer.  War on cancer is lost, Nixon declared the war on cancer and there is no end in site.   \\n\\nOh, and we live longer due to 2 proven facts.\\n1. HVAC  (Heating especially )\\n2. Modern septic systems']\n",
            "score: 0.4961 -- text: [\"The vaccine that are commonly used do use adjuvants. Often that leads to adverse effects.\\nThe study that approved the Pandemrix vaccine noted that the vaccine gave  21.5% of children between 6 and 9 headaches.\\n\\nWhen the vaccine was used under live condition in Germany for swine flu the general monitoring system wasn't sensitive enough to pick up the adverse effects. Given the fact that the general monitoring system isn't working we don't know about the real extend of the damage that the vaccine has done under live conditions.\"]\n",
            "score: 0.4497 -- text: [\"Some studies into COVID and others into Influenza contradict the government position on the efficacy of masks suggest there's no benefit.\\nhttps://www.acpjournals.org/doi/10.7326/M20-6817\\nhttps://www.rcreader.com/commentary/masks-dont-work-covid-a-review-of-science-relevant-to-covide-19-social-policy\\nHere's a doctor -Jim Meehan MD saying mask wearing can be dangerous.\\nhttps://theplantstrongclub.org/2020/07/04/healthy-people-should-not-wear-face-masks-by-jim-meehan-md/\"]\n",
            "score: 0.4431 -- text: ['Yes, but it goes even further back than that:\\n\\nMADRID (Reuters) - Spanish virologists have found traces of the novel coronavirus in a sample of Barcelona waste water collected in March 2019, nine months before the COVID-19 disease was identified in China, the University of Barcelona said on Friday.']\n",
            "score: 0.4187 -- text: ['Note: This isn\\'t intended as a complete answer, only a partial one (which is too extensive to place in comments).\\n\\nA Washington Post article from April 19, 2020 states:\\n\\n\\n  More than a dozen U.S. researchers, physicians and public health\\n  experts, many of them from the Centers for Disease Control and\\n  Prevention, were working full time at the Geneva headquarters of the\\n  World Health Organization as the novel coronavirus emerged late last\\n  year and transmitted real-time information about its discovery and\\n  spread in China to the Trump administration, according to U.S. and\\n  international officials.\\n  \\n  A number of CDC staff members are regularly detailed to work at the\\n  WHO in Geneva as part of a rotation that has operated for years.\\n  Senior Trump-appointed health officials also consulted regularly at\\n  the highest levels with the WHO as the crisis unfolded, the officials\\n  said.\\n\\n\\nSo CDC staff working with WHO did communicate (in \"real time\") to the White House staff information about the virus.\\n\\nAnd an article in the March 30, 2020 issue of The New Yorker contains a story, written by an English professor from the US, relating his experience with the virus while living in China during the origin of the outbreak.  He implies that the presence of the virus was well-known by mid-January, and a \"lock-down\" was implemented to prevent its spread between people.\\n\\nWhat I can\\'t show is that the details (ie, people-to-people transmission) was transmitted to the WHO, though it\\'s clear that the fact would have been known to anyone outside of China who was following the situation there, since it was so well-known within China.']\n",
            "score: 0.388 -- text: ['This peer-reviewed paper from Reviews of Cardiovascular Medicine in Dec 2020 lists (and links) to studies in 23 countries: Algeria, Argentina, Brazil, Bangladesh, Cameroon, China, Colombia, Egypt, France, Ghana, India, Korea, Mexico, Morocco, Mozanbique, Nigeria, Peru, Senegal, South Africa, Spain, Taiwan, Uganda, USA.\\nHere is a list of 247 HCQ studies, 203 comparing treatment and control groups.\\nHere is a list of 58 Ivermectin COVID-19 studies, 22 peer reviewed, 38 with results comparing treatment and control groups. Here is a different list for Ivermectin showing the countries involved.\\nTrialsite News also has links.\\nThis should be a good starting point for your chase.']\n",
            "score: 0.3542 -- text: ['In a MedCram video entitled Coronavirus Epidemic Update 12: Unsupported Theories, Pneumonia, ACE2 &amp; nCoV, pulmonologist Dr. Seheualt looks at the \"leaked\" numbers, and calculates the \\ndeath ratio (deaths divided by confirmed cases) as around 16%.\\n\\nHe compares that to the experience with nCoV-2019 in Japan and Singapore, and suggests that the number of deaths is lower than would be expected if the leak was accurate expected. \\n\\n(Sheheault performs no statistical analysis of the likelihood of these results, and does not consider if the ratio might be different due to the initial health or treatment regimes of the countries.)\\n\\nHe concludes that the leaked data is inaccurate.']\n",
            "score: 0.3233 -- text: [\"Yes.\\nIt 'is' a pandemic.\\nOr can be classified as one, since there is simply no widely agreed upon stable definitions to say otherwise.\\nA pandemic is simply an epidemic that affects a large area. This is true for common language definitions like from the Oxford English Dictionary:\\n\\nGeneral, universal. esp. Of a disease: Prevalent over the whole of a country or continent, or over the whole world. Distinguished from epidemic, which may connote limitation to a smaller area. (Epidemic:  Of a disease: `Prevalent among a people or a community at a special time, and produced by some special causes not generally present in the affected locality')\\n\\nOr from a medical English dictionary:\\n\\nPandemic: An epidemic occurring over a very wide area, crossing international boundaries, and usually affecting a large number of people. Only some pandemics cause severe disease in some individuals or at a population level.\\n Oxford Dictionary of Epidemiology\\n\\n\\nThis is especially also true going by the terribly weak definition the WHO now occasionally likes to operate on:\\n\\nA pandemic is defined as an epidemic occurring worldwide, or over a very wide area, crossing international boundaries and usually affecting a large number of people. The classical definition includes nothing about population immunity, virology or disease severity. By this definition, pandemics can be said to occur annually in each of the temperate southern and northern hemispheres, given that seasonal epidemics cross international boundaries and affect a large number of people.\\n(src)\\n\\nNeither is any human-to-human transmission required, although in Lyme it is also observable.  Nor is 'pandemic' necessitating 'a large number of people dying'.\\nThe latter was a requirement for 'pandemic' influenza classifications but it hurt business too much so that criterion was dropped. Now pandemics can appear very frequently because of that move. A move that in 2009 was widely regarded as crossing the borderlines between intransparency, conflicts of interest and outright corruption. (As described in the British Medical Journal, the Parliamentary Assembly of the European Council, with a focus on declaring weak effects of a flu as pandemic with the consequence of pressuring the public into buying large numbers of ineffective medicines or administering rushed and not adequately tested vaccines with too many unpredicted side-effects to a public that didn't need them or couldn't benefit from them (like Tamiflu or Pandemrix)).1\\nThis criticism was on the one hand simply dismissed by the WHO with empty politician's phrases. On the other hand the lesson the WHO communicated it learned from these allegations to the public as recently as the start of this year was:\\n&quot;The WHO no longer uses the category of pandemic&quot; at all: &quot;WHO says it no longer uses 'pandemic' category, but virus still emergency&quot;\\nAnd Lyme disease is frequently classified as a pandemic:\\n\\nWe further propose that vertical and horizontal intra-human transmission over generations has likely had a non-linear amplifying effect on human prevalence. [] this transmission mechanism now significantly exceeds the contribution of new cases from zoonotic vectors, and has reached pandemic proportion on all continents where humans reside. These conclusions strongly support our clinical experience.\\n W. T. Harvey, P. Salvato: &quot;Lyme disease: ancient engine of an unrecognized  borreliosis pandemic?&quot;, Medical Hypotheses (2003) 60(5), 742759, 2003. doi:10.1016/S0306-9877(03)00060-4.\\n\\n Marcus Davidsson: &quot;The Financial Implications of a Well-Hidden and Ignored Chronic Lyme Disease Pandemic&quot;, healthcare, 2018, 6, 16; doi:10.3390/healthcare6010016\\n\\nA seemingly stealthy pandemic of epic proportions, causing untold misery and suffering for millions, thrives amidst a culture of politics, greed, corruption, incompetence and arrogance. Endemic in many parts of the world Lyme disease and its associated co- infections doesnt even exist in the minds of some in the medical community, cant be easily diagnosed, treatment regimens are often confusing and not evidence based. When treatment is attempted it is often inadequate or substandard leaving many with chronic persistent infections. While not fitting a vaccine model, paradoxically the quest for finding a vaccine seems to have superseded all other priorities.\\n Kenneth Paul Stoller: &quot;Overview Of Lyme Disease: A Critique of an Ignored Pandemic&quot;, International Journal of Current Advanced Research Vol 4, Issue 10, pp 409-414, October 2015.\\n\\n\\nLyme disease, the most common tick-borne infection in the north- ern hemisphere, is a serious public health problem. In North America, it is caused exclusively by Borrelia burgdorferi sensu stricto (hereafter referred to as B. burgdorferi), whereas in Europe it is caused by B. afzelii, B. garinii, B. burgdorferi, and occasionally by other species of borrelia.\\n Henry M. Feder et al.: &quot;A Critical Appraisal of Chronic Lyme Disease, The new england journal of medicine,  2007;357:1422-30.\\n\\n Raphael B Stricker &amp; Marianne J Middelveen: &quot;Sexual transmission of Lyme disease: challenging the tickborne disease paradigm&quot;, Expert Review of Anti-infective Therapy Volume 13, 2015 - Issue 11, Pages 1303-1306 | Published online: 26 Aug 2015.\\nOr listing lyme right among our currently most favorite 'pandemic' and even counting it as &quot;new and important emergences and re-emergences&quot;:\\n David M. Morens and Anthony S. Fauci: &quot;Emerging Pandemic Diseases: How We Got to COVID-19&quot;, Cell. 2020 Sep 3; 182(5): 10771092. Published online 2020 Aug 15. doi: 10.1016/j.cell.2020.08.021 PMCID: PMC7428724 PMID: 32846157\\nEpistemologically the explanation for these differences in defining an infectious disease pandemic are\\n\\nThe examples given above suggest that the pandemic concept, as applied to important global events spanning many centuries, includes diseases of very different etiologies that exhibit a variety of epidemiologic features. There seems to be only 1 invariable common denominator: wide-spread geographic extension. However, most of the other epidemiologic features noted are commonfor example, movement and high attack rateswhereas other variable features, such as noninfectiousness and severity, seem generally out of place. It should not be surprising that, in coming to terms with a new pandemic in 2009, different observers would invoke and emphasize different aspects of older pandemics with which they were familiar.\\nIt is ironic that part of the recent problem with pandemic terminology arose not because of inherent vagueness but because of well-meaning attempts to eliminate ambiguities. Decades ago, influenza virologists began to use a highly restricted definition of pandemic that accepted only the introduction and global spread of novel hemagglutinin (HA) subtypes.\\n[]\\nThe WHO pointed out that the pandemic influenza phases emphasized geographic distribution of disease caused by the emergent virus, not its severity, []\\nOutside of taxonomic considerations, scientific terminology often arises by habit and usage rather than by choice. Once we have a term, changing it may be difficult, and there is no consensus process for doing so. What are the implications of using a flexible and subjective term that means different things to different observers and varies when applied to different diseases? []\\nIn summary, simply defining a pandemic as a large epidemic may make ultimate sense in terms of comprehensibility and consistency. []\\n David M. Morens, Gregory K. Folkers, Anthony S. Fauci: &quot;What Is a Pandemic?&quot;, The Journal of Infectious Diseases, Volume 200, Issue 7, 1 October 2009, Pages 10181021, https://doi.org/10.1086/644537\\n\\nThus we arrive at this 'expert' opinion\\n\\nLyme disease meets these eight characteristics that have been applied to pandemics by Morens. The disease has a worldwide distribution; is moved long distances by birds; has a high attack rate and explosive spread; offers minimal immunity; can lead to a wide range of chronic manifestations not previously described; is transmitted by a vector, and can lead to severe illness.\\n Daniel J. Cameron, MD, MPH. &quot;Time to designate Lyme disease as a pandemic?&quot;.\\n\\nWhether anyone thinks of the last two examples as 'Fauci as a fraud' or 'Cameron as an expert'  or justthe other way around  they both share similar views on how to define and classify pandemics. And that makes lyme disease count as some form of pandemic.\\nAnd since\\n Clara Chaisson: &quot;The Lyme Epidemic Is Worse Than Ever.\\nPrevention is the best medicine for this tick-borne diseasebut weve got our work cut out for us.&quot;, April 09, 2018.\\nSuch a classification has of course found its way into the market in form of a book that ticks a lot of other boxes:\\n Barbaros etin: &quot;The New Pandemic of the 21st Century; Lyme Disease: The First Pandemic of Climate Change&quot;, 2020.\\nBringing us back again to how even the WHO plays fast and loose with such panic inducing words like 'pandemic'. Even in official WHO publications we also find &quot;obesity as a global epidemic&quot;, or: pandemic. (PDF)\\nOf course, other problems are seen as benefitting from this attention grabbing label:\\n\\nWHO: 10 facts on the global tobacco epidemic\\nWHO: Unsafe abortion: the preventable pandemic\\n\\nWe also see heart disease called a pandemic, metabolic syndrome, cardiovascular or coronary heart disease (this even &quot;in a true sense&quot;, hypertension and simply Vitamin D deficiency. As it is often used as just nothing more than &quot;widespread disease&quot;, the list is practically endless.\\nThus, if 'obesity' or 'abortion' can be called to be a pandemic by WHO officials, then lyme sure can be too.\\nThere is no universally accepted proscriptive usage pattern that excludes lyme and the observational language usage pattern shows pandemic to be in use for lyme.\\nLyme disease: What it is and why some are calling it the next pandemic\\nParallel Pandemics: Covid-19 and Lyme Disease\\n1: Transparency Supports Cochrane Collaborations Request For Open Access To Clinical Trial Reports On Tamiflu \\nThe BMJ questions transparency of information surrounding safety of Pandemrix swine flu vaccine \\nCorruption and the Coronavirus \\nConflicts of interest. WHO and the pandemic flu &quot;conspiracies&quot; \\nDie Gesponserte Pandemie - Die Who Und Die Schweinegrippe \\nWHO and pandemic flu. Another question for GSK \\nSwine flu panic\\nVaccines to prevent influenza in healthy adults \\nParliamentary Assembly Council of Europe, March 23, 2010: &quot;The handling of the H1N1 pandemic: more transparency needed&quot;, 23 March 2010, PDF\"]\n",
            "score: 0.3208 -- text: [\"edit: I need to clarify: This is not a complete answer to the question. But it contains relevant information for reaching a conclusion.\\n\\nJPMorgan has a new study (paywall) showing the strongest correlation to new cases is eating in restaurants.\\n\\nThe firm analyzed spending by 30 million Chase credit and debit cardholders and coronavirus case data from Johns Hopkins University, and found that spending patterns from a few weeks ago &quot;have some power in predicting where the virus has spread since then,&quot; analyst Jesse Edgerton wrote Thursday. The study found that the &quot;level of spending in restaurants three weeks ago was the strongest predictor of the rise in new virus cases over the subsequent three weeks,&quot; in line with the firm's recent studies using OpenTable data.\\n\\nSome more discussion on twitter with this graph:\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_in = corpus\n",
        "query_in = [\"Woman's right\"]\n",
        "\n",
        "get_most_similar(corpus_in, query_in, col='down', nb_samples=200, col_dict=col_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9bF876k3JTN",
        "outputId": "3ec4e4aa-6f4f-471e-bf47-08cd13fb25df"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: 0.2459 -- text: [\"Not an expert regarding this topic, but all the studies that I found regarding this topic say that yes, women overall consume more sustainably than men. I cannot speak to your second question regarding gender quotas in environmental organizations reducing climate change - that question is much too specific.\\n\\nThis study here conducted in Turkey says that\\n\\n\\n  Women showed a higher level of sustainable consumption behavior both in overall behavior and tendency to reuse products. Taken together, the findings suggest that gender and generation of consumers can differentiate sustainable consumption behavior.\\n\\n\\nThis study conducted with families in Sweden says that (I'm pretty much quoting the abstract in full here because it's quite relevant to the topic)\\n\\n\\n  Women  are  more  likely  than  men  to    consume  sustainably  based  on  a  case  study  of  Swedish  families.  Sustainable  consumption  includes  activities  such  as  buying  green  and  fair  trade  products,  reducing travel, eating organic foods, and recycling. According to this research, women express more interest in sustainable living and spend more time seeking information on sustainable consumption and sustainable alternatives than men. But  women  also  bare  a  disproportionate  burden  for  maintaining  sustainable  lifestyles.  While  Sweden  has  consistently  ranked  high  in  measures  of  gender  equity,  household  and  family  duties  remain  a  female  responsibility  in  most  Swedish  families.  As  such,  women  are  often  pressed  for  time,  making  the  pursuit  of  sustainable  consumerism  and  lifestyles  difficult. \\n\\n\\nAnd still, they apparently manage to do so to a greater degree than men, according to the study.\\n\\nThe OECD says that \\n\\n\\n  In terms of resource impacts, women tend to leave a smaller ecological footprint  than  men  due  to  their  more  sustainable  consumption  patterns.  Sustainable consumption is using resources in a way that minimises harm to the environment while supporting the well-being of people. Mens lifestyles and  consumer  patterns,  whether  they  are  rich  or  poor,  tend  to  be  more  resource-intensive  and  less  sustainable  than  womens  (Johnsson-Latham,  2006).\\n\\n\\nThe OECD paper mentioned above quotes a larger body of research, e.g.\\n\\n\\n  Surveys  show  that  women  tend  to  be  more  sustainable  consumers.  Women  are  more  likely  to  recycle,  buy  organic  food  and  eco-labelled  products  and  place  a  higher  value  on  energy-efficient  transport  (OECD,  2008a). \\n\\n\\nAnother more specific example from a report by the Swedish government that argues the same point:\\n\\n\\n  Women   also   use   public   transport   even   in   household  with  cars  more  often  than  men  and  travel  short  distances  close  to  home.\"]\n",
            "score: 0.1923 -- text: ['I don\\'t think so.\\n\\nFor example, W. Isaacson\\'s biography, which is very well documented and covers a lot of his personal life, doesn\\'t cite anything like that at all.\\n\\nAlso, he had 2 marriages, each of less than 20 years of length (as cited by the other answers).\\n\\nI seriously doubt he said something like that about his first wife. He did not have a great relationship with her, and this is documented in a famous list of \"cruel duties\" which he forced his wife to agree to:\\n\\n\\n  CONDITIONS\\n  \\n  A. You will make sure:\\n  \\n  \\n  that my clothes and laundry are kept in good order;\\n  that I will receive my three meals regularly in my room;\\n  that my bedroom and study are kept neat, and especially that my desk is left for my use only.\\n  \\n  \\n  B. You will renounce all personal relations with me insofar as they are not completely necessary for social reasons. Specifically, You will forego:\\n  \\n  \\n  my sitting at home with you;\\n  my going out or travelling with you.\\n  \\n  \\n  C. You will obey the following points in your relations with me:\\n  \\n  \\n  you will not expect any intimacy from me, nor will you reproach me in any way;\\n  you will stop talking to me if I request it;\\n  you will leave my bedroom or study immediately without protest if I request it.\\n  \\n  \\n  D. You will undertake not to belittle me in front of our children, either through words or behavior.\\n\\n\\nsource: his biography by W. Isaacson, mentioned here: Albert Einstein Imposes on His First Wife a Cruel List of Marital Demands\\n\\nOn the other hand, while his second marriage with his first cousin Elsa was much more happy, I don\\'t think this quote is something that would be applied to it. Citing the another biography, as paraphrased by Wikipedia\\n\\n\\n  Elsa spent most of her marriage with Albert acting as gatekeeper, protecting him from unwelcome visitors and charlatans. She also was the driving force behind building their summer house in 1929.\\n\\n\\nNote that this second biography seems much less reliable as it contains \"shock claims\" in its sleeve (\"This controversial account of Albert Einstein\\'s scandalous personal life challenges the image of this genius, painting a shocking portrait that exposes him as \"an adulterous, egomaniacal misogynist who may have even beaten his first wife\"\").']\n",
            "score: 0.19 -- text: [\"Quote 1\\nI found an article that mentions a source for the first quote:\\n\\nThe Womans Rights Association had only recently changed its\\nname to the American Equal Rights Association (AERA)on\\nMay 10, 1868and tension within the organization grew quickly\\nover the Fourteenth Amendment. A few days after the organizational\\nname change, Susan B. Anthony and Elizabeth Cady Stanton\\nmet with fellow AERA members Wendell Phillips and Theodore\\nTilton. During their meeting, Phillips suggested that the organization\\nturn away from woman suffrage for the moment and focus on\\nBlack suffrage. If anything interfered, he claimed, the chance for\\nBlack enfranchisement might be lost forever. Anthony objected\\nvehemently. She raised up her right arm and proclaimed: Look at\\nthis, all of you. And hear me swear that I will cut off this right arm of\\nmine before I will ever work for or demand the ballot for the negro\\nand not the woman\\nW.E.B. DU BOIS ON\\nWOMAN SUFFRAGE\\nA Critical Analysis of\\nHis Crisis Writings\\n\\nThe article cites this book which was published in 1928.\\n\\nQuote 2\\nThe second quote is from Anthony's biography (which was written at her request): The Life and Work of Susan B. Anthony by Ida Husted Harper, page 238.\\n\\nQuote 3\\nThe third quote can be found in History of Woman Suffrage: 1861-1876 edited by Elizabeth Cady Stanton, Susan Brownell Anthony, Matilda Joslyn Gage, Ida Husted Harper, page 383. If I'm reading correctly, the book says that Anthony said it at an event in May 1869 celebrating the anniversary of the American Equal Rights Association.\\n\\n\\nMore Context\\nAs the first quote hints at, Anthony was actually fighting for the right for both blacks and women to vote. However, the fact that the 15th Amendment only gave the right for blacks to vote and not women left many, including her, feeling resentment towards blacks:\\n\\nThroughout much of the 1800s, the women's alcohol temperance movement was a powerful force in the greater push toward women's suffrage. Meanwhile, many suffrage leaders  such as Susan B. Anthony and Elizabeth Cady Stanton  had also championed black equality. Yet in 1870, the suffragists found themselves on opposing ends of the equal-rights battle when Congress passed the 15th Amendment, enabling black men to vote (at least, in theory)  and not women. That measure engendered resentment among some white suffragists, especially in the South.\\nThe Root: How Racism Tainted Women's Suffrage\"]\n",
            "score: 0.1816 -- text: ['Officers are only permitted to marry other officers, or they lose their \"commission\".  When they do marry, only the husband gets paid.  The wife is not allowed to take another job outside SA, she is expected to \"serve alongside\" her husband.  If she does not, her husband loses his \"commission\".  The married woman\\'s role in SA is subservient.  The single females get a little bit more consideration.']\n",
            "score: 0.181 -- text: [\"Google 2011 revenue: $37.9 billion \\nAmazon 2011 revenue:$34.2 billion \\nMicrosoft 2011 revenue: $69.94 billion\\n\\n\\nI don't have 2006 numbers, but I would say that it's possible in 2006 the revenue of the entire pornography industry was the size of half of the revenues of Microsoft, Google, Amazon, eBay, Yahoo, Apple and Netflix.  But the comparison is apples to oranges, and given some quick duck-duck-going on these 3 companies, I doubt that the revenue of the porn industry is equal to half of the revenue from the above companies.\\n\\nIt is even more doubtful that your friends claim (which is different from the question's title) is true.\"]\n",
            "score: 0.1543 -- text: ['Tim Bray says on Twitter:\\n\\n\\n  Phil [Karlton] said it, I reported it, someone else added on the off-by-one.\\n\\n\\nLeon Bambrick replies that he added off-by-one.']\n",
            "score: 0.1506 -- text: ['Anne Innis Dagg studied giraffe in the wild in the late 50\\'s &amp; early 60\\'s. She observed and documented lots of male homosexual behavior. She authored \"The giraffe : its biology, behavior and ecology\" in 1976 &amp; much later, \"Pursuing Giraffe\", which is about her experiences as a woman zoologist at that time, &amp; some of the resistance to her observing and reporting on homosexual behavior.']\n",
            "score: 0.149 -- text: ['To answer your question \"Do human pheromones exist\" the answer is most certainly \"yes\". That\\'s what body odour is. \\n\\nYour question should be \"Do human pheromones work the way the scam artists say they do\". The answer is almost categorically \"no\". It\\'s already pretty apparent that your natural pheromones aren\\'t attracting the opposite sex like sharks to blood. More than likely the reason for this is because human beings just don\\'t operate (or mate) like dogs or moths. We all meet and mate through social mechanisms instead. I suspect that the effectiveness of your pheromones on other people is a highly subjective and individual thing and just as importantly, only part of the equation.']\n",
            "score: 0.1466 -- text: [\"https://drjengunter.wordpress.com/2015/09/21/obgyns-agree-fully-formed-fetus-in-that-planned-parenthood-video-not-from-an-abortion-heres-why/\\n\\nThis is a gynecologist showing that one of the images in the 3rd video is not what they claim it is.  While it's only one fabrication such things rarely travel alone.\\n\\nEdit:\\n\\nhttps://drjengunter.wordpress.com/2015/09/29/the-center-for-bio-ethical-reform-promotes-illegally-taped-video-of-perineum-and-premature-delivery-and-fiorina-supports-them/\\n\\nMore from her:  The procedure doesn't match current US medical practice.  Either it's very old or it was shot in some other country.\"]\n",
            "score: 0.1442 -- text: [\"In an episode of QI (youtube) they address this, their website I will quote below:\\n\\n\\n  Until the 20th century toddlers of either sex were normally dressed in white, but when colours were used, boys were dressed in pink. At the turn of the 20th century, Dressmaker Magazine wrote: 'The preferred colour to dress young boys in is pink. Blue is reserved for girls as it is considered paler, and the more dainty of the two colours, and pink is thought to be stronger (akin to red).' As late as 1927, Time magazine reported that Princess Astrid of Belgium had been caught out when she gave birth to a girl, because 'The cradlehad been optimistically outfitted in pink, the colour for boys.'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "dataset = load_dataset(\"md_gender_bias\", \"convai2_inferred\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "jdmXIH5z5j7i",
        "outputId": "762ee83b-9f00-4adb-d580-3dc0d3d6242e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset md_gender_bias (/root/.cache/huggingface/datasets/md_gender_bias/convai2_inferred/1.0.0/8ae77b51acf93383161cc954b146159291beca6c979b54ce228c46db86116c05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = dataset['train'].to_pandas()"
      ],
      "metadata": {
        "id": "UbGytm7C7CDK"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_in = corpus\n",
        "query_in = [\"The man is wealthy\"]\n",
        "\n",
        "get_most_similar(corpus_in, query_in, col='text', nb_samples=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7peujxc6zlO",
        "outputId": "59c5fa9d-c0ca-40f4-c687-aeb36301a76c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: 0.2882 -- text: ['wow , does he live there or work ?']\n",
            "score: 0.2076 -- text: ['i agree . what do you do for a living ?']\n",
            "score: 0.1658 -- text: ['that is nice my boss at the grocery store is nice too']\n",
            "score: 0.158 -- text: [\"i don't work , i guess i am an investor . i've waited tables in the past .\"]\n",
            "score: 0.1501 -- text: ['that is very true . do you ever donate ?']\n",
            "score: 0.1379 -- text: [\"oh ok i'm a teller was the best job i could find with no college\"]\n",
            "score: 0.1315 -- text: ['yes it does pay the bills']\n",
            "score: 0.1215 -- text: ['what do you do for a living ? i proofread for hallmark .']\n",
            "score: 0.1173 -- text: ['have you visited him there before ?']\n",
            "score: 0.1116 -- text: ['i only worked half a day i work at the bank']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_in = corpus\n",
        "query_in = [\"The woman is wealthy\"]\n",
        "\n",
        "get_most_similar(corpus_in, query_in, col='text', nb_samples=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKfQL0Mc63Vm",
        "outputId": "e0ee7840-2e1e-4b44-fe0b-9e516f2ab594"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: 0.2789 -- text: ['she might . she thinks she is better than me because she has an actual job .']\n",
            "score: 0.2145 -- text: ['i agree . what do you do for a living ?']\n",
            "score: 0.1855 -- text: ['what do you do for a living ? i proofread for hallmark .']\n",
            "score: 0.1457 -- text: ['yes it does pay the bills']\n",
            "score: 0.1448 -- text: [\"interesting . i'm a website designer . pretty much spend all my time on the computer .\"]\n",
            "score: 0.1426 -- text: [\"oh ok i'm a teller was the best job i could find with no college\"]\n",
            "score: 0.1402 -- text: [\"i thought i'd make a pretty good fashion designer since i love to shop .\"]\n",
            "score: 0.1329 -- text: [\"i don't work , i guess i am an investor . i've waited tables in the past .\"]\n",
            "score: 0.1311 -- text: ['work is tiring . i would love to travel the world instead .']\n",
            "score: 0.1266 -- text: ['i think my mother was a bit touched in the head .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like any machine learning model, SentenceBERT can be subject to various sources of bias, including:\n",
        "\n",
        " - Dataset bias: If the dataset on which SentenceBERT was trained is not diverse or representative of the languages, dialects, and communities that the model will be applied to, the model may perform poorly or unfairly on those languages, dialects, or communities. To mitigate this bias, it is important to carefully select a diverse and representative dataset for training the model.\n",
        " - Algorithmic bias: The algorithms used to train SentenceBERT, as well as the hyperparameters and optimization techniques used, can influence the model's performance and the biases it exhibits. For example, if the model is trained on a heavily imbalanced dataset, it may learn to favor the majority class, leading to biased predictions.\n",
        " - Human bias: The data used to train SentenceBERT, as well as the labeling and annotation process, may be influenced by human biases. For example, if the dataset contains biased or stereotypical language, the model may learn and reproduce these biases in its predictions.\n",
        "\n",
        "The bias studied here is the dataset bias. Biased data has been injected as the input corpus. As expected from the \"Garbage in, Garbage out\" rule, the outputs present bias. Before to look at the examples, it is interesting to note that finding bias with SentenceBERT was considerably harder than with the previous methods, possibly because the pretrained model used here is trained on good data that has reduced bias to a minimum. From the examples above it is possible to note that:\n",
        " - ``Vaccination is a barbarous practice, and it is one of the most fatal of all the delu`ions current in our time, not to be found even among the so-called savage...\" \n",
        " - ``Some studies into COVID and others into Influenza contradict the government position on the efficacy of masks suggest there's no benefit\"\n",
        "\n",
        "and the other answers are disproportionately against Vaccins in general where as studies have shown the positive effects of vaccins on society. Those results are not only biased but also provide miss-information.\n"
      ],
      "metadata": {
        "id": "XM9D0_Ox8zZW"
      }
    }
  ]
}